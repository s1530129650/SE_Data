{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T02:27:27.407332Z",
     "start_time": "2021-09-27T02:27:27.359619Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "filename=\"code_idx_map.txt\"\n",
    "with open(filename, \"r\") as f:\n",
    "    code_idx_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T02:27:32.555526Z",
     "start_time": "2021-09-27T02:27:32.540829Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3840e1ca0c1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcode_idx_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    " code_idx_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T02:27:34.736061Z",
     "start_time": "2021-09-27T02:27:34.675916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'def writeBoolean(self, n):\\n        \"\"\"\\n        Writes a Boolean to the stream.\\n        \"\"\"\\n        t = TYPE_BOOL_TRUE\\n\\n        if n is False:\\n            t = TYPE_BOOL_FALSE\\n\\n        self.stream.write(t)': 0,\n",
       " 'def paste(xsel=False):\\n    \"\"\"Returns system clipboard contents.\"\"\"\\n    selection = \"primary\" if xsel else \"clipboard\"\\n    try:\\n        return subprocess.Popen([\"xclip\", \"-selection\", selection, \"-o\"], stdout=subprocess.PIPE).communicate()[0].decode(\"utf-8\")\\n    except OSError as why:\\n        raise XclipNotFound': 1,\n",
       " 'def _format_json(data, theme):\\n    \"\"\"Pretty print a dict as a JSON, with colors if pygments is present.\"\"\"\\n    output = json.dumps(data, indent=2, sort_keys=True)\\n\\n    if pygments and sys.stdout.isatty():\\n        style = get_style_by_name(theme)\\n        formatter = Terminal256Formatter(style=style)\\n        return pygments.highlight(output, JsonLexer(), formatter)\\n\\n    return output': 2,\n",
       " 'def create_path(path):\\n    \"\"\"Creates a absolute path in the file system.\\n\\n    :param path: The path to be created\\n    \"\"\"\\n    import os\\n    if not os.path.exists(path):\\n        os.makedirs(path)': 3,\n",
       " 'def _vector_or_scalar(x, type=\\'row\\'):\\n    \"\"\"Convert an object to either a scalar or a row or column vector.\"\"\"\\n    if isinstance(x, (list, tuple)):\\n        x = np.array(x)\\n    if isinstance(x, np.ndarray):\\n        assert x.ndim == 1\\n        if type == \\'column\\':\\n            x = x[:, None]\\n    return x': 4,\n",
       " 'def experiment_property(prop):\\n    \"\"\"Get a property of the experiment by name.\"\"\"\\n    exp = experiment(session)\\n    p = getattr(exp, prop)\\n    return success_response(field=prop, data=p, request_type=prop)': 5,\n",
       " 'def data_from_file(file):\\n    \"\"\"Return (first channel data, sample frequency, sample width) from a .wav\\n    file.\"\"\"\\n    fp = wave.open(file, \\'r\\')\\n    data = fp.readframes(fp.getnframes())\\n    channels = fp.getnchannels()\\n    freq = fp.getframerate()\\n    bits = fp.getsampwidth()\\n\\n    # Unpack bytes -- warning currently only tested with 16 bit wavefiles. 32\\n    # bit not supported.\\n    data = struct.unpack((\\'%sh\\' % fp.getnframes()) * channels, data)\\n\\n    # Only use first channel\\n    channel1 = []\\n    n = 0\\n    for d in data:\\n        if n % channels == 0:\\n            channel1.append(d)\\n        n += 1\\n    fp.close()\\n    return (channel1, freq, bits)': 6,\n",
       " 'def source_range(start, end, nr_var_dict):\\n    \"\"\"\\n    Given a range of source numbers, as well as a dictionary\\n    containing the numbers of each source, returns a dictionary\\n    containing tuples of the start and end index\\n    for each source variable type.\\n    \"\"\"\\n\\n    return OrderedDict((k, e-s)\\n        for k, (s, e)\\n        in source_range_tuple(start, end, nr_var_dict).iteritems())': 7,\n",
       " 'def timespan(start_time):\\n    \"\"\"Return time in milliseconds from start_time\"\"\"\\n\\n    timespan = datetime.datetime.now() - start_time\\n    timespan_ms = timespan.total_seconds() * 1000\\n    return timespan_ms': 8,\n",
       " 'def _convert_to_array(array_like, dtype):\\n        \"\"\"\\n        Convert Matrix attributes which are array-like or buffer to array.\\n        \"\"\"\\n        if isinstance(array_like, bytes):\\n            return np.frombuffer(array_like, dtype=dtype)\\n        return np.asarray(array_like, dtype=dtype)': 9,\n",
       " 'def get_uniques(l):\\n    \"\"\" Returns a list with no repeated elements.\\n    \"\"\"\\n    result = []\\n\\n    for i in l:\\n        if i not in result:\\n            result.append(i)\\n\\n    return result': 10,\n",
       " 'def interp(x, xp, *args, **kwargs):\\n    \"\"\"Wrap interpolate_1d for deprecated interp.\"\"\"\\n    return interpolate_1d(x, xp, *args, **kwargs)': 11,\n",
       " 'def _array2cstr(arr):\\n    \"\"\" Serializes a numpy array to a compressed base64 string \"\"\"\\n    out = StringIO()\\n    np.save(out, arr)\\n    return b64encode(out.getvalue())': 12,\n",
       " 'def percentile(values, k):\\n    \"\"\"Find the percentile of a list of values.\\n\\n    :param list values: The list of values to find the percentile of\\n    :param int k: The percentile to find\\n    :rtype: float or int\\n\\n    \"\"\"\\n    if not values:\\n        return None\\n    values.sort()\\n    index = (len(values) * (float(k) / 100)) - 1\\n    return values[int(math.ceil(index))]': 13,\n",
       " 'def _string_hash(s):\\n    \"\"\"String hash (djb2) with consistency between py2/py3 and persistency between runs (unlike `hash`).\"\"\"\\n    h = 5381\\n    for c in s:\\n        h = h * 33 + ord(c)\\n    return h': 14,\n",
       " 'def transform_from_rot_trans(R, t):\\n    \"\"\"Transforation matrix from rotation matrix and translation vector.\"\"\"\\n    R = R.reshape(3, 3)\\n    t = t.reshape(3, 1)\\n    return np.vstack((np.hstack([R, t]), [0, 0, 0, 1]))': 15,\n",
       " 'def _encode_bool(name, value, dummy0, dummy1):\\n    \"\"\"Encode a python boolean (True/False).\"\"\"\\n    return b\"\\\\x08\" + name + (value and b\"\\\\x01\" or b\"\\\\x00\")': 16,\n",
       " 'def transform_to_3d(points,normal,z=0):\\n    \"\"\"Project points into 3d from 2d points.\"\"\"\\n    d = np.cross(normal, (0, 0, 1))\\n    M = rotation_matrix(d)\\n    transformed_points = M.dot(points.T).T + z\\n    return transformed_points': 17,\n",
       " 'def _not(condition=None, **kwargs):\\n    \"\"\"\\n    Return the opposite of input condition.\\n\\n    :param condition: condition to process.\\n\\n    :result: not condition.\\n    :rtype: bool\\n    \"\"\"\\n\\n    result = True\\n\\n    if condition is not None:\\n        result = not run(condition, **kwargs)\\n\\n    return result': 18,\n",
       " 'def HttpResponse403(request, template=KEY_AUTH_403_TEMPLATE,\\ncontent=KEY_AUTH_403_CONTENT, content_type=KEY_AUTH_403_CONTENT_TYPE):\\n    \"\"\"\\n    HTTP response for forbidden access (status code 403)\\n    \"\"\"\\n    return AccessFailedResponse(request, template, content, content_type, status=403)': 19,\n",
       " 'def items(self, section_name):\\n        \"\"\":return: list((option, value), ...) pairs of all items in the given section\"\"\"\\n        return [(k, v) for k, v in super(GitConfigParser, self).items(section_name) if k != \\'__name__\\']': 20,\n",
       " 'def mag(z):\\n    \"\"\"Get the magnitude of a vector.\"\"\"\\n    if isinstance(z[0], np.ndarray):\\n        return np.array(list(map(np.linalg.norm, z)))\\n    else:\\n        return np.linalg.norm(z)': 21,\n",
       " 'def config_parser_to_dict(config_parser):\\n    \"\"\"\\n    Convert a ConfigParser to a dictionary.\\n    \"\"\"\\n    response = {}\\n\\n    for section in config_parser.sections():\\n        for option in config_parser.options(section):\\n            response.setdefault(section, {})[option] = config_parser.get(section, option)\\n\\n    return response': 22,\n",
       " 'def __add__(self, other):\\n        \"\"\"Handle the `+` operator.\"\"\"\\n        return self._handle_type(other)(self.value + other.value)': 23,\n",
       " 'def connect_mysql(host, port, user, password, database):\\n    \"\"\"Connect to MySQL with retries.\"\"\"\\n    return pymysql.connect(\\n        host=host, port=port,\\n        user=user, passwd=password,\\n        db=database\\n    )': 24,\n",
       " 'def get_column(self, X, column):\\n        \"\"\"Return a column of the given matrix.\\n\\n        Args:\\n            X: `numpy.ndarray` or `pandas.DataFrame`.\\n            column: `int` or `str`.\\n\\n        Returns:\\n            np.ndarray: Selected column.\\n        \"\"\"\\n        if isinstance(X, pd.DataFrame):\\n            return X[column].values\\n\\n        return X[:, column]': 25,\n",
       " 'def connect(url, username, password):\\n    \"\"\"\\n    Return a connected Bitbucket session\\n    \"\"\"\\n\\n    bb_session = stashy.connect(url, username, password)\\n\\n    logger.info(\\'Connected to: %s as %s\\', url, username)\\n\\n    return bb_session': 26,\n",
       " 'def add_blank_row(self, label):\\n        \"\"\"\\n        Add a blank row with only an index value to self.df.\\n        This is done inplace.\\n        \"\"\"\\n        col_labels = self.df.columns\\n        blank_item = pd.Series({}, index=col_labels, name=label)\\n        # use .loc to add in place (append won\\'t do that)\\n        self.df.loc[blank_item.name] = blank_item\\n        return self.df': 27,\n",
       " 'def teardown(self):\\n        \"\"\"\\n        Stop and remove the container if it exists.\\n        \"\"\"\\n        while self._http_clients:\\n            self._http_clients.pop().close()\\n        if self.created:\\n            self.halt()': 28,\n",
       " 'def dumped(text, level, indent=2):\\n    \"\"\"Put curly brackets round an indented text\"\"\"\\n    return indented(\"{\\\\n%s\\\\n}\" % indented(text, level + 1, indent) or \"None\", level, indent) + \"\\\\n\"': 29,\n",
       " 'def context(self):\\n        \"\"\"\\n        Create a context manager that ensures code runs within action\\'s context.\\n\\n        The action does NOT finish when the context is exited.\\n        \"\"\"\\n        parent = _ACTION_CONTEXT.set(self)\\n        try:\\n            yield self\\n        finally:\\n            _ACTION_CONTEXT.reset(parent)': 30,\n",
       " 'def pformat(object, indent=1, width=80, depth=None):\\n    \"\"\"Format a Python object into a pretty-printed representation.\"\"\"\\n    return PrettyPrinter(indent=indent, width=width, depth=depth).pformat(object)': 31,\n",
       " 'def replace_sys_args(new_args):\\n    \"\"\"Temporarily replace sys.argv with current arguments\\n\\n    Restores sys.argv upon exit of the context manager.\\n    \"\"\"\\n    # Replace sys.argv arguments\\n    # for module import\\n    old_args = sys.argv\\n    sys.argv = new_args\\n    try:\\n        yield\\n    finally:\\n        sys.argv = old_args': 32,\n",
       " 'def serialize(obj):\\n    \"\"\"Takes a object and produces a dict-like representation\\n\\n    :param obj: the object to serialize\\n    \"\"\"\\n    if isinstance(obj, list):\\n        return [serialize(o) for o in obj]\\n    return GenericSerializer(ModelProviderImpl()).serialize(obj)': 33,\n",
       " 'def advance_one_line(self):\\n    \"\"\"Advances to next line.\"\"\"\\n\\n    current_line = self._current_token.line_number\\n    while current_line == self._current_token.line_number:\\n      self._current_token = ConfigParser.Token(*next(self._token_generator))': 34,\n",
       " 'def generate_swagger_html(swagger_static_root, swagger_json_url):\\n    \"\"\"\\n    given a root directory for the swagger statics, and\\n    a swagger json path, return back a swagger html designed\\n    to use those values.\\n    \"\"\"\\n    tmpl = _get_template(\"swagger.html\")\\n    return tmpl.render(\\n        swagger_root=swagger_static_root, swagger_json_url=swagger_json_url\\n    )': 35,\n",
       " 'def do_next(self, args):\\n        \"\"\"Step over the next statement\\n        \"\"\"\\n        self._do_print_from_last_cmd = True\\n        self._interp.step_over()\\n        return True': 36,\n",
       " 'def __add__(self,other):\\n        \"\"\"\\n            If the number of columns matches, we can concatenate two LabeldMatrices\\n            with the + operator.\\n        \"\"\"\\n        assert self.matrix.shape[1] == other.matrix.shape[1]\\n        return LabeledMatrix(np.concatenate([self.matrix,other.matrix],axis=0),self.labels)': 37,\n",
       " 'def get_line_flux(line_wave, wave, flux, **kwargs):\\n    \"\"\"Interpolated flux at a given wavelength (calls np.interp).\"\"\"\\n    return np.interp(line_wave, wave, flux, **kwargs)': 38,\n",
       " 'def send(message, request_context=None, binary=False):\\n    \"\"\"Sends a message to websocket.\\n\\n    :param str message: data to send\\n\\n    :param request_context:\\n\\n    :raises IOError: If unable to send a message.\\n    \"\"\"\\n    if binary:\\n        return uwsgi.websocket_send_binary(message, request_context)\\n\\n    return uwsgi.websocket_send(message, request_context)': 39,\n",
       " 'def get_number(s, cast=int):\\n    \"\"\"\\n    Try to get a number out of a string, and cast it.\\n    \"\"\"\\n    import string\\n    d = \"\".join(x for x in str(s) if x in string.digits)\\n    return cast(d)': 40,\n",
       " 'def get_hline():\\n    \"\"\" gets a horiztonal line \"\"\"\\n    return Window(\\n        width=LayoutDimension.exact(1),\\n        height=LayoutDimension.exact(1),\\n        content=FillControl(\\'-\\', token=Token.Line))': 41,\n",
       " 'def parse_cookies_str(cookies):\\n    \"\"\"\\n    parse cookies str to dict\\n    :param cookies: cookies str\\n    :type cookies: str\\n    :return: cookie dict\\n    :rtype: dict\\n    \"\"\"\\n    cookie_dict = {}\\n    for record in cookies.split(\";\"):\\n        key, value = record.strip().split(\"=\", 1)\\n        cookie_dict[key] = value\\n    return cookie_dict': 42,\n",
       " 'def to_snake_case(name):\\n    \"\"\" Given a name in camelCase return in snake_case \"\"\"\\n    s1 = FIRST_CAP_REGEX.sub(r\\'\\\\1_\\\\2\\', name)\\n    return ALL_CAP_REGEX.sub(r\\'\\\\1_\\\\2\\', s1).lower()': 43,\n",
       " 'def populate_obj(obj, attrs):\\n    \"\"\"Populates an object\\'s attributes using the provided dict\\n    \"\"\"\\n    for k, v in attrs.iteritems():\\n        setattr(obj, k, v)': 44,\n",
       " 'def wordfreq(text, is_filename=False):\\n    \"\"\"Return a dictionary of words and word counts in a string.\"\"\"\\n    if is_filename:\\n        with open(text) as f:\\n            text = f.read()\\n    freqs = {}\\n    for word in text.split():\\n        lword = word.lower()\\n        freqs[lword] = freqs.get(lword, 0) + 1\\n    return freqs': 45,\n",
       " 'def copyFile(input, output, replace=None):\\n    \"\"\"Copy a file whole from input to output.\"\"\"\\n\\n    _found = findFile(output)\\n    if not _found or (_found and replace):\\n        shutil.copy2(input, output)': 46,\n",
       " 'def push(h, x):\\n    \"\"\"Push a new value into heap.\"\"\"\\n    h.push(x)\\n    up(h, h.size()-1)': 47,\n",
       " 'def yank(event):\\n    \"\"\"\\n    Paste before cursor.\\n    \"\"\"\\n    event.current_buffer.paste_clipboard_data(\\n        event.cli.clipboard.get_data(), count=event.arg, paste_mode=PasteMode.EMACS)': 48,\n",
       " 'def filter_contour(imageFile, opFile):\\n    \"\"\" convert an image by applying a contour \"\"\"\\n    im = Image.open(imageFile)\\n    im1 = im.filter(ImageFilter.CONTOUR)\\n    im1.save(opFile)': 49,\n",
       " 'def count(lines):\\n  \"\"\" Counts the word frequences in a list of sentences.\\n\\n  Note:\\n    This is a helper function for parallel execution of `Vocabulary.from_text`\\n    method.\\n  \"\"\"\\n  words = [w for l in lines for w in l.strip().split()]\\n  return Counter(words)': 50,\n",
       " 'def dictapply(d, fn):\\n    \"\"\"\\n    apply a function to all non-dict values in a dictionary\\n    \"\"\"\\n    for k, v in d.items():\\n        if isinstance(v, dict):\\n            v = dictapply(v, fn)\\n        else:\\n            d[k] = fn(v)\\n    return d': 51,\n",
       " 'def count_replica(self, partition):\\n        \"\"\"Return count of replicas of given partition.\"\"\"\\n        return sum(1 for b in partition.replicas if b in self.brokers)': 52,\n",
       " 'def visit_Name(self, node):\\n        \"\"\" Get range for parameters for examples or false branching. \"\"\"\\n        return self.add(node, self.result[node.id])': 53,\n",
       " 'def mkdir(dir, enter):\\n    \"\"\"Create directory with template for topic of the current environment\\n\\n    \"\"\"\\n\\n    if not os.path.exists(dir):\\n        os.makedirs(dir)': 54,\n",
       " 'def qrot(vector, quaternion):\\n    \"\"\"Rotate a 3D vector using quaternion algebra.\\n\\n    Implemented by Vladimir Kulikovskiy.\\n\\n    Parameters\\n    ----------\\n    vector: np.array\\n    quaternion: np.array\\n\\n    Returns\\n    -------\\n    np.array\\n\\n    \"\"\"\\n    t = 2 * np.cross(quaternion[1:], vector)\\n    v_rot = vector + quaternion[0] * t + np.cross(quaternion[1:], t)\\n    return v_rot': 55,\n",
       " 'def _numpy_char_to_bytes(arr):\\n    \"\"\"Like netCDF4.chartostring, but faster and more flexible.\\n    \"\"\"\\n    # based on: http://stackoverflow.com/a/10984878/809705\\n    arr = np.array(arr, copy=False, order=\\'C\\')\\n    dtype = \\'S\\' + str(arr.shape[-1])\\n    return arr.view(dtype).reshape(arr.shape[:-1])': 56,\n",
       " 'def csv_to_dicts(file, header=None):\\n    \"\"\"Reads a csv and returns a List of Dicts with keys given by header row.\"\"\"\\n    with open(file) as csvfile:\\n        return [row for row in csv.DictReader(csvfile, fieldnames=header)]': 57,\n",
       " 'def get_tri_area(pts):\\n    \"\"\"\\n    Given a list of coords for 3 points,\\n    Compute the area of this triangle.\\n\\n    Args:\\n        pts: [a, b, c] three points\\n    \"\"\"\\n    a, b, c = pts[0], pts[1], pts[2]\\n    v1 = np.array(b) - np.array(a)\\n    v2 = np.array(c) - np.array(a)\\n    area_tri = abs(sp.linalg.norm(sp.cross(v1, v2)) / 2)\\n    return area_tri': 58,\n",
       " 'def one_hot(x, size, dtype=np.float32):\\n  \"\"\"Make a n+1 dim one-hot array from n dim int-categorical array.\"\"\"\\n  return np.array(x[..., np.newaxis] == np.arange(size), dtype)': 59,\n",
       " 'def round_to_int(number, precision):\\n    \"\"\"Round a number to a precision\"\"\"\\n    precision = int(precision)\\n    rounded = (int(number) + precision / 2) // precision * precision\\n    return rounded': 60,\n",
       " 'def create_object(cls, members):\\n    \"\"\"Promise an object of class `cls` with content `members`.\"\"\"\\n    obj = cls.__new__(cls)\\n    obj.__dict__ = members\\n    return obj': 61,\n",
       " 'def to_unicode_repr( _letter ):\\n    \"\"\" helpful in situations where browser/app may recognize Unicode encoding\\n        in the \\\\u0b8e type syntax but not actual unicode glyph/code-point\"\"\"\\n    # Python 2-3 compatible\\n    return u\"u\\'\"+ u\"\".join( [ u\"\\\\\\\\u%04x\"%ord(l) for l in _letter ] ) + u\"\\'\"': 62,\n",
       " 'def string_input(prompt=\\'\\'):\\n    \"\"\"Python 3 input()/Python 2 raw_input()\"\"\"\\n    v = sys.version[0]\\n    if v == \\'3\\':\\n        return input(prompt)\\n    else:\\n        return raw_input(prompt)': 63,\n",
       " 'def cfloat64_array_to_numpy(cptr, length):\\n    \"\"\"Convert a ctypes double pointer array to a numpy array.\"\"\"\\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_double)):\\n        return np.fromiter(cptr, dtype=np.float64, count=length)\\n    else:\\n        raise RuntimeError(\\'Expected double pointer\\')': 64,\n",
       " 'def yn_prompt(msg, default=True):\\n    \"\"\"\\n    Prompts the user for yes or no.\\n    \"\"\"\\n    ret = custom_prompt(msg, [\"y\", \"n\"], \"y\" if default else \"n\")\\n    if ret == \"y\":\\n        return True\\n    return False': 65,\n",
       " 'def _display(self, layout):\\n        \"\"\"launch layouts display\"\"\"\\n        print(file=self.out)\\n        TextWriter().format(layout, self.out)': 66,\n",
       " 'def assert_list(self, putative_list, expected_type=string_types, key_arg=None):\\n    \"\"\"\\n    :API: public\\n    \"\"\"\\n    return assert_list(putative_list, expected_type, key_arg=key_arg,\\n                       raise_type=lambda msg: TargetDefinitionException(self, msg))': 67,\n",
       " 'def _xxrange(self, start, end, step_count):\\n        \"\"\"Generate n values between start and end.\"\"\"\\n        _step = (end - start) / float(step_count)\\n        return (start + (i * _step) for i in xrange(int(step_count)))': 68,\n",
       " 'def assert_exactly_one_true(bool_list):\\n    \"\"\"This method asserts that only one value of the provided list is True.\\n\\n    :param bool_list: List of booleans to check\\n    :return: True if only one value is True, False otherwise\\n    \"\"\"\\n    assert isinstance(bool_list, list)\\n    counter = 0\\n    for item in bool_list:\\n        if item:\\n            counter += 1\\n    return counter == 1': 69,\n",
       " 'def _get_random_id():\\n    \"\"\" Get a random (i.e., unique) string identifier\"\"\"\\n    symbols = string.ascii_uppercase + string.ascii_lowercase + string.digits\\n    return \\'\\'.join(random.choice(symbols) for _ in range(15))': 70,\n",
       " 'async def list(source):\\n    \"\"\"Generate a single list from an asynchronous sequence.\"\"\"\\n    result = []\\n    async with streamcontext(source) as streamer:\\n        async for item in streamer:\\n            result.append(item)\\n    yield result': 71,\n",
       " 'def _attrprint(d, delimiter=\\', \\'):\\n    \"\"\"Print a dictionary of attributes in the DOT format\"\"\"\\n    return delimiter.join((\\'\"%s\"=\"%s\"\\' % item) for item in sorted(d.items()))': 72,\n",
       " 'def get_next_scheduled_time(cron_string):\\n    \"\"\"Calculate the next scheduled time by creating a crontab object\\n    with a cron string\"\"\"\\n    itr = croniter.croniter(cron_string, datetime.utcnow())\\n    return itr.get_next(datetime)': 73,\n",
       " 'def exit(exit_code=0):\\n  r\"\"\"A function to support exiting from exit hooks.\\n\\n  Could also be used to exit from the calling scripts in a thread safe manner.\\n  \"\"\"\\n  core.processExitHooks()\\n\\n  if state.isExitHooked and not hasattr(sys, \\'exitfunc\\'): # The function is called from the exit hook\\n    sys.stderr.flush()\\n    sys.stdout.flush()\\n    os._exit(exit_code) #pylint: disable=W0212\\n\\n  sys.exit(exit_code)': 74,\n",
       " 'def dot_product(self, other):\\n        \"\"\" Return the dot product of the given vectors. \"\"\"\\n        return self.x * other.x + self.y * other.y': 75,\n",
       " 'def reloader_thread(softexit=False):\\n    \"\"\"If ``soft_exit`` is True, we use sys.exit(); otherwise ``os_exit``\\n    will be used to end the process.\\n    \"\"\"\\n    while RUN_RELOADER:\\n        if code_changed():\\n            # force reload\\n            if softexit:\\n                sys.exit(3)\\n            else:\\n                os._exit(3)\\n        time.sleep(1)': 76,\n",
       " 'def list_to_csv(value):\\n    \"\"\"\\n    Converts list to string with comma separated values. For string is no-op.\\n    \"\"\"\\n    if isinstance(value, (list, tuple, set)):\\n        value = \",\".join(value)\\n    return value': 77,\n",
       " 'def average(iterator):\\n    \"\"\"Iterative mean.\"\"\"\\n    count = 0\\n    total = 0\\n    for num in iterator:\\n        count += 1\\n        total += num\\n    return float(total)/count': 78,\n",
       " 'def cint32_array_to_numpy(cptr, length):\\n    \"\"\"Convert a ctypes int pointer array to a numpy array.\"\"\"\\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_int32)):\\n        return np.fromiter(cptr, dtype=np.int32, count=length)\\n    else:\\n        raise RuntimeError(\\'Expected int pointer\\')': 79,\n",
       " 'def _aws_get_instance_by_tag(region, name, tag, raw):\\n    \"\"\"Get all instances matching a tag.\"\"\"\\n    client = boto3.session.Session().client(\\'ec2\\', region)\\n    matching_reservations = client.describe_instances(Filters=[{\\'Name\\': tag, \\'Values\\': [name]}]).get(\\'Reservations\\', [])\\n    instances = []\\n    [[instances.append(_aws_instance_from_dict(region, instance, raw))  # pylint: disable=expression-not-assigned\\n      for instance in reservation.get(\\'Instances\\')] for reservation in matching_reservations if reservation]\\n    return instances': 80,\n",
       " 'def loganalytics_data_plane_client(cli_ctx, _):\\n    \"\"\"Initialize Log Analytics data client for use with CLI.\"\"\"\\n    from .vendored_sdks.loganalytics import LogAnalyticsDataClient\\n    from azure.cli.core._profile import Profile\\n    profile = Profile(cli_ctx=cli_ctx)\\n    cred, _, _ = profile.get_login_credentials(\\n        resource=\"https://api.loganalytics.io\")\\n    return LogAnalyticsDataClient(cred)': 81,\n",
       " 'def cfloat32_array_to_numpy(cptr, length):\\n    \"\"\"Convert a ctypes float pointer array to a numpy array.\"\"\"\\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_float)):\\n        return np.fromiter(cptr, dtype=np.float32, count=length)\\n    else:\\n        raise RuntimeError(\\'Expected float pointer\\')': 82,\n",
       " 'def underscore(text):\\n    \"\"\"Converts text that may be camelcased into an underscored format\"\"\"\\n    return UNDERSCORE[1].sub(r\\'\\\\1_\\\\2\\', UNDERSCORE[0].sub(r\\'\\\\1_\\\\2\\', text)).lower()': 83,\n",
       " 'def cint8_array_to_numpy(cptr, length):\\n    \"\"\"Convert a ctypes int pointer array to a numpy array.\"\"\"\\n    if isinstance(cptr, ctypes.POINTER(ctypes.c_int8)):\\n        return np.fromiter(cptr, dtype=np.int8, count=length)\\n    else:\\n        raise RuntimeError(\\'Expected int pointer\\')': 84,\n",
       " 'def get_stoplist(language):\\n    \"\"\"Returns an built-in stop-list for the language as a set of words.\"\"\"\\n    file_path = os.path.join(\"stoplists\", \"%s.txt\" % language)\\n    try:\\n        stopwords = pkgutil.get_data(\"justext\", file_path)\\n    except IOError:\\n        raise ValueError(\\n            \"Stoplist for language \\'%s\\' is missing. \"\\n            \"Please use function \\'get_stoplists\\' for complete list of stoplists \"\\n            \"and feel free to contribute by your own stoplist.\" % language\\n        )\\n\\n    return frozenset(w.decode(\"utf8\").lower() for w in stopwords.splitlines())': 85,\n",
       " 'def add_str(window, line_num, str):\\n    \"\"\" attempt to draw str on screen and ignore errors if they occur \"\"\"\\n    try:\\n        window.addstr(line_num, 0, str)\\n    except curses.error:\\n        pass': 86,\n",
       " 'def relative_path(path):\\n    \"\"\"\\n    Return the given path relative to this file.\\n    \"\"\"\\n    return os.path.join(os.path.dirname(__file__), path)': 87,\n",
       " 'def dictfetchall(cursor):\\n    \"\"\"Returns all rows from a cursor as a dict (rather than a headerless table)\\n\\n    From Django Documentation: https://docs.djangoproject.com/en/dev/topics/db/sql/\\n    \"\"\"\\n    desc = cursor.description\\n    return [dict(zip([col[0] for col in desc], row)) for row in cursor.fetchall()]': 88,\n",
       " 'def xmltreefromfile(filename):\\n    \"\"\"Internal function to read an XML file\"\"\"\\n    try:\\n        return ElementTree.parse(filename, ElementTree.XMLParser(collect_ids=False))\\n    except TypeError:\\n        return ElementTree.parse(filename, ElementTree.XMLParser())': 89,\n",
       " 'def _dictfetchall(self, cursor):\\n        \"\"\" Return all rows from a cursor as a dict. \"\"\"\\n        columns = [col[0] for col in cursor.description]\\n        return [\\n            dict(zip(columns, row))\\n            for row in cursor.fetchall()\\n        ]': 90,\n",
       " 'def beta_pdf(x, a, b):\\n  \"\"\"Beta distirbution probability density function.\"\"\"\\n  bc = 1 / beta(a, b)\\n  fc = x ** (a - 1)\\n  sc = (1 - x) ** (b - 1)\\n  return bc * fc * sc': 91,\n",
       " 'def filter_out(queryset, setting_name):\\n  \"\"\"\\n  Remove unwanted results from queryset\\n  \"\"\"\\n  kwargs = helpers.get_settings().get(setting_name, {}).get(\\'FILTER_OUT\\', {})\\n  queryset = queryset.exclude(**kwargs)\\n  return queryset': 92,\n",
       " 'def intToBin(i):\\n    \"\"\" Integer to two bytes \"\"\"\\n    # divide in two parts (bytes)\\n    i1 = i % 256\\n    i2 = int(i / 256)\\n    # make string (little endian)\\n    return i.to_bytes(2, byteorder=\\'little\\')': 93,\n",
       " 'def listlike(obj):\\n    \"\"\"Is an object iterable like a list (and not a string)?\"\"\"\\n    \\n    return hasattr(obj, \"__iter__\") \\\\\\n    and not issubclass(type(obj), str)\\\\\\n    and not issubclass(type(obj), unicode)': 94,\n",
       " 'def table_top_abs(self):\\n        \"\"\"Returns the absolute position of table top\"\"\"\\n        table_height = np.array([0, 0, self.table_full_size[2]])\\n        return string_to_array(self.floor.get(\"pos\")) + table_height': 95,\n",
       " 'def pdf(x, mu, std):\\n    \"\"\"Probability density function (normal distribution)\"\"\"\\n    return (1.0 / (std * sqrt(2 * pi))) * np.exp(-(x - mu) ** 2 / (2 * std ** 2))': 96,\n",
       " 'def bytes_to_c_array(data):\\n    \"\"\"\\n    Make a C array using the given string.\\n    \"\"\"\\n    chars = [\\n        \"\\'{}\\'\".format(encode_escape(i))\\n        for i in decode_escape(data)\\n    ]\\n    return \\', \\'.join(chars) + \\', 0\\'': 97,\n",
       " 'def gray2bgr(img):\\n    \"\"\"Convert a grayscale image to BGR image.\\n\\n    Args:\\n        img (ndarray or str): The input image.\\n\\n    Returns:\\n        ndarray: The converted BGR image.\\n    \"\"\"\\n    img = img[..., None] if img.ndim == 2 else img\\n    out_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\\n    return out_img': 98,\n",
       " 'def mean_date(dt_list):\\n    \"\"\"Calcuate mean datetime from datetime list\\n    \"\"\"\\n    dt_list_sort = sorted(dt_list)\\n    dt_list_sort_rel = [dt - dt_list_sort[0] for dt in dt_list_sort]\\n    avg_timedelta = sum(dt_list_sort_rel, timedelta())/len(dt_list_sort_rel)\\n    return dt_list_sort[0] + avg_timedelta': 99,\n",
       " 'def rotate_img(im, deg, mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_AREA):\\n    \"\"\" Rotates an image by deg degrees\\n\\n    Arguments:\\n        deg (float): degree to rotate.\\n    \"\"\"\\n    r,c,*_ = im.shape\\n    M = cv2.getRotationMatrix2D((c//2,r//2),deg,1)\\n    return cv2.warpAffine(im,M,(c,r), borderMode=mode, flags=cv2.WARP_FILL_OUTLIERS+interpolation)': 100,\n",
       " 'def similarity(self, other):\\n        \"\"\"Calculates the cosine similarity between this vector and another\\n        vector.\"\"\"\\n        if self.magnitude == 0 or other.magnitude == 0:\\n            return 0\\n\\n        return self.dot(other) / self.magnitude': 101,\n",
       " 'def _calculate_distance(latlon1, latlon2):\\n    \"\"\"Calculates the distance between two points on earth.\\n    \"\"\"\\n    lat1, lon1 = latlon1\\n    lat2, lon2 = latlon2\\n    dlon = lon2 - lon1\\n    dlat = lat2 - lat1\\n    R = 6371  # radius of the earth in kilometers\\n    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * (np.sin(dlon / 2))**2\\n    c = 2 * np.pi * R * np.arctan2(np.sqrt(a), np.sqrt(1 - a)) / 180\\n    return c': 102,\n",
       " 'def screen_cv2(self):\\n        \"\"\"cv2 Image of current window screen\"\"\"\\n        pil_image = self.screen.convert(\\'RGB\\')\\n        cv2_image = np.array(pil_image)\\n        pil_image.close()\\n        # Convert RGB to BGR \\n        cv2_image = cv2_image[:, :, ::-1]\\n        return cv2_image': 103,\n",
       " 'def direct2dDistance(self, point):\\n        \"\"\"consider the distance between two mapPoints, ignoring all terrain, pathing issues\"\"\"\\n        if not isinstance(point, MapPoint): return 0.0\\n        return  ((self.x-point.x)**2 + (self.y-point.y)**2)**(0.5) # simple distance formula': 104,\n",
       " 'def _model_unique(ins):\\n    \"\"\" Get unique constraints info\\n\\n    :type ins: sqlalchemy.orm.mapper.Mapper\\n    :rtype: list[tuple[str]]\\n    \"\"\"\\n    unique = []\\n    for t in ins.tables:\\n        for c in t.constraints:\\n            if isinstance(c, UniqueConstraint):\\n                unique.append(tuple(col.key for col in c.columns))\\n    return unique': 105,\n",
       " 'def horz_dpi(self):\\n        \"\"\"\\n        Integer dots per inch for the width of this image. Defaults to 72\\n        when not present in the file, as is often the case.\\n        \"\"\"\\n        pHYs = self._chunks.pHYs\\n        if pHYs is None:\\n            return 72\\n        return self._dpi(pHYs.units_specifier, pHYs.horz_px_per_unit)': 106,\n",
       " 'def parse(self, s):\\n        \"\"\"\\n        Parses a date string formatted like ``YYYY-MM-DD``.\\n        \"\"\"\\n        return datetime.datetime.strptime(s, self.date_format).date()': 107,\n",
       " 'def estimate_complexity(self, x,y,z,n):\\n        \"\"\" \\n        calculates a rough guess of runtime based on product of parameters \\n        \"\"\"\\n        num_calculations = x * y * z * n\\n        run_time = num_calculations / 100000  # a 2014 PC does about 100k calcs in a second (guess based on prior logs)\\n        return self.show_time_as_short_string(run_time)': 108,\n",
       " 'def weekly(date=datetime.date.today()):\\n    \"\"\"\\n    Weeks start are fixes at Monday for now.\\n    \"\"\"\\n    return date - datetime.timedelta(days=date.weekday())': 109,\n",
       " 'def inh(table):\\n    \"\"\"\\n    inverse hyperbolic sine transformation\\n    \"\"\"\\n    t = []\\n    for i in table:\\n        t.append(np.ndarray.tolist(np.arcsinh(i)))\\n    return t': 110,\n",
       " 'def daterange(start, end, delta=timedelta(days=1), lower=Interval.CLOSED, upper=Interval.OPEN):\\n    \"\"\"Returns a generator which creates the next value in the range on demand\"\"\"\\n    date_interval = Interval(lower=lower, lower_value=start, upper_value=end, upper=upper)\\n    current = start if start in date_interval else start + delta\\n    while current in date_interval:\\n        yield current\\n        current = current + delta': 111,\n",
       " 'async def _thread_coro(self, *args):\\n        \"\"\" Coroutine called by MapAsync. It\\'s wrapping the call of\\n        run_in_executor to run the synchronous function as thread \"\"\"\\n        return await self._loop.run_in_executor(\\n            self._executor, self._function, *args)': 112,\n",
       " 'def start_of_month(val):\\n    \"\"\"\\n    Return a new datetime.datetime object with values that represent\\n    a start of a month.\\n    :param val: Date to ...\\n    :type val: datetime.datetime | datetime.date\\n    :rtype: datetime.datetime\\n    \"\"\"\\n    if type(val) == date:\\n        val = datetime.fromordinal(val.toordinal())\\n    return start_of_day(val).replace(day=1)': 113,\n",
       " 'def check_output(args, env=None, sp=subprocess):\\n    \"\"\"Call an external binary and return its stdout.\"\"\"\\n    log.debug(\\'calling %s with env %s\\', args, env)\\n    output = sp.check_output(args=args, env=env)\\n    log.debug(\\'output: %r\\', output)\\n    return output': 114,\n",
       " 'def datetime_to_ms(dt):\\n    \"\"\"\\n    Converts a datetime to a millisecond accuracy timestamp\\n    \"\"\"\\n    seconds = calendar.timegm(dt.utctimetuple())\\n    return seconds * 1000 + int(dt.microsecond / 1000)': 115,\n",
       " 'def retry_on_signal(function):\\n    \"\"\"Retries function until it doesn\\'t raise an EINTR error\"\"\"\\n    while True:\\n        try:\\n            return function()\\n        except EnvironmentError, e:\\n            if e.errno != errno.EINTR:\\n                raise': 116,\n",
       " 'def datetime_to_timezone(date, tz=\"UTC\"):\\n    \"\"\" convert naive datetime to timezone-aware datetime \"\"\"\\n    if not date.tzinfo:\\n        date = date.replace(tzinfo=timezone(get_timezone()))\\n    return date.astimezone(timezone(tz))': 117,\n",
       " 'def test(*args):\\n    \"\"\"\\n    Run unit tests.\\n    \"\"\"\\n    subprocess.call([\"py.test-2.7\"] + list(args))\\n    subprocess.call([\"py.test-3.4\"] + list(args))': 118,\n",
       " 'def ToDatetime(self):\\n    \"\"\"Converts Timestamp to datetime.\"\"\"\\n    return datetime.utcfromtimestamp(\\n        self.seconds + self.nanos / float(_NANOS_PER_SECOND))': 119,\n",
       " 'def sortable_title(instance):\\n    \"\"\"Uses the default Plone sortable_text index lower-case\\n    \"\"\"\\n    title = plone_sortable_title(instance)\\n    if safe_callable(title):\\n        title = title()\\n    return title.lower()': 120,\n",
       " 'def localize(dt):\\n    \"\"\"Localize a datetime object to local time.\"\"\"\\n    if dt.tzinfo is UTC:\\n        return (dt + LOCAL_UTC_OFFSET).replace(tzinfo=None)\\n    # No TZ info so not going to assume anything, return as-is.\\n    return dt': 121,\n",
       " 'def percent_cb(name, complete, total):\\n    \"\"\" Callback for updating target progress \"\"\"\\n    logger.debug(\\n        \"{}: {} transferred out of {}\".format(\\n            name, sizeof_fmt(complete), sizeof_fmt(total)\\n        )\\n    )\\n    progress.update_target(name, complete, total)': 122,\n",
       " 'def now(self):\\n\\t\\t\"\"\"\\n\\t\\tReturn a :py:class:`datetime.datetime` instance representing the current time.\\n\\n\\t\\t:rtype: :py:class:`datetime.datetime`\\n\\t\\t\"\"\"\\n\\t\\tif self.use_utc:\\n\\t\\t\\treturn datetime.datetime.utcnow()\\n\\t\\telse:\\n\\t\\t\\treturn datetime.datetime.now()': 123,\n",
       " 'def to_pascal_case(s):\\n    \"\"\"Transform underscore separated string to pascal case\\n\\n    \"\"\"\\n    return re.sub(r\\'(?!^)_([a-zA-Z])\\', lambda m: m.group(1).upper(), s.capitalize())': 124,\n",
       " 'def _convert_date_to_dict(field_date):\\n        \"\"\"\\n        Convert native python ``datetime.date`` object  to a format supported by the API\\n        \"\"\"\\n        return {DAY: field_date.day, MONTH: field_date.month, YEAR: field_date.year}': 125,\n",
       " 'def convert_array(array):\\n    \"\"\"\\n    Converts an ARRAY string stored in the database back into a Numpy array.\\n\\n    Parameters\\n    ----------\\n    array: ARRAY\\n        The array object to be converted back into a Numpy array.\\n\\n    Returns\\n    -------\\n    array\\n            The converted Numpy array.\\n\\n    \"\"\"\\n    out = io.BytesIO(array)\\n    out.seek(0)\\n    return np.load(out)': 126,\n",
       " 'def parse_timestamp(timestamp):\\n    \"\"\"Parse ISO8601 timestamps given by github API.\"\"\"\\n    dt = dateutil.parser.parse(timestamp)\\n    return dt.astimezone(dateutil.tz.tzutc())': 127,\n",
       " 'def add_to_js(self, name, var):\\n        \"\"\"Add an object to Javascript.\"\"\"\\n        frame = self.page().mainFrame()\\n        frame.addToJavaScriptWindowObject(name, var)': 128,\n",
       " 'def fromtimestamp(cls, timestamp):\\n    \"\"\"Returns a datetime object of a given timestamp (in local tz).\"\"\"\\n    d = cls.utcfromtimestamp(timestamp)\\n    return d.astimezone(localtz())': 129,\n",
       " 'def print_latex(o):\\n    \"\"\"A function to generate the latex representation of sympy\\n    expressions.\"\"\"\\n    if can_print_latex(o):\\n        s = latex(o, mode=\\'plain\\')\\n        s = s.replace(\\'\\\\\\\\dag\\',\\'\\\\\\\\dagger\\')\\n        s = s.strip(\\'$\\')\\n        return \\'$$%s$$\\' % s\\n    # Fallback to the string printer\\n    return None': 130,\n",
       " 'def datetime64_to_datetime(dt):\\n    \"\"\" convert numpy\\'s datetime64 to datetime \"\"\"\\n    dt64 = np.datetime64(dt)\\n    ts = (dt64 - np.datetime64(\\'1970-01-01T00:00:00\\')) / np.timedelta64(1, \\'s\\')\\n    return datetime.datetime.utcfromtimestamp(ts)': 131,\n",
       " 'def batch_tensor(self, name):\\n        \"\"\" A buffer of a given value in a \\'flat\\' (minibatch-indexed) format \"\"\"\\n        if name in self.transition_tensors:\\n            return tensor_util.merge_first_two_dims(self.transition_tensors[name])\\n        else:\\n            return self.rollout_tensors[name]': 132,\n",
       " 'def isInteractive():\\n    \"\"\"\\n    A basic check of if the program is running in interactive mode\\n    \"\"\"\\n    if sys.stdout.isatty() and os.name != \\'nt\\':\\n        #Hopefully everything but ms supports \\'\\\\r\\'\\n        try:\\n            import threading\\n        except ImportError:\\n            return False\\n        else:\\n            return True\\n    else:\\n        return False': 133,\n",
       " 'def create_symlink(source, link_name):\\n    \"\"\"\\n    Creates symbolic link for either operating system.\\n\\n    http://stackoverflow.com/questions/6260149/os-symlink-support-in-windows\\n    \"\"\"\\n    os_symlink = getattr(os, \"symlink\", None)\\n    if isinstance(os_symlink, collections.Callable):\\n        os_symlink(source, link_name)\\n    else:\\n        import ctypes\\n        csl = ctypes.windll.kernel32.CreateSymbolicLinkW\\n        csl.argtypes = (ctypes.c_wchar_p, ctypes.c_wchar_p, ctypes.c_uint32)\\n        csl.restype = ctypes.c_ubyte\\n        flags = 1 if os.path.isdir(source) else 0\\n        if csl(link_name, source, flags) == 0:\\n            raise ctypes.WinError()': 134,\n",
       " 'def export(defn):\\n    \"\"\"Decorator to explicitly mark functions that are exposed in a lib.\"\"\"\\n    globals()[defn.__name__] = defn\\n    __all__.append(defn.__name__)\\n    return defn': 135,\n",
       " 'def parse(source, remove_comments=True, **kw):\\n    \"\"\"Thin wrapper around ElementTree.parse\"\"\"\\n    return ElementTree.parse(source, SourceLineParser(), **kw)': 136,\n",
       " 'def decorator(func):\\n  r\"\"\"Makes the passed decorators to support optional args.\\n  \"\"\"\\n  def wrapper(__decorated__=None, *Args, **KwArgs):\\n    if __decorated__ is None: # the decorator has some optional arguments.\\n      return lambda _func: func(_func, *Args, **KwArgs)\\n\\n    else:\\n      return func(__decorated__, *Args, **KwArgs)\\n\\n  return wrap(wrapper, func)': 137,\n",
       " 'def show_image(self, key):\\n        \"\"\"Show image (item is a PIL image)\"\"\"\\n        data = self.model.get_data()\\n        data[key].show()': 138,\n",
       " 'def get_default_args(func):\\n    \"\"\"\\n    returns a dictionary of arg_name:default_values for the input function\\n    \"\"\"\\n    args, varargs, keywords, defaults = getargspec_no_self(func)\\n    return dict(zip(args[-len(defaults):], defaults))': 139,\n",
       " 'def _interval_to_bound_points(array):\\n    \"\"\"\\n    Helper function which returns an array\\n    with the Intervals\\' boundaries.\\n    \"\"\"\\n\\n    array_boundaries = np.array([x.left for x in array])\\n    array_boundaries = np.concatenate(\\n        (array_boundaries, np.array([array[-1].right])))\\n\\n    return array_boundaries': 140,\n",
       " 'def closing_plugin(self, cancelable=False):\\n        \"\"\"Perform actions before parent main window is closed\"\"\"\\n        self.dialog_manager.close_all()\\n        self.shell.exit_interpreter()\\n        return True': 141,\n",
       " 'def test():        \\n    \"\"\"Local test.\"\"\"\\n    from spyder.utils.qthelpers import qapplication\\n    app = qapplication()\\n    dlg = ProjectDialog(None)\\n    dlg.show()\\n    sys.exit(app.exec_())': 142,\n",
       " 'def del_label(self, name):\\n        \"\"\"Delete a label by name.\"\"\"\\n        labels_tag = self.root[0]\\n        labels_tag.remove(self._find_label(name))': 143,\n",
       " 'def mixedcase(path):\\n    \"\"\"Removes underscores and capitalizes the neighbouring character\"\"\"\\n    words = path.split(\\'_\\')\\n    return words[0] + \\'\\'.join(word.title() for word in words[1:])': 144,\n",
       " 'def delete_all_eggs(self):\\n        \"\"\" delete all the eggs in the directory specified \"\"\"\\n        path_to_delete = os.path.join(self.egg_directory, \"lib\", \"python\")\\n        if os.path.exists(path_to_delete):\\n            shutil.rmtree(path_to_delete)': 145,\n",
       " 'def get_system_cpu_times():\\n    \"\"\"Return system CPU times as a namedtuple.\"\"\"\\n    user, nice, system, idle = _psutil_osx.get_system_cpu_times()\\n    return _cputimes_ntuple(user, nice, system, idle)': 146,\n",
       " 'def remove(self, document_id, namespace, timestamp):\\n        \"\"\"Removes documents from Solr\\n\\n        The input is a python dictionary that represents a mongo document.\\n        \"\"\"\\n        self.solr.delete(id=u(document_id),\\n                         commit=(self.auto_commit_interval == 0))': 147,\n",
       " 'def update_hash_from_str(hsh, str_input):\\n    \"\"\"\\n    Convert a str to object supporting buffer API and update a hash with it.\\n    \"\"\"\\n    byte_input = str(str_input).encode(\"UTF-8\")\\n    hsh.update(byte_input)': 148,\n",
       " 'def make_regex(separator):\\n    \"\"\"Utility function to create regexp for matching escaped separators\\n    in strings.\\n\\n    \"\"\"\\n    return re.compile(r\\'(?:\\' + re.escape(separator) + r\\')?((?:[^\\' +\\n                      re.escape(separator) + r\\'\\\\\\\\]|\\\\\\\\.)+)\\')': 149,\n",
       " 'def dictify(a_named_tuple):\\n    \"\"\"Transform a named tuple into a dictionary\"\"\"\\n    return dict((s, getattr(a_named_tuple, s)) for s in a_named_tuple._fields)': 150,\n",
       " 'def _py2_and_3_joiner(sep, joinable):\\n    \"\"\"\\n    Allow \\'\\\\n\\'.join(...) statements to work in Py2 and Py3.\\n    :param sep:\\n    :param joinable:\\n    :return:\\n    \"\"\"\\n    if ISPY3:\\n        sep = bytes(sep, DEFAULT_ENCODING)\\n    joined = sep.join(joinable)\\n    return joined.decode(DEFAULT_ENCODING) if ISPY3 else joined': 151,\n",
       " 'def c_str(string):\\n    \"\"\"\"Convert a python string to C string.\"\"\"\\n    if not isinstance(string, str):\\n        string = string.decode(\\'ascii\\')\\n    return ctypes.c_char_p(string.encode(\\'utf-8\\'))': 152,\n",
       " 'def endline_semicolon_check(self, original, loc, tokens):\\n        \"\"\"Check for semicolons at the end of lines.\"\"\"\\n        return self.check_strict(\"semicolon at end of line\", original, loc, tokens)': 153,\n",
       " 'def _datetime_to_date(arg):\\n    \"\"\"\\n    convert datetime/str to date\\n    :param arg:\\n    :return:\\n    \"\"\"\\n    _arg = parse(arg)\\n    if isinstance(_arg, datetime.datetime):\\n        _arg = _arg.date()\\n    return _arg': 154,\n",
       " 'def get(self):\\n        \"\"\"Get the highest priority Processing Block from the queue.\"\"\"\\n        with self._mutex:\\n            entry = self._queue.pop()\\n            del self._block_map[entry[2]]\\n            return entry[2]': 155,\n",
       " 'def center_text(text, width=80):\\n    \"\"\"Center all lines of the text.\\n\\n    It is assumed that all lines width is smaller then B{width}, because the\\n    line width will not be checked.\\n\\n    Args:\\n        text (str): Text to wrap.\\n        width (int): Maximum number of characters per line.\\n\\n    Returns:\\n        str: Centered text.\\n    \"\"\"\\n    centered = []\\n    for line in text.splitlines():\\n        centered.append(line.center(width))\\n    return \"\\\\n\".join(centered)': 156,\n",
       " 'def from_json(cls, json_str):\\n        \"\"\"Deserialize the object from a JSON string.\"\"\"\\n        d = json.loads(json_str)\\n        return cls.from_dict(d)': 157,\n",
       " 'def update(kernel=False):\\n    \"\"\"\\n    Upgrade all packages, skip obsoletes if ``obsoletes=0`` in ``yum.conf``.\\n\\n    Exclude *kernel* upgrades by default.\\n    \"\"\"\\n    manager = MANAGER\\n    cmds = {\\'yum -y --color=never\\': {False: \\'--exclude=kernel* update\\', True: \\'update\\'}}\\n    cmd = cmds[manager][kernel]\\n    run_as_root(\"%(manager)s %(cmd)s\" % locals())': 158,\n",
       " 'def guess_encoding(text, default=DEFAULT_ENCODING):\\n    \"\"\"Guess string encoding.\\n\\n    Given a piece of text, apply character encoding detection to\\n    guess the appropriate encoding of the text.\\n    \"\"\"\\n    result = chardet.detect(text)\\n    return normalize_result(result, default=default)': 159,\n",
       " 'def commajoin_as_strings(iterable):\\n    \"\"\" Join the given iterable with \\',\\' \"\"\"\\n    return _(u\\',\\').join((six.text_type(i) for i in iterable))': 160,\n",
       " 'def supports_color():\\n    \"\"\"\\n    Returns True if the running system\\'s terminal supports color, and False\\n    otherwise.\\n    \"\"\"\\n    unsupported_platform = (sys.platform in (\\'win32\\', \\'Pocket PC\\'))\\n    # isatty is not always implemented, #6223.\\n    is_a_tty = hasattr(sys.stdout, \\'isatty\\') and sys.stdout.isatty()\\n    if unsupported_platform or not is_a_tty:\\n        return False\\n    return True': 161,\n",
       " 'def seconds_to_hms(seconds):\\n    \"\"\"\\n    Converts seconds float to \\'hh:mm:ss.ssssss\\' format.\\n    \"\"\"\\n    hours = int(seconds / 3600.0)\\n    minutes = int((seconds / 60.0) % 60.0)\\n    secs = float(seconds % 60.0)\\n    return \"{0:02d}:{1:02d}:{2:02.6f}\".format(hours, minutes, secs)': 162,\n",
       " 'def __contains__(self, key):\\n        \"\"\"\\n        Invoked when determining whether a specific key is in the dictionary\\n        using `key in d`.\\n\\n        The key is looked up case-insensitively.\\n        \"\"\"\\n        k = self._real_key(key)\\n        return k in self._data': 163,\n",
       " 'def get_truetype(value):\\n    \"\"\"Convert a string to a pythonized parameter.\"\"\"\\n    if value in [\"true\", \"True\", \"y\", \"Y\", \"yes\"]:\\n        return True\\n    if value in [\"false\", \"False\", \"n\", \"N\", \"no\"]:\\n        return False\\n    if value.isdigit():\\n        return int(value)\\n    return str(value)': 164,\n",
       " 'def Serializable(o):\\n    \"\"\"Make sure an object is JSON-serializable\\n    Use this to return errors and other info that does not need to be\\n    deserialized or does not contain important app data. Best for returning\\n    error info and such\"\"\"\\n    if isinstance(o, (str, dict, int)):\\n        return o\\n    else:\\n        try:\\n            json.dumps(o)\\n            return o\\n        except Exception:\\n            LOG.debug(\"Got a non-serilizeable object: %s\" % o)\\n            return o.__repr__()': 165,\n",
       " 'def timed_rotating_file_handler(name, logname, filename, when=\\'h\\',\\n                                interval=1, backupCount=0,\\n                                encoding=None, delay=False, utc=False):\\n    \"\"\"\\n    A Bark logging handler logging output to a named file.  At\\n    intervals specified by the \\'when\\', the file will be rotated, under\\n    control of \\'backupCount\\'.\\n\\n    Similar to logging.handlers.TimedRotatingFileHandler.\\n    \"\"\"\\n\\n    return wrap_log_handler(logging.handlers.TimedRotatingFileHandler(\\n        filename, when=when, interval=interval, backupCount=backupCount,\\n        encoding=encoding, delay=delay, utc=utc))': 166,\n",
       " 'def is_identifier(string):\\n    \"\"\"Check if string could be a valid python identifier\\n\\n    :param string: string to be tested\\n    :returns: True if string can be a python identifier, False otherwise\\n    :rtype: bool\\n    \"\"\"\\n    matched = PYTHON_IDENTIFIER_RE.match(string)\\n    return bool(matched) and not keyword.iskeyword(string)': 167,\n",
       " 'def uniform_iterator(sequence):\\n    \"\"\"Uniform (key, value) iteration on a `dict`,\\n    or (idx, value) on a `list`.\"\"\"\\n\\n    if isinstance(sequence, abc.Mapping):\\n        return six.iteritems(sequence)\\n    else:\\n        return enumerate(sequence)': 168,\n",
       " 'def _guess_type(val):\\n        \"\"\"Guess the input type of the parameter based off the default value, if unknown use text\"\"\"\\n        if isinstance(val, bool):\\n            return \"choice\"\\n        elif isinstance(val, int):\\n            return \"number\"\\n        elif isinstance(val, float):\\n            return \"number\"\\n        elif isinstance(val, str):\\n            return \"text\"\\n        elif hasattr(val, \\'read\\'):\\n            return \"file\"\\n        else:\\n            return \"text\"': 169,\n",
       " 'def _to_corrected_pandas_type(dt):\\n    \"\"\"\\n    When converting Spark SQL records to Pandas DataFrame, the inferred data type may be wrong.\\n    This method gets the corrected data type for Pandas if that type may be inferred uncorrectly.\\n    \"\"\"\\n    import numpy as np\\n    if type(dt) == ByteType:\\n        return np.int8\\n    elif type(dt) == ShortType:\\n        return np.int16\\n    elif type(dt) == IntegerType:\\n        return np.int32\\n    elif type(dt) == FloatType:\\n        return np.float32\\n    else:\\n        return None': 170,\n",
       " 'def _platform_is_windows(platform=sys.platform):\\n        \"\"\"Is the current OS a Windows?\"\"\"\\n        matched = platform in (\\'cygwin\\', \\'win32\\', \\'win64\\')\\n        if matched:\\n            error_msg = \"Windows isn\\'t supported yet\"\\n            raise OSError(error_msg)\\n        return matched': 171,\n",
       " 'def _xls2col_widths(self, worksheet, tab):\\n        \"\"\"Updates col_widths in code_array\"\"\"\\n\\n        for col in xrange(worksheet.ncols):\\n            try:\\n                xls_width = worksheet.colinfo_map[col].width\\n                pys_width = self.xls_width2pys_width(xls_width)\\n                self.code_array.col_widths[col, tab] = pys_width\\n\\n            except KeyError:\\n                pass': 172,\n",
       " 'def keys_to_snake_case(camel_case_dict):\\n    \"\"\"\\n    Make a copy of a dictionary with all keys converted to snake case. This is just calls to_snake_case on\\n    each of the keys in the dictionary and returns a new dictionary.\\n\\n    :param camel_case_dict: Dictionary with the keys to convert.\\n    :type camel_case_dict: Dictionary.\\n\\n    :return: Dictionary with the keys converted to snake case.\\n    \"\"\"\\n    return dict((to_snake_case(key), value) for (key, value) in camel_case_dict.items())': 173,\n",
       " 'def _bytes_to_json(value):\\n    \"\"\"Coerce \\'value\\' to an JSON-compatible representation.\"\"\"\\n    if isinstance(value, bytes):\\n        value = base64.standard_b64encode(value).decode(\"ascii\")\\n    return value': 174,\n",
       " 'def dict_hash(dct):\\n    \"\"\"Return a hash of the contents of a dictionary\"\"\"\\n    dct_s = json.dumps(dct, sort_keys=True)\\n\\n    try:\\n        m = md5(dct_s)\\n    except TypeError:\\n        m = md5(dct_s.encode())\\n\\n    return m.hexdigest()': 175,\n",
       " 'def int_to_date(date):\\n    \"\"\"\\n    Convert an int of form yyyymmdd to a python date object.\\n    \"\"\"\\n\\n    year = date // 10**4\\n    month = date % 10**4 // 10**2\\n    day = date % 10**2\\n\\n    return datetime.date(year, month, day)': 176,\n",
       " 'def filter_dict(d, keys):\\n    \"\"\"\\n    Creates a new dict from an existing dict that only has the given keys\\n    \"\"\"\\n    return {k: v for k, v in d.items() if k in keys}': 177,\n",
       " 'def hasattrs(object, *names):\\n    \"\"\"\\n    Takes in an object and a variable length amount of named attributes,\\n    and checks to see if the object has each property. If any of the\\n    attributes are missing, this returns false.\\n\\n    :param object: an object that may or may not contain the listed attributes\\n    :param names: a variable amount of attribute names to check for\\n    :return: True if the object contains each named attribute, false otherwise\\n    \"\"\"\\n    for name in names:\\n        if not hasattr(object, name):\\n            return False\\n    return True': 178,\n",
       " 'def dict_update_newkeys(dict_, dict2):\\n    \"\"\" Like dict.update, but does not overwrite items \"\"\"\\n    for key, val in six.iteritems(dict2):\\n        if key not in dict_:\\n            dict_[key] = val': 179,\n",
       " 'def numpy_aware_eq(a, b):\\n    \"\"\"Return whether two objects are equal via recursion, using\\n    :func:`numpy.array_equal` for comparing numpy arays.\\n    \"\"\"\\n    if isinstance(a, np.ndarray) or isinstance(b, np.ndarray):\\n        return np.array_equal(a, b)\\n    if ((isinstance(a, Iterable) and isinstance(b, Iterable)) and\\n            not isinstance(a, str) and not isinstance(b, str)):\\n        if len(a) != len(b):\\n            return False\\n        return all(numpy_aware_eq(x, y) for x, y in zip(a, b))\\n    return a == b': 180,\n",
       " 'def update(self, other_dict):\\n        \"\"\"update() extends rather than replaces existing key lists.\"\"\"\\n        for key, value in iter_multi_items(other_dict):\\n            MultiDict.add(self, key, value)': 181,\n",
       " 'def _internet_on(address):\\n    \"\"\"\\n    Check to see if the internet is on by pinging a set address.\\n    :param address: the IP or address to hit\\n    :return: a boolean - true if can be reached, false if not.\\n    \"\"\"\\n    try:\\n        urllib2.urlopen(address, timeout=1)\\n        return True\\n    except urllib2.URLError as err:\\n        return False': 182,\n",
       " 'def _defaultdict(dct, fallback=_illegal_character):\\n    \"\"\"Wraps the given dictionary such that the given fallback function will be called when a nonexistent key is\\n    accessed.\\n    \"\"\"\\n    out = defaultdict(lambda: fallback)\\n    for k, v in six.iteritems(dct):\\n        out[k] = v\\n    return out': 183,\n",
       " 'def is_json_file(filename, show_warnings = False):\\n    \"\"\"Check configuration file type is JSON\\n    Return a boolean indicating wheather the file is JSON format or not\\n    \"\"\"\\n    try:\\n        config_dict = load_config(filename, file_type = \"json\")\\n        is_json = True\\n    except:\\n        is_json = False\\n    return(is_json)': 184,\n",
       " 'def _remove_dict_keys_with_value(dict_, val):\\n  \"\"\"Removes `dict` keys which have have `self` as value.\"\"\"\\n  return {k: v for k, v in dict_.items() if v is not val}': 185,\n",
       " 'def post_commit_hook(argv):\\n    \"\"\"Hook: for checking commit message.\"\"\"\\n    _, stdout, _ = run(\"git log -1 --format=%B HEAD\")\\n    message = \"\\\\n\".join(stdout)\\n    options = {\"allow_empty\": True}\\n\\n    if not _check_message(message, options):\\n        click.echo(\\n            \"Commit message errors (fix with \\'git commit --amend\\').\",\\n            file=sys.stderr)\\n        return 1  # it should not fail with exit\\n    return 0': 186,\n",
       " 'def setdefaults(dct, defaults):\\n    \"\"\"Given a target dct and a dict of {key:default value} pairs,\\n    calls setdefault for all of those pairs.\"\"\"\\n    for key in defaults:\\n        dct.setdefault(key, defaults[key])\\n\\n    return dct': 187,\n",
       " 'def is_image_file_valid(file_path_name):\\n    \"\"\"\\n    Indicate whether the specified image file is valid or not.\\n\\n\\n    @param file_path_name: absolute path and file name of an image.\\n\\n\\n    @return: ``True`` if the image file is valid, ``False`` if the file is\\n        truncated or does not correspond to a supported image.\\n    \"\"\"\\n    # Image.verify is only implemented for PNG images, and it only verifies\\n    # the CRC checksum in the image.  The only way to check from within\\n    # Pillow is to load the image in a try/except and check the error.  If\\n    # as much info as possible is from the image is needed,\\n    # ``ImageFile.LOAD_TRUNCATED_IMAGES=True`` needs to bet set and it\\n    # will attempt to parse as much as possible.\\n    try:\\n        with Image.open(file_path_name) as image:\\n            image.load()\\n    except IOError:\\n        return False\\n\\n    return True': 188,\n",
       " 'def dict_to_html_attrs(dict_):\\n    \"\"\"\\n    Banana banana\\n    \"\"\"\\n    res = \\' \\'.join(\\'%s=\"%s\"\\' % (k, v) for k, v in dict_.items())\\n    return res': 189,\n",
       " 'def is_binary(filename):\\n    \"\"\" Returns True if the file is binary\\n\\n    \"\"\"\\n    with open(filename, \\'rb\\') as fp:\\n        data = fp.read(1024)\\n        if not data:\\n            return False\\n        if b\\'\\\\0\\' in data:\\n            return True\\n        return False': 190,\n",
       " 'def dict_to_querystring(dictionary):\\n    \"\"\"Converts a dict to a querystring suitable to be appended to a URL.\"\"\"\\n    s = u\"\"\\n    for d in dictionary.keys():\\n        s = unicode.format(u\"{0}{1}={2}&\", s, d, dictionary[d])\\n    return s[:-1]': 191,\n",
       " 'def _check_elements_equal(lst):\\n    \"\"\"\\n    Returns true if all of the elements in the list are equal.\\n    \"\"\"\\n    assert isinstance(lst, list), \"Input value must be a list.\"\\n    return not lst or lst.count(lst[0]) == len(lst)': 192,\n",
       " 'def nonull_dict(self):\\n        \"\"\"Like dict, but does not hold any null values.\\n\\n        :return:\\n\\n        \"\"\"\\n        return {k: v for k, v in six.iteritems(self.dict) if v and k != \\'_codes\\'}': 193,\n",
       " 'def is_element_present(driver, selector, by=By.CSS_SELECTOR):\\n    \"\"\"\\n    Returns whether the specified element selector is present on the page.\\n    @Params\\n    driver - the webdriver object (required)\\n    selector - the locator that is used (required)\\n    by - the method to search for the locator (Default: By.CSS_SELECTOR)\\n    @Returns\\n    Boolean (is element present)\\n    \"\"\"\\n    try:\\n        driver.find_element(by=by, value=selector)\\n        return True\\n    except Exception:\\n        return False': 194,\n",
       " 'def updateFromKwargs(self, properties, kwargs, collector, **unused):\\n        \"\"\"Primary entry point to turn \\'kwargs\\' into \\'properties\\'\"\"\"\\n        properties[self.name] = self.getFromKwargs(kwargs)': 195,\n",
       " 'def is_callable(*p):\\n    \"\"\" True if all the args are functions and / or subroutines\\n    \"\"\"\\n    import symbols\\n    return all(isinstance(x, symbols.FUNCTION) for x in p)': 196,\n",
       " 'async def disconnect(self):\\n        \"\"\" Disconnect from target. \"\"\"\\n        if not self.connected:\\n            return\\n\\n        self.writer.close()\\n        self.reader = None\\n        self.writer = None': 197,\n",
       " 'def is_dataframe(obj):\\n    \"\"\"\\n    Returns True if the given object is a Pandas Data Frame.\\n\\n    Parameters\\n    ----------\\n    obj: instance\\n        The object to test whether or not is a Pandas DataFrame.\\n    \"\"\"\\n    try:\\n        # This is the best method of type checking\\n        from pandas import DataFrame\\n        return isinstance(obj, DataFrame)\\n    except ImportError:\\n        # Pandas is not a dependency, so this is scary\\n        return obj.__class__.__name__ == \"DataFrame\"': 198,\n",
       " 'def test():\\n    \"\"\"Run the unit tests.\"\"\"\\n    import unittest\\n    tests = unittest.TestLoader().discover(\\'tests\\')\\n    unittest.TextTestRunner(verbosity=2).run(tests)': 199,\n",
       " 'def is_datetime_like(dtype):\\n    \"\"\"Check if a dtype is a subclass of the numpy datetime types\\n    \"\"\"\\n    return (np.issubdtype(dtype, np.datetime64) or\\n            np.issubdtype(dtype, np.timedelta64))': 200,\n",
       " 'def serialize_json_string(self, value):\\n        \"\"\"\\n        Tries to load an encoded json string back into an object\\n        :param json_string:\\n        :return:\\n        \"\"\"\\n\\n        # Check if the value might be a json string\\n        if not isinstance(value, six.string_types):\\n            return value\\n\\n        # Make sure it starts with a brace\\n        if not value.startswith(\\'{\\') or value.startswith(\\'[\\'):\\n            return value\\n\\n        # Try to load the string\\n        try:\\n            return json.loads(value)\\n        except:\\n            return value': 201,\n",
       " 'def is_defined(self, objtxt, force_import=False):\\n        \"\"\"Return True if object is defined\"\"\"\\n        return self.interpreter.is_defined(objtxt, force_import)': 202,\n",
       " 'def group_exists(groupname):\\n    \"\"\"Check if a group exists\"\"\"\\n    try:\\n        grp.getgrnam(groupname)\\n        group_exists = True\\n    except KeyError:\\n        group_exists = False\\n    return group_exists': 203,\n",
       " 'def sync(self, recursive=False):\\n        \"\"\"\\n        Syncs the information from this item to the tree and view.\\n        \"\"\"\\n        self.syncTree(recursive=recursive)\\n        self.syncView(recursive=recursive)': 204,\n",
       " 'def is_same_shape(self, other_im, check_channels=False):\\n        \"\"\" Checks if two images have the same height and width (and optionally channels).\\n\\n        Parameters\\n        ----------\\n        other_im : :obj:`Image`\\n            image to compare\\n        check_channels : bool\\n            whether or not to check equality of the channels\\n\\n        Returns\\n        -------\\n        bool\\n            True if the images are the same shape, False otherwise\\n        \"\"\"\\n        if self.height == other_im.height and self.width == other_im.width:\\n            if check_channels and self.channels != other_im.channels:\\n                return False\\n            return True\\n        return False': 205,\n",
       " 'def get_distance_between_two_points(self, one, two):\\n        \"\"\"Returns the distance between two XYPoints.\"\"\"\\n        dx = one.x - two.x\\n        dy = one.y - two.y\\n        return math.sqrt(dx * dx + dy * dy)': 206,\n",
       " 'def post_process(self):\\n        \"\"\" Apply last 2D transforms\"\"\"\\n        self.image.putdata(self.pixels)\\n        self.image = self.image.transpose(Image.ROTATE_90)': 207,\n",
       " 'def _not_none(items):\\n    \"\"\"Whether the item is a placeholder or contains a placeholder.\"\"\"\\n    if not isinstance(items, (tuple, list)):\\n        items = (items,)\\n    return all(item is not _none for item in items)': 208,\n",
       " 'def delete_all_from_db():\\n    \"\"\"Clear the database.\\n\\n    Used for testing and debugging.\\n\\n    \"\"\"\\n    # The models.CASCADE property is set on all ForeignKey fields, so tables can\\n    # be deleted in any order without breaking constraints.\\n    for model in django.apps.apps.get_models():\\n        model.objects.all().delete()': 209,\n",
       " 'def is_complex(dtype):\\n  \"\"\"Returns whether this is a complex floating point type.\"\"\"\\n  dtype = tf.as_dtype(dtype)\\n  if hasattr(dtype, \\'is_complex\\'):\\n    return dtype.is_complex\\n  return np.issubdtype(np.dtype(dtype), np.complex)': 210,\n",
       " 'def delete(build_folder):\\n    \"\"\"Delete build directory and all its contents.\\n    \"\"\"\\n    if _meta_.del_build in [\"on\", \"ON\"] and os.path.exists(build_folder):\\n        shutil.rmtree(build_folder)': 211,\n",
       " 'def _stdin_ready_posix():\\n    \"\"\"Return True if there\\'s something to read on stdin (posix version).\"\"\"\\n    infds, outfds, erfds = select.select([sys.stdin],[],[],0)\\n    return bool(infds)': 212,\n",
       " 'def json_response(data, status=200):\\n    \"\"\"Return a JsonResponse. Make sure you have django installed first.\"\"\"\\n    from django.http import JsonResponse\\n    return JsonResponse(data=data, status=status, safe=isinstance(data, dict))': 213,\n",
       " 'def _is_path(s):\\n    \"\"\"Return whether an object is a path.\"\"\"\\n    if isinstance(s, string_types):\\n        try:\\n            return op.exists(s)\\n        except (OSError, ValueError):\\n            return False\\n    else:\\n        return False': 214,\n",
       " 'def see_doc(obj_with_doc):\\n    \"\"\"Copy docstring from existing object to the decorated callable.\"\"\"\\n    def decorator(fn):\\n        fn.__doc__ = obj_with_doc.__doc__\\n        return fn\\n    return decorator': 215,\n",
       " 'def isToneCal(self):\\n        \"\"\"Whether the currently selected calibration stimulus type is the calibration curve\\n\\n        :returns: boolean -- if the current combo box selection is calibration curve\\n        \"\"\"\\n        return self.ui.calTypeCmbbx.currentIndex() == self.ui.calTypeCmbbx.count() -1': 216,\n",
       " 'def hmsToDeg(h, m, s):\\n    \"\"\"Convert RA hours, minutes, seconds into an angle in degrees.\"\"\"\\n    return h * degPerHMSHour + m * degPerHMSMin + s * degPerHMSSec': 217,\n",
       " 'def is_date(thing):\\n    \"\"\"Checks if the given thing represents a date\\n\\n    :param thing: The object to check if it is a date\\n    :type thing: arbitrary object\\n    :returns: True if we have a date object\\n    :rtype: bool\\n    \"\"\"\\n    # known date types\\n    date_types = (datetime.datetime,\\n                  datetime.date,\\n                  DateTime)\\n    return isinstance(thing, date_types)': 218,\n",
       " 'def prepare(doc):\\n    \"\"\"Sets the caption_found and plot_found variables to False.\"\"\"\\n    doc.caption_found = False\\n    doc.plot_found = False\\n    doc.listings_counter = 0': 219,\n",
       " 'def validate(key):\\n    \"\"\"Check that the key is a string or bytestring.\\n\\n    That\\'s the only valid type of key.\\n    \"\"\"\\n    if not isinstance(key, (str, bytes)):\\n        raise KeyError(\\'Key must be of type str or bytes, found type {}\\'.format(type(key)))': 220,\n",
       " 'def _normal_prompt(self):\\n        \"\"\"\\n        Flushes the prompt before requesting the input\\n\\n        :return: The command line\\n        \"\"\"\\n        sys.stdout.write(self.__get_ps1())\\n        sys.stdout.flush()\\n        return safe_input()': 221,\n",
       " 'def maxDepth(self, currentDepth=0):\\n        \"\"\"Compute the depth of the longest branch of the tree\"\"\"\\n        if not any((self.left, self.right)):\\n            return currentDepth\\n        result = 0\\n        for child in (self.left, self.right):\\n            if child:\\n                result = max(result, child.maxDepth(currentDepth + 1))\\n        return result': 222,\n",
       " 'def from_rectangle(box):\\n        \"\"\" Create a vector randomly within the given rectangle. \"\"\"\\n        x = box.left + box.width * random.uniform(0, 1)\\n        y = box.bottom + box.height * random.uniform(0, 1)\\n        return Vector(x, y)': 223,\n",
       " 'def launched():\\n    \"\"\"Test whether the current python environment is the correct lore env.\\n\\n    :return:  :any:`True` if the environment is launched\\n    :rtype: bool\\n    \"\"\"\\n    if not PREFIX:\\n        return False\\n\\n    return os.path.realpath(sys.prefix) == os.path.realpath(PREFIX)': 224,\n",
       " 'def hline(self, x, y, width, color):\\n        \"\"\"Draw a horizontal line up to a given length.\"\"\"\\n        self.rect(x, y, width, 1, color, fill=True)': 225,\n",
       " 'def is_sequence(obj):\\n    \"\"\"Check if `obj` is a sequence, but not a string or bytes.\"\"\"\\n    return isinstance(obj, Sequence) and not (\\n        isinstance(obj, str) or BinaryClass.is_valid_type(obj))': 226,\n",
       " 'def isnamedtuple(obj):\\n    \"\"\"Heuristic check if an object is a namedtuple.\"\"\"\\n    return isinstance(obj, tuple) \\\\\\n           and hasattr(obj, \"_fields\") \\\\\\n           and hasattr(obj, \"_asdict\") \\\\\\n           and callable(obj._asdict)': 227,\n",
       " 'def starts_with_prefix_in_list(text, prefixes):\\n    \"\"\"\\n    Return True if the given string starts with one of the prefixes in the given list, otherwise\\n    return False.\\n\\n    Arguments:\\n        text (str): Text to check for prefixes.\\n        prefixes (list): List of prefixes to check for.\\n\\n    Returns:\\n        bool: True if the given text starts with any of the given prefixes, otherwise False.\\n    \"\"\"\\n    for prefix in prefixes:\\n        if text.startswith(prefix):\\n            return True\\n    return False': 228,\n",
       " 'def print_yaml(o):\\n    \"\"\"Pretty print an object as YAML.\"\"\"\\n    print(yaml.dump(o, default_flow_style=False, indent=4, encoding=\\'utf-8\\'))': 229,\n",
       " 'def issuperset(self, other):\\n        \"\"\"Report whether this RangeSet contains another set.\"\"\"\\n        self._binary_sanity_check(other)\\n        return set.issuperset(self, other)': 230,\n",
       " 'def deserialize_ndarray_npy(d):\\n    \"\"\"\\n    Deserializes a JSONified :obj:`numpy.ndarray` that was created using numpy\\'s\\n    :obj:`save` function.\\n\\n    Args:\\n        d (:obj:`dict`): A dictionary representation of an :obj:`ndarray` object, created\\n            using :obj:`numpy.save`.\\n\\n    Returns:\\n        An :obj:`ndarray` object.\\n    \"\"\"\\n    with io.BytesIO() as f:\\n        f.write(json.loads(d[\\'npy\\']).encode(\\'latin-1\\'))\\n        f.seek(0)\\n        return np.load(f)': 231,\n",
       " 'def check(text):\\n    \"\"\"Check the text.\"\"\"\\n    err = \"misc.currency\"\\n    msg = u\"Incorrect use of symbols in {}.\"\\n\\n    symbols = [\\n        \"\\\\$[\\\\d]* ?(?:dollars|usd|us dollars)\"\\n    ]\\n\\n    return existence_check(text, symbols, err, msg)': 232,\n",
       " 'def required_header(header):\\n    \"\"\"Function that verify if the header parameter is a essential header\\n\\n    :param header:  A string represented a header\\n    :returns:       A boolean value that represent if the header is required\\n    \"\"\"\\n    if header in IGNORE_HEADERS:\\n        return False\\n\\n    if header.startswith(\\'HTTP_\\') or header == \\'CONTENT_TYPE\\':\\n        return True\\n\\n    return False': 233,\n",
       " 'def _map_table_name(self, model_names):\\n        \"\"\"\\n        Pre foregin_keys potrbejeme pre z nazvu tabulky zistit class,\\n        tak si to namapujme\\n        \"\"\"\\n\\n        for model in model_names:\\n            if isinstance(model, tuple):\\n                model = model[0]\\n\\n            try:\\n                model_cls = getattr(self.models, model)\\n                self.table_to_class[class_mapper(model_cls).tables[0].name] = model\\n            except AttributeError:\\n                pass': 234,\n",
       " 'def service_available(service_name):\\n    \"\"\"Determine whether a system service is available\"\"\"\\n    try:\\n        subprocess.check_output(\\n            [\\'service\\', service_name, \\'status\\'],\\n            stderr=subprocess.STDOUT).decode(\\'UTF-8\\')\\n    except subprocess.CalledProcessError as e:\\n        return b\\'unrecognized service\\' not in e.output\\n    else:\\n        return True': 235,\n",
       " 'def keys(self):\\n        \"\"\"Return a list of all keys in the dictionary.\\n\\n        Returns:\\n            list of str: [key1,key2,...,keyN]\\n        \"\"\"\\n        all_keys = [k.decode(\\'utf-8\\') for k,v in self.rdb.hgetall(self.session_hash).items()]\\n        return all_keys': 236,\n",
       " 'def _valid_other_type(x, types):\\n    \"\"\"\\n    Do all elements of x have a type from types?\\n    \"\"\"\\n    return all(any(isinstance(el, t) for t in types) for el in np.ravel(x))': 237,\n",
       " 'def escape_tex(value):\\n  \"\"\"\\n  Make text tex safe\\n  \"\"\"\\n  newval = value\\n  for pattern, replacement in LATEX_SUBS:\\n    newval = pattern.sub(replacement, newval)\\n  return newval': 238,\n",
       " 'def _pip_exists(self):\\n        \"\"\"Returns True if pip exists inside the virtual environment. Can be\\n        used as a naive way to verify that the environment is installed.\"\"\"\\n        return os.path.isfile(os.path.join(self.path, \\'bin\\', \\'pip\\'))': 239,\n",
       " 'def update_index(index):\\n    \"\"\"Re-index every document in a named index.\"\"\"\\n    logger.info(\"Updating search index: \\'%s\\'\", index)\\n    client = get_client()\\n    responses = []\\n    for model in get_index_models(index):\\n        logger.info(\"Updating search index model: \\'%s\\'\", model.search_doc_type)\\n        objects = model.objects.get_search_queryset(index).iterator()\\n        actions = bulk_actions(objects, index=index, action=\"index\")\\n        response = helpers.bulk(client, actions, chunk_size=get_setting(\"chunk_size\"))\\n        responses.append(response)\\n    return responses': 240,\n",
       " 'def hidden_cursor(self):\\n        \"\"\"Return a context manager that hides the cursor while inside it and\\n        makes it visible on leaving.\"\"\"\\n        self.stream.write(self.hide_cursor)\\n        try:\\n            yield\\n        finally:\\n            self.stream.write(self.normal_cursor)': 241,\n",
       " 'def copy(doc, dest, src):\\n    \"\"\"Copy element from sequence, member from mapping.\\n\\n    :param doc: the document base\\n    :param dest: the destination\\n    :type dest: Pointer\\n    :param src: the source\\n    :type src: Pointer\\n    :return: the new object\\n    \"\"\"\\n\\n    return Target(doc).copy(dest, src).document': 242,\n",
       " 'def is_string(val):\\n    \"\"\"Determines whether the passed value is a string, safe for 2/3.\"\"\"\\n    try:\\n        basestring\\n    except NameError:\\n        return isinstance(val, str)\\n    return isinstance(val, basestring)': 243,\n",
       " 'def read_from_file(file_path, encoding=\"utf-8\"):\\n    \"\"\"\\n    Read helper method\\n\\n    :type file_path: str|unicode\\n    :type encoding: str|unicode\\n    :rtype: str|unicode\\n    \"\"\"\\n    with codecs.open(file_path, \"r\", encoding) as f:\\n        return f.read()': 244,\n",
       " 'def _is_root():\\n    \"\"\"Checks if the user is rooted.\"\"\"\\n    import os\\n    import ctypes\\n    try:\\n        return os.geteuid() == 0\\n    except AttributeError:\\n        return ctypes.windll.shell32.IsUserAnAdmin() != 0\\n    return False': 245,\n",
       " 'def describe_enum_value(enum_value):\\n    \"\"\"Build descriptor for Enum instance.\\n\\n    Args:\\n      enum_value: Enum value to provide descriptor for.\\n\\n    Returns:\\n      Initialized EnumValueDescriptor instance describing the Enum instance.\\n    \"\"\"\\n    enum_value_descriptor = EnumValueDescriptor()\\n    enum_value_descriptor.name = six.text_type(enum_value.name)\\n    enum_value_descriptor.number = enum_value.number\\n    return enum_value_descriptor': 246,\n",
       " 'def user_in_all_groups(user, groups):\\n    \"\"\"Returns True if the given user is in all given groups\"\"\"\\n    return user_is_superuser(user) or all(user_in_group(user, group) for group in groups)': 247,\n",
       " 'def items(self):\\n    \"\"\"Return a list of the (name, value) pairs of the enum.\\n\\n    These are returned in the order they were defined in the .proto file.\\n    \"\"\"\\n    return [(value_descriptor.name, value_descriptor.number)\\n            for value_descriptor in self._enum_type.values]': 248,\n",
       " 'def n_choose_k(n, k):\\n    \"\"\" get the number of quartets as n-choose-k. This is used\\n    in equal splits to decide whether a split should be exhaustively sampled\\n    or randomly sampled. Edges near tips can be exhaustive while highly nested\\n    edges probably have too many quartets\\n    \"\"\"\\n    return int(reduce(MUL, (Fraction(n-i, i+1) for i in range(k)), 1))': 249,\n",
       " 'def items(cls):\\n        \"\"\"\\n        All values for this enum\\n        :return: list of tuples\\n\\n        \"\"\"\\n        return [\\n            cls.PRECIPITATION,\\n            cls.WIND,\\n            cls.TEMPERATURE,\\n            cls.PRESSURE\\n        ]': 250,\n",
       " 'def revnet_164_cifar():\\n  \"\"\"Tiny hparams suitable for CIFAR/etc.\"\"\"\\n  hparams = revnet_cifar_base()\\n  hparams.bottleneck = True\\n  hparams.num_channels = [16, 32, 64]\\n  hparams.num_layers_per_block = [8, 8, 8]\\n  return hparams': 251,\n",
       " 'def mtf_image_transformer_cifar_mp_4x():\\n  \"\"\"Data parallel CIFAR parameters.\"\"\"\\n  hparams = mtf_image_transformer_base_cifar()\\n  hparams.mesh_shape = \"model:4;batch:8\"\\n  hparams.layout = \"batch:batch;d_ff:model;heads:model\"\\n  hparams.batch_size = 32\\n  hparams.num_heads = 8\\n  hparams.d_ff = 8192\\n  return hparams': 252,\n",
       " 'def image_set_aspect(aspect=1.0, axes=\"gca\"):\\n    \"\"\"\\n    sets the aspect ratio of the current zoom level of the imshow image\\n    \"\"\"\\n    if axes is \"gca\": axes = _pylab.gca()\\n\\n    e = axes.get_images()[0].get_extent()\\n    axes.set_aspect(abs((e[1]-e[0])/(e[3]-e[2]))/aspect)': 253,\n",
       " 'def Flush(self):\\n    \"\"\"Flush all items from cache.\"\"\"\\n    while self._age:\\n      node = self._age.PopLeft()\\n      self.KillObject(node.data)\\n\\n    self._hash = dict()': 254,\n",
       " 'def _propagate_mean(mean, linop, dist):\\n  \"\"\"Propagate a mean through linear Gaussian transformation.\"\"\"\\n  return linop.matmul(mean) + dist.mean()[..., tf.newaxis]': 255,\n",
       " 'def invalidate_cache(cpu, address, size):\\n        \"\"\" remove decoded instruction from instruction cache \"\"\"\\n        cache = cpu.instruction_cache\\n        for offset in range(size):\\n            if address + offset in cache:\\n                del cache[address + offset]': 256,\n",
       " 'def convertToBool():\\n    \"\"\" Convert a byte value to boolean (0 or 1) if\\n    the global flag strictBool is True\\n    \"\"\"\\n    if not OPTIONS.strictBool.value:\\n        return []\\n\\n    REQUIRES.add(\\'strictbool.asm\\')\\n\\n    result = []\\n    result.append(\\'pop af\\')\\n    result.append(\\'call __NORMALIZE_BOOLEAN\\')\\n    result.append(\\'push af\\')\\n\\n    return result': 257,\n",
       " 'def normalize(x, min_value, max_value):\\n    \"\"\"Normalize value between min and max values.\\n    It also clips the values, so that you cannot have values higher or lower\\n    than 0 - 1.\"\"\"\\n    x = (x - min_value) / (max_value - min_value)\\n    return clip(x, 0, 1)': 258,\n",
       " 'def prepare_for_reraise(error, exc_info=None):\\n    \"\"\"Prepares the exception for re-raising with reraise method.\\n\\n    This method attaches type and traceback info to the error object\\n    so that reraise can properly reraise it using this info.\\n\\n    \"\"\"\\n    if not hasattr(error, \"_type_\"):\\n        if exc_info is None:\\n            exc_info = sys.exc_info()\\n        error._type_ = exc_info[0]\\n        error._traceback = exc_info[2]\\n    return error': 259,\n",
       " 'def close_all_but_this(self):\\n        \"\"\"Close all files but the current one\"\"\"\\n        self.close_all_right()\\n        for i in range(0, self.get_stack_count()-1  ):\\n            self.close_file(0)': 260,\n",
       " 'def eval_in_system_namespace(self, exec_str):\\n        \"\"\"\\n            Get Callable for specified string (for GUI-based editing)\\n        \"\"\"\\n        ns = self.cmd_namespace\\n        try:\\n            return eval(exec_str, ns)\\n        except Exception as e:\\n            self.logger.warning(\\'Could not execute %s, gave error %s\\', exec_str, e)\\n            return None': 261,\n",
       " 'def _close_socket(self):\\n        \"\"\"Shutdown and close the Socket.\\n\\n        :return:\\n        \"\"\"\\n        try:\\n            self.socket.shutdown(socket.SHUT_RDWR)\\n        except (OSError, socket.error):\\n            pass\\n        self.socket.close()': 262,\n",
       " 'def exec_function(ast, globals_map):\\n    \"\"\"Execute a python code object in the given environment.\\n\\n    Args:\\n      globals_map: Dictionary to use as the globals context.\\n    Returns:\\n      locals_map: Dictionary of locals from the environment after execution.\\n    \"\"\"\\n    locals_map = globals_map\\n    exec ast in globals_map, locals_map\\n    return locals_map': 263,\n",
       " 'def cleanup(self, app):\\n        \"\"\"Close all connections.\"\"\"\\n        if hasattr(self.database.obj, \\'close_all\\'):\\n            self.database.close_all()': 264,\n",
       " 'def get_unicode_str(obj):\\n    \"\"\"Makes sure obj is a unicode string.\"\"\"\\n    if isinstance(obj, six.text_type):\\n        return obj\\n    if isinstance(obj, six.binary_type):\\n        return obj.decode(\"utf-8\", errors=\"ignore\")\\n    return six.text_type(obj)': 265,\n",
       " 'def exp_fit_fun(x, a, tau, c):\\n    \"\"\"Function used to fit the exponential decay.\"\"\"\\n    # pylint: disable=invalid-name\\n    return a * np.exp(-x / tau) + c': 266,\n",
       " 'def _findNearest(arr, value):\\n    \"\"\" Finds the value in arr that value is closest to\\n    \"\"\"\\n    arr = np.array(arr)\\n    # find nearest value in array\\n    idx = (abs(arr-value)).argmin()\\n    return arr[idx]': 267,\n",
       " 'def gauss_pdf(x, mu, sigma):\\n    \"\"\"Normalized Gaussian\"\"\"\\n    return 1 / np.sqrt(2 * np.pi) / sigma * np.exp(-(x - mu) ** 2 / 2. / sigma ** 2)': 268,\n",
       " 'def remove_examples_all():\\n    \"\"\"remove arduino/examples/all directory.\\n\\n    :rtype: None\\n\\n    \"\"\"\\n    d = examples_all_dir()\\n    if d.exists():\\n        log.debug(\\'remove %s\\', d)\\n        d.rmtree()\\n    else:\\n        log.debug(\\'nothing to remove: %s\\', d)': 269,\n",
       " 'def resources(self):\\n        \"\"\"Retrieve contents of each page of PDF\"\"\"\\n        return [self.pdf.getPage(i) for i in range(self.pdf.getNumPages())]': 270,\n",
       " 'def cli_command_quit(self, msg):\\n        \"\"\"\\\\\\n        kills the child and exits\\n        \"\"\"\\n        if self.state == State.RUNNING and self.sprocess and self.sprocess.proc:\\n            self.sprocess.proc.kill()\\n        else:\\n            sys.exit(0)': 271,\n",
       " 'def dot(self, w):\\n        \"\"\"Return the dotproduct between self and another vector.\"\"\"\\n\\n        return sum([x * y for x, y in zip(self, w)])': 272,\n",
       " 'def printc(cls, txt, color=colors.red):\\n        \"\"\"Print in color.\"\"\"\\n        print(cls.color_txt(txt, color))': 273,\n",
       " 'def need_update(a, b):\\n    \"\"\"\\n    Check if file a is newer than file b and decide whether or not to update\\n    file b. Can generalize to two lists.\\n    \"\"\"\\n    a = listify(a)\\n    b = listify(b)\\n\\n    return any((not op.exists(x)) for x in b) or \\\\\\n           all((os.stat(x).st_size == 0 for x in b)) or \\\\\\n           any(is_newer_file(x, y) for x in a for y in b)': 274,\n",
       " 'def lengths( self ):\\n        \"\"\"\\n        The cell lengths.\\n\\n        Args:\\n            None\\n\\n        Returns:\\n            (np.array(a,b,c)): The cell lengths.\\n        \"\"\"\\n        return( np.array( [ math.sqrt( sum( row**2 ) ) for row in self.matrix ] ) )': 275,\n",
       " 'def random_str(size=10):\\n    \"\"\"\\n    create random string of selected size\\n\\n    :param size: int, length of the string\\n    :return: the string\\n    \"\"\"\\n    return \\'\\'.join(random.choice(string.ascii_lowercase) for _ in range(size))': 276,\n",
       " 'def get_table_columns(dbconn, tablename):\\n    \"\"\"\\n    Return a list of tuples specifying the column name and type\\n    \"\"\"\\n    cur = dbconn.cursor()\\n    cur.execute(\"PRAGMA table_info(\\'%s\\');\" % tablename)\\n    info = cur.fetchall()\\n    cols = [(i[1], i[2]) for i in info]\\n    return cols': 277,\n",
       " 'def remove_duplicates(lst):\\n    \"\"\"\\n    Emulate what a Python ``set()`` does, but keeping the element\\'s order.\\n    \"\"\"\\n    dset = set()\\n    return [l for l in lst if l not in dset and not dset.add(l)]': 278,\n",
       " 'def _on_select(self, *args):\\n        \"\"\"\\n        Function bound to event of selection in the Combobox, calls callback if callable\\n        \\n        :param args: Tkinter event\\n        \"\"\"\\n        if callable(self.__callback):\\n            self.__callback(self.selection)': 279,\n",
       " 'def fft_spectrum(frames, fft_points=512):\\n    \"\"\"This function computes the one-dimensional n-point discrete Fourier\\n    Transform (DFT) of a real-valued array by means of an efficient algorithm\\n    called the Fast Fourier Transform (FFT). Please refer to\\n    https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.rfft.html\\n    for further details.\\n\\n    Args:\\n        frames (array): The frame array in which each row is a frame.\\n        fft_points (int): The length of FFT. If fft_length is greater than frame_len, the frames will be zero-padded.\\n\\n    Returns:\\n            array: The fft spectrum.\\n            If frames is an num_frames x sample_per_frame matrix, output\\n            will be num_frames x FFT_LENGTH.\\n    \"\"\"\\n    SPECTRUM_VECTOR = np.fft.rfft(frames, n=fft_points, axis=-1, norm=None)\\n    return np.absolute(SPECTRUM_VECTOR)': 280,\n",
       " 'def isetdiff_flags(list1, list2):\\n    \"\"\"\\n    move to util_iter\\n    \"\"\"\\n    set2 = set(list2)\\n    return (item not in set2 for item in list1)': 281,\n",
       " 'def guess_file_type(kind, filepath=None, youtube_id=None, web_url=None, encoding=None):\\n    \"\"\" guess_file_class: determines what file the content is\\n        Args:\\n            filepath (str): filepath of file to check\\n        Returns: string indicating file\\'s class\\n    \"\"\"\\n    if youtube_id:\\n        return FileTypes.YOUTUBE_VIDEO_FILE\\n    elif web_url:\\n        return FileTypes.WEB_VIDEO_FILE\\n    elif encoding:\\n        return FileTypes.BASE64_FILE\\n    else:\\n        ext = os.path.splitext(filepath)[1][1:].lower()\\n        if kind in FILE_TYPE_MAPPING and ext in FILE_TYPE_MAPPING[kind]:\\n            return FILE_TYPE_MAPPING[kind][ext]\\n    return None': 282,\n",
       " 'def is_same_dict(d1, d2):\\n    \"\"\"Test two dictionary is equal on values. (ignore order)\\n    \"\"\"\\n    for k, v in d1.items():\\n        if isinstance(v, dict):\\n            is_same_dict(v, d2[k])\\n        else:\\n            assert d1[k] == d2[k]\\n\\n    for k, v in d2.items():\\n        if isinstance(v, dict):\\n            is_same_dict(v, d1[k])\\n        else:\\n            assert d1[k] == d2[k]': 283,\n",
       " 'def file_writelines_flush_sync(path, lines):\\n    \"\"\"\\n    Fill file at @path with @lines then flush all buffers\\n    (Python and system buffers)\\n    \"\"\"\\n    fp = open(path, \\'w\\')\\n    try:\\n        fp.writelines(lines)\\n        flush_sync_file_object(fp)\\n    finally:\\n        fp.close()': 284,\n",
       " 'def make_kind_check(python_types, numpy_kind):\\n    \"\"\"\\n    Make a function that checks whether a scalar or array is of a given kind\\n    (e.g. float, int, datetime, timedelta).\\n    \"\"\"\\n    def check(value):\\n        if hasattr(value, \\'dtype\\'):\\n            return value.dtype.kind == numpy_kind\\n        return isinstance(value, python_types)\\n    return check': 285,\n",
       " 'def file_empty(fp):\\n    \"\"\"Determine if a file is empty or not.\"\"\"\\n    # for python 2 we need to use a homemade peek()\\n    if six.PY2:\\n        contents = fp.read()\\n        fp.seek(0)\\n        return not bool(contents)\\n\\n    else:\\n        return not fp.peek()': 286,\n",
       " 'def all_equal(arg1,arg2):\\n    \"\"\"\\n    Return a single boolean for arg1==arg2, even for numpy arrays\\n    using element-wise comparison.\\n\\n    Uses all(arg1==arg2) for sequences, and arg1==arg2 otherwise.\\n\\n    If both objects have an \\'_infinitely_iterable\\' attribute, they are\\n    not be zipped together and are compared directly instead.\\n    \"\"\"\\n    if all(hasattr(el, \\'_infinitely_iterable\\') for el in [arg1,arg2]):\\n        return arg1==arg2\\n    try:\\n        return all(a1 == a2 for a1, a2 in zip(arg1, arg2))\\n    except TypeError:\\n        return arg1==arg2': 287,\n",
       " 'def get_file_size(filename):\\n    \"\"\"\\n    Get the file size of a given file\\n\\n    :param filename: string: pathname of a file\\n    :return: human readable filesize\\n    \"\"\"\\n    if os.path.isfile(filename):\\n        return convert_size(os.path.getsize(filename))\\n    return None': 288,\n",
       " 'def _check_for_int(x):\\n    \"\"\"\\n    This is a compatibility function that takes a C{float} and converts it to an\\n    C{int} if the values are equal.\\n    \"\"\"\\n    try:\\n        y = int(x)\\n    except (OverflowError, ValueError):\\n        pass\\n    else:\\n        # There is no way in AMF0 to distinguish between integers and floats\\n        if x == x and y == x:\\n            return y\\n\\n    return x': 289,\n",
       " 'def fill_form(form, data):\\n    \"\"\"Prefill form with data.\\n\\n    :param form: The form to fill.\\n    :param data: The data to insert in the form.\\n    :returns: A pre-filled form.\\n    \"\"\"\\n    for (key, value) in data.items():\\n        if hasattr(form, key):\\n            if isinstance(value, dict):\\n                fill_form(getattr(form, key), value)\\n            else:\\n                getattr(form, key).data = value\\n    return form': 290,\n",
       " 'def check_clang_apply_replacements_binary(args):\\n  \"\"\"Checks if invoking supplied clang-apply-replacements binary works.\"\"\"\\n  try:\\n    subprocess.check_call([args.clang_apply_replacements_binary, \\'--version\\'])\\n  except:\\n    print(\\'Unable to run clang-apply-replacements. Is clang-apply-replacements \\'\\n          \\'binary correctly specified?\\', file=sys.stderr)\\n    traceback.print_exc()\\n    sys.exit(1)': 291,\n",
       " 'def _maybe_fill(arr, fill_value=np.nan):\\n    \"\"\"\\n    if we have a compatible fill_value and arr dtype, then fill\\n    \"\"\"\\n    if _isna_compat(arr, fill_value):\\n        arr.fill(fill_value)\\n    return arr': 292,\n",
       " 'def extract_alzip (archive, compression, cmd, verbosity, interactive, outdir):\\n    \"\"\"Extract a ALZIP archive.\"\"\"\\n    return [cmd, \\'-d\\', outdir, archive]': 293,\n",
       " 'def get_lons_from_cartesian(x__, y__):\\n    \"\"\"Get longitudes from cartesian coordinates.\\n    \"\"\"\\n    return rad2deg(arccos(x__ / sqrt(x__ ** 2 + y__ ** 2))) * sign(y__)': 294,\n",
       " 'def filter_(stream_spec, filter_name, *args, **kwargs):\\n    \"\"\"Alternate name for ``filter``, so as to not collide with the\\n    built-in python ``filter`` operator.\\n    \"\"\"\\n    return filter(stream_spec, filter_name, *args, **kwargs)': 295,\n",
       " 'def find_lt(a, x):\\n    \"\"\"Find rightmost value less than x.\"\"\"\\n    i = bs.bisect_left(a, x)\\n    if i: return i - 1\\n    raise ValueError': 296,\n",
       " 'def get_stationary_distribution(self):\\n        \"\"\"Compute the stationary distribution of states.\\n        \"\"\"\\n        # The stationary distribution is proportional to the left-eigenvector\\n        # associated with the largest eigenvalue (i.e., 1) of the transition\\n        # matrix.\\n        check_is_fitted(self, \"transmat_\")\\n        eigvals, eigvecs = np.linalg.eig(self.transmat_.T)\\n        eigvec = np.real_if_close(eigvecs[:, np.argmax(eigvals)])\\n        return eigvec / eigvec.sum()': 297,\n",
       " 'def apply_fit(xy,coeffs):\\n    \"\"\" Apply the coefficients from a linear fit to\\n        an array of x,y positions.\\n\\n        The coeffs come from the \\'coeffs\\' member of the\\n        \\'fit_arrays()\\' output.\\n    \"\"\"\\n    x_new = coeffs[0][2] + coeffs[0][0]*xy[:,0] + coeffs[0][1]*xy[:,1]\\n    y_new = coeffs[1][2] + coeffs[1][0]*xy[:,0] + coeffs[1][1]*xy[:,1]\\n\\n    return x_new,y_new': 298,\n",
       " 'def _tf_squared_euclidean(X, Y):\\n        \"\"\"Squared Euclidean distance between the rows of `X` and `Y`.\\n        \"\"\"\\n        return tf.reduce_sum(tf.pow(tf.subtract(X, Y), 2), axis=1)': 299,\n",
       " 'def euclidean(x, y):\\n    \"\"\"Standard euclidean distance.\\n\\n    ..math::\\n        D(x, y) = \\\\sqrt{\\\\sum_i (x_i - y_i)^2}\\n    \"\"\"\\n    result = 0.0\\n    for i in range(x.shape[0]):\\n        result += (x[i] - y[i]) ** 2\\n    return np.sqrt(result)': 300,\n",
       " 'def create_table_from_fits(fitsfile, hduname, colnames=None):\\n    \"\"\"Memory efficient function for loading a table from a FITS\\n    file.\"\"\"\\n\\n    if colnames is None:\\n        return Table.read(fitsfile, hduname)\\n\\n    cols = []\\n    with fits.open(fitsfile, memmap=True) as h:\\n        for k in colnames:\\n            data = h[hduname].data.field(k)\\n            cols += [Column(name=k, data=data)]\\n    return Table(cols)': 301,\n",
       " 'def _gcd_array(X):\\n    \"\"\"\\n    Return the largest real value h such that all elements in x are integer\\n    multiples of h.\\n    \"\"\"\\n    greatest_common_divisor = 0.0\\n    for x in X:\\n        greatest_common_divisor = _gcd(greatest_common_divisor, x)\\n\\n    return greatest_common_divisor': 302,\n",
       " 'def lint(args):\\n    \"\"\"Run lint checks using flake8.\"\"\"\\n    application = get_current_application()\\n    if not args:\\n        args = [application.name, \\'tests\\']\\n    args = [\\'flake8\\'] + list(args)\\n    run.main(args, standalone_mode=False)': 303,\n",
       " 'def torecarray(*args, **kwargs):\\n    \"\"\"\\n    Convenient shorthand for ``toarray(*args, **kwargs).view(np.recarray)``.\\n\\n    \"\"\"\\n\\n    import numpy as np\\n    return toarray(*args, **kwargs).view(np.recarray)': 304,\n",
       " 'def _type_bool(label,default=False):\\n    \"\"\"Shortcut fot boolean like fields\"\"\"\\n    return label, abstractSearch.nothing, abstractRender.boolen, default': 305,\n",
       " 'def join_cols(cols):\\n    \"\"\"Join list of columns into a string for a SQL query\"\"\"\\n    return \", \".join([i for i in cols]) if isinstance(cols, (list, tuple, set)) else cols': 306,\n",
       " 'def parse_form(self, req, name, field):\\n        \"\"\"Pull a form value from the request.\"\"\"\\n        return core.get_value(req.POST, name, field)': 307,\n",
       " 'def type_converter(text):\\n    \"\"\" I convert strings into integers, floats, and strings! \"\"\"\\n    if text.isdigit():\\n        return int(text), int\\n\\n    try:\\n        return float(text), float\\n    except ValueError:\\n        return text, STRING_TYPE': 308,\n",
       " 'def cors_header(func):\\n    \"\"\" @cors_header decorator adds CORS headers \"\"\"\\n\\n    @wraps(func)\\n    def wrapper(self, request, *args, **kwargs):\\n        res = func(self, request, *args, **kwargs)\\n        request.setHeader(\\'Access-Control-Allow-Origin\\', \\'*\\')\\n        request.setHeader(\\'Access-Control-Allow-Headers\\', \\'Content-Type, Access-Control-Allow-Headers, Authorization, X-Requested-With\\')\\n        return res\\n\\n    return wrapper': 309,\n",
       " 'def handleFlaskPostRequest(flaskRequest, endpoint):\\n    \"\"\"\\n    Handles the specified flask request for one of the POST URLS\\n    Invokes the specified endpoint to generate a response.\\n    \"\"\"\\n    if flaskRequest.method == \"POST\":\\n        return handleHttpPost(flaskRequest, endpoint)\\n    elif flaskRequest.method == \"OPTIONS\":\\n        return handleHttpOptions()\\n    else:\\n        raise exceptions.MethodNotAllowedException()': 310,\n",
       " 'def python_mime(fn):\\n    \"\"\"\\n    Decorator, which adds correct MIME type for python source to the decorated\\n    bottle API function.\\n    \"\"\"\\n    @wraps(fn)\\n    def python_mime_decorator(*args, **kwargs):\\n        response.content_type = \"text/x-python\"\\n\\n        return fn(*args, **kwargs)\\n\\n    return python_mime_decorator': 311,\n",
       " 'def _spawn_kafka_consumer_thread(self):\\n        \"\"\"Spawns a kafka continuous consumer thread\"\"\"\\n        self.logger.debug(\"Spawn kafka consumer thread\"\"\")\\n        self._consumer_thread = Thread(target=self._consumer_loop)\\n        self._consumer_thread.setDaemon(True)\\n        self._consumer_thread.start()': 312,\n",
       " 'def flatpages_link_list(request):\\n    \"\"\"\\n    Returns a HttpResponse whose content is a Javascript file representing a\\n    list of links to flatpages.\\n    \"\"\"\\n    from django.contrib.flatpages.models import FlatPage\\n    link_list = [(page.title, page.url) for page in FlatPage.objects.all()]\\n    return render_to_link_list(link_list)': 313,\n",
       " 'def values(self):\\n        \"\"\"Gets the user enter max and min values of where the \\n        raster points should appear on the y-axis\\n\\n        :returns: (float, float) -- (min, max) y-values to bound the raster plot by\\n        \"\"\"\\n        lower = float(self.lowerSpnbx.value())\\n        upper = float(self.upperSpnbx.value())\\n        return (lower, upper)': 314,\n",
       " 'def sqlmany(self, stringname, *args):\\n        \"\"\"Wrapper for executing many SQL calls on my connection.\\n\\n        First arg is the name of a query, either a key in the\\n        precompiled JSON or a method name in\\n        ``allegedb.alchemy.Alchemist``. Remaining arguments should be\\n        tuples of argument sequences to be passed to the query.\\n\\n        \"\"\"\\n        if hasattr(self, \\'alchemist\\'):\\n            return getattr(self.alchemist.many, stringname)(*args)\\n        s = self.strings[stringname]\\n        return self.connection.cursor().executemany(s, args)': 315,\n",
       " 'def convolve_gaussian_2d(image, gaussian_kernel_1d):\\n    \"\"\"Convolve 2d gaussian.\"\"\"\\n    result = scipy.ndimage.filters.correlate1d(\\n        image, gaussian_kernel_1d, axis=0)\\n    result = scipy.ndimage.filters.correlate1d(\\n        result, gaussian_kernel_1d, axis=1)\\n    return result': 316,\n",
       " 'def render_template_string(source, **context):\\n    \"\"\"Renders a template from the given template source string\\n    with the given context.\\n\\n    :param source: the sourcecode of the template to be\\n                   rendered\\n    :param context: the variables that should be available in the\\n                    context of the template.\\n    \"\"\"\\n    ctx = _app_ctx_stack.top\\n    ctx.app.update_template_context(context)\\n    return _render(ctx.app.jinja_env.from_string(source),\\n                   context, ctx.app)': 317,\n",
       " 'def asynchronous(function, event):\\n    \"\"\"\\n    Runs the function asynchronously taking care of exceptions.\\n    \"\"\"\\n    thread = Thread(target=synchronous, args=(function, event))\\n    thread.daemon = True\\n    thread.start()': 318,\n",
       " 'def default_static_path():\\n    \"\"\"\\n        Return the path to the javascript bundle\\n    \"\"\"\\n    fdir = os.path.dirname(__file__)\\n    return os.path.abspath(os.path.join(fdir, \\'../assets/\\'))': 319,\n",
       " 'def count_list(the_list):\\n    \"\"\"\\n    Generates a count of the number of times each unique item appears in a list\\n    \"\"\"\\n    count = the_list.count\\n    result = [(item, count(item)) for item in set(the_list)]\\n    result.sort()\\n    return result': 320,\n",
       " 'def round_to_float(number, precision):\\n    \"\"\"Round a float to a precision\"\"\"\\n    rounded = Decimal(str(floor((number + precision / 2) // precision))\\n                      ) * Decimal(str(precision))\\n    return float(rounded)': 321,\n",
       " 'def _calc_overlap_count(\\n    markers1: dict,\\n    markers2: dict,\\n):\\n    \"\"\"Calculate overlap count between the values of two dictionaries\\n\\n    Note: dict values must be sets\\n    \"\"\"\\n    overlaps=np.zeros((len(markers1), len(markers2)))\\n\\n    j=0\\n    for marker_group in markers1:\\n        tmp = [len(markers2[i].intersection(markers1[marker_group])) for i in markers2.keys()]\\n        overlaps[j,:] = tmp\\n        j += 1\\n\\n    return overlaps': 322,\n",
       " 'def intround(value):\\n    \"\"\"Given a float returns a rounded int. Should give the same result on\\n    both Py2/3\\n    \"\"\"\\n\\n    return int(decimal.Decimal.from_float(\\n        value).to_integral_value(decimal.ROUND_HALF_EVEN))': 323,\n",
       " 'def focusInEvent(self, event):\\n        \"\"\"Reimplement Qt method to send focus change notification\"\"\"\\n        self.focus_changed.emit()\\n        return super(PageControlWidget, self).focusInEvent(event)': 324,\n",
       " 'def _accumulate(sequence, func):\\n    \"\"\"\\n    Python2 accumulate implementation taken from\\n    https://docs.python.org/3/library/itertools.html#itertools.accumulate\\n    \"\"\"\\n    iterator = iter(sequence)\\n    total = next(iterator)\\n    yield total\\n    for element in iterator:\\n        total = func(total, element)\\n        yield total': 325,\n",
       " 'def iter_finds(regex_obj, s):\\n    \"\"\"Generate all matches found within a string for a regex and yield each match as a string\"\"\"\\n    if isinstance(regex_obj, str):\\n        for m in re.finditer(regex_obj, s):\\n            yield m.group()\\n    else:\\n        for m in regex_obj.finditer(s):\\n            yield m.group()': 326,\n",
       " 'def a2s(a):\\n    \"\"\"\\n     convert 3,3 a matrix to 6 element \"s\" list  (see Tauxe 1998)\\n    \"\"\"\\n    s = np.zeros((6,), \\'f\\')  # make the a matrix\\n    for i in range(3):\\n        s[i] = a[i][i]\\n    s[3] = a[0][1]\\n    s[4] = a[1][2]\\n    s[5] = a[0][2]\\n    return s': 327,\n",
       " 'def concat(cls, iterables):\\n    \"\"\"\\n    Similar to #itertools.chain.from_iterable().\\n    \"\"\"\\n\\n    def generator():\\n      for it in iterables:\\n        for element in it:\\n          yield element\\n    return cls(generator())': 328,\n",
       " 'def format_result(input):\\n        \"\"\"From: http://stackoverflow.com/questions/13062300/convert-a-dict-to-sorted-dict-in-python\\n        \"\"\"\\n        items = list(iteritems(input))\\n        return OrderedDict(sorted(items, key=lambda x: x[0]))': 329,\n",
       " 'def bulk_query(self, query, *multiparams):\\n        \"\"\"Bulk insert or update.\"\"\"\\n\\n        with self.get_connection() as conn:\\n            conn.bulk_query(query, *multiparams)': 330,\n",
       " 'def Trie(S):\\n    \"\"\"\\n    :param S: set of words\\n    :returns: trie containing all words from S\\n    :complexity: linear in total word sizes from S\\n    \"\"\"\\n    T = None\\n    for w in S:\\n        T = add(T, w)\\n    return T': 331,\n",
       " 'def __set__(self, instance, value):\\n        \"\"\" Set a related object for an instance. \"\"\"\\n\\n        self.map[id(instance)] = (weakref.ref(instance), value)': 332,\n",
       " 'def recarray(self):\\n        \"\"\"Returns data as :class:`numpy.recarray`.\"\"\"\\n        return numpy.rec.fromrecords(self.records, names=self.names)': 333,\n",
       " 'def go_to_background():\\n    \"\"\" Daemonize the running process. \"\"\"\\n    try:\\n        if os.fork():\\n            sys.exit()\\n    except OSError as errmsg:\\n        LOGGER.error(\\'Fork failed: {0}\\'.format(errmsg))\\n        sys.exit(\\'Fork failed\\')': 334,\n",
       " 'def generate_unique_host_id():\\n    \"\"\"Generate a unique ID, that is somewhat guaranteed to be unique among all\\n    instances running at the same time.\"\"\"\\n    host = \".\".join(reversed(socket.gethostname().split(\".\")))\\n    pid = os.getpid()\\n    return \"%s.%d\" % (host, pid)': 335,\n",
       " 'def compress(self, data_list):\\n        \"\"\"\\n        Return the cleaned_data of the form, everything should already be valid\\n        \"\"\"\\n        data = {}\\n        if data_list:\\n            return dict(\\n                (f.name, data_list[i]) for i, f in enumerate(self.form))\\n        return data': 336,\n",
       " 'def init_db():\\n    \"\"\"\\n    Drops and re-creates the SQL schema\\n    \"\"\"\\n    db.drop_all()\\n    db.configure_mappers()\\n    db.create_all()\\n    db.session.commit()': 337,\n",
       " 'def safe_format(s, **kwargs):\\n  \"\"\"\\n  :type s str\\n  \"\"\"\\n  return string.Formatter().vformat(s, (), defaultdict(str, **kwargs))': 338,\n",
       " 'def _init_unique_sets(self):\\n        \"\"\"Initialise sets used for uniqueness checking.\"\"\"\\n\\n        ks = dict()\\n        for t in self._unique_checks:\\n            key = t[0]\\n            ks[key] = set() # empty set\\n        return ks': 339,\n",
       " 'def straight_line_show(title, length=100, linestyle=\"=\", pad=0):\\n        \"\"\"Print a formatted straight line.\\n        \"\"\"\\n        print(StrTemplate.straight_line(\\n            title=title, length=length, linestyle=linestyle, pad=pad))': 340,\n",
       " 'def make_executable(script_path):\\n    \"\"\"Make `script_path` executable.\\n\\n    :param script_path: The file to change\\n    \"\"\"\\n    status = os.stat(script_path)\\n    os.chmod(script_path, status.st_mode | stat.S_IEXEC)': 341,\n",
       " 'def  make_html_code( self, lines ):\\n        \"\"\" convert a code sequence to HTML \"\"\"\\n        line = code_header + \\'\\\\n\\'\\n        for l in lines:\\n            line = line + html_quote( l ) + \\'\\\\n\\'\\n\\n        return line + code_footer': 342,\n",
       " 'def cross_product_matrix(vec):\\n    \"\"\"Returns a 3x3 cross-product matrix from a 3-element vector.\"\"\"\\n    return np.array([[0, -vec[2], vec[1]],\\n                     [vec[2], 0, -vec[0]],\\n                     [-vec[1], vec[0], 0]])': 343,\n",
       " 'def index_nearest(value, array):\\n    \"\"\"\\n    expects a _n.array\\n    returns the global minimum of (value-array)^2\\n    \"\"\"\\n\\n    a = (array-value)**2\\n    return index(a.min(), a)': 344,\n",
       " 'def main(args=sys.argv):\\n    \"\"\"\\n    main entry point for the jardiff CLI\\n    \"\"\"\\n\\n    parser = create_optparser(args[0])\\n    return cli(parser.parse_args(args[1:]))': 345,\n",
       " 'def free(self):\\n        \"\"\"Free the underlying C array\"\"\"\\n        if self._ptr is None:\\n            return\\n        Gauged.array_free(self.ptr)\\n        FloatArray.ALLOCATIONS -= 1\\n        self._ptr = None': 346,\n",
       " 'def from_points(cls, list_of_lists):\\n        \"\"\"\\n        Creates a *Polygon* instance out of a list of lists, each sublist being populated with\\n        `pyowm.utils.geo.Point` instances\\n        :param list_of_lists: list\\n        :type: list_of_lists: iterable_of_polygons\\n        :returns:  a *Polygon* instance\\n\\n        \"\"\"\\n        result = []\\n        for l in list_of_lists:\\n            curve = []\\n            for point in l:\\n                curve.append((point.lon, point.lat))\\n            result.append(curve)\\n        return Polygon(result)': 347,\n",
       " 'def connect():\\n    \"\"\"Connect to FTP server, login and return an ftplib.FTP instance.\"\"\"\\n    ftp_class = ftplib.FTP if not SSL else ftplib.FTP_TLS\\n    ftp = ftp_class(timeout=TIMEOUT)\\n    ftp.connect(HOST, PORT)\\n    ftp.login(USER, PASSWORD)\\n    if SSL:\\n        ftp.prot_p()  # secure data connection\\n    return ftp': 348,\n",
       " 'def tmpfile(prefix, direc):\\n    \"\"\"Returns the path to a newly created temporary file.\"\"\"\\n    return tempfile.mktemp(prefix=prefix, suffix=\\'.pdb\\', dir=direc)': 349,\n",
       " 'def connect(host, port, username, password):\\n        \"\"\"Connect and login to an FTP server and return ftplib.FTP object.\"\"\"\\n        # Instantiate ftplib client\\n        session = ftplib.FTP()\\n\\n        # Connect to host without auth\\n        session.connect(host, port)\\n\\n        # Authenticate connection\\n        session.login(username, password)\\n        return session': 350,\n",
       " 'def unique_list(lst):\\n    \"\"\"Make a list unique, retaining order of initial appearance.\"\"\"\\n    uniq = []\\n    for item in lst:\\n        if item not in uniq:\\n            uniq.append(item)\\n    return uniq': 351,\n",
       " 'def All(sequence):\\n  \"\"\"\\n  :param sequence: Any sequence whose elements can be evaluated as booleans.\\n  :returns: true if all elements of the sequence satisfy True and x.\\n  \"\"\"\\n  return bool(reduce(lambda x, y: x and y, sequence, True))': 352,\n",
       " 'def zero_state(self, batch_size):\\n        \"\"\" Initial state of the network \"\"\"\\n        return torch.zeros(batch_size, self.state_dim, dtype=torch.float32)': 353,\n",
       " 'def _fullname(o):\\n    \"\"\"Return the fully-qualified name of a function.\"\"\"\\n    return o.__module__ + \".\" + o.__name__ if o.__module__ else o.__name__': 354,\n",
       " 'def create_index(config):\\n    \"\"\"Create the root index.\"\"\"\\n    filename = pathlib.Path(config.cache_path) / \"index.json\"\\n    index = {\"version\": __version__}\\n    with open(filename, \"w\") as out:\\n        out.write(json.dumps(index, indent=2))': 355,\n",
       " 'def issorted(list_, op=operator.le):\\n    \"\"\"\\n    Determines if a list is sorted\\n\\n    Args:\\n        list_ (list):\\n        op (func): sorted operation (default=operator.le)\\n\\n    Returns:\\n        bool : True if the list is sorted\\n    \"\"\"\\n    return all(op(list_[ix], list_[ix + 1]) for ix in range(len(list_) - 1))': 356,\n",
       " 'def is_valid(number):\\n    \"\"\"determines whether the card number is valid.\"\"\"\\n    n = str(number)\\n    if not n.isdigit():\\n        return False\\n    return int(n[-1]) == get_check_digit(n[:-1])': 357,\n",
       " 'def us2mc(string):\\n    \"\"\"Transform an underscore_case string to a mixedCase string\"\"\"\\n    return re.sub(r\\'_([a-z])\\', lambda m: (m.group(1).upper()), string)': 358,\n",
       " 'def csv2yaml(in_file, out_file=None):\\n    \"\"\"Convert a CSV SampleSheet to YAML run_info format.\\n    \"\"\"\\n    if out_file is None:\\n        out_file = \"%s.yaml\" % os.path.splitext(in_file)[0]\\n    barcode_ids = _generate_barcode_ids(_read_input_csv(in_file))\\n    lanes = _organize_lanes(_read_input_csv(in_file), barcode_ids)\\n    with open(out_file, \"w\") as out_handle:\\n        out_handle.write(yaml.safe_dump(lanes, default_flow_style=False))\\n    return out_file': 359,\n",
       " 'def get_average_length_of_string(strings):\\n    \"\"\"Computes average length of words\\n\\n    :param strings: list of words\\n    :return: Average length of word on list\\n    \"\"\"\\n    if not strings:\\n        return 0\\n\\n    return sum(len(word) for word in strings) / len(strings)': 360,\n",
       " 'def cumsum(inlist):\\n    \"\"\"\\nReturns a list consisting of the cumulative sum of the items in the\\npassed list.\\n\\nUsage:   lcumsum(inlist)\\n\"\"\"\\n    newlist = copy.deepcopy(inlist)\\n    for i in range(1, len(newlist)):\\n        newlist[i] = newlist[i] + newlist[i - 1]\\n    return newlist': 361,\n",
       " 'def good(txt):\\n    \"\"\"Print, emphasized \\'good\\', the given \\'txt\\' message\"\"\"\\n\\n    print(\"%s# %s%s%s\" % (PR_GOOD_CC, get_time_stamp(), txt, PR_NC))\\n    sys.stdout.flush()': 362,\n",
       " 'def move_to(self, ypos, xpos):\\n        \"\"\"\\n            move the cursor to the given co-ordinates.  Co-ordinates are 1\\n            based, as listed in the status area of the terminal.\\n        \"\"\"\\n        # the screen\\'s co-ordinates are 1 based, but the command is 0 based\\n        xpos -= 1\\n        ypos -= 1\\n        self.exec_command(\"MoveCursor({0}, {1})\".format(ypos, xpos).encode(\"ascii\"))': 363,\n",
       " 'def dict_from_object(obj: object):\\n    \"\"\"Convert a object into dictionary with all of its readable attributes.\"\"\"\\n\\n    # If object is a dict instance, no need to convert.\\n    return (obj if isinstance(obj, dict)\\n            else {attr: getattr(obj, attr)\\n                  for attr in dir(obj) if not attr.startswith(\\'_\\')})': 364,\n",
       " 'def ensure_hbounds(self):\\n        \"\"\"Ensure the cursor is within horizontal screen bounds.\"\"\"\\n        self.cursor.x = min(max(0, self.cursor.x), self.columns - 1)': 365,\n",
       " 'def strip_spaces(s):\\n    \"\"\" Strip excess spaces from a string \"\"\"\\n    return u\" \".join([c for c in s.split(u\\' \\') if c])': 366,\n",
       " 'def scatter(self, *args, **kwargs):\\n        \"\"\"Add a scatter plot.\"\"\"\\n        cls = _make_class(ScatterVisual,\\n                          _default_marker=kwargs.pop(\\'marker\\', None),\\n                          )\\n        return self._add_item(cls, *args, **kwargs)': 367,\n",
       " 'def download_file_from_bucket(self, bucket, file_path, key):\\n        \"\"\" Download file from S3 Bucket \"\"\"\\n        with open(file_path, \\'wb\\') as data:\\n            self.__s3.download_fileobj(bucket, key, data)\\n            return file_path': 368,\n",
       " 'def imdecode(image_path):\\n    \"\"\"Return BGR image read by opencv\"\"\"\\n    import os\\n    assert os.path.exists(image_path), image_path + \\' not found\\'\\n    im = cv2.imread(image_path)\\n    return im': 369,\n",
       " 'def ex(self, cmd):\\n        \"\"\"Execute a normal python statement in user namespace.\"\"\"\\n        with self.builtin_trap:\\n            exec cmd in self.user_global_ns, self.user_ns': 370,\n",
       " 'def isbinary(*args):\\n    \"\"\"Checks if value can be part of binary/bitwise operations.\"\"\"\\n    return all(map(lambda c: isnumber(c) or isbool(c), args))': 371,\n",
       " 'def split(s):\\n  \"\"\"Uses dynamic programming to infer the location of spaces in a string without spaces.\"\"\"\\n  l = [_split(x) for x in _SPLIT_RE.split(s)]\\n  return [item for sublist in l for item in sublist]': 372,\n",
       " 'def dt2jd(dt):\\n    \"\"\"Convert datetime to julian date\\n    \"\"\"\\n    a = (14 - dt.month)//12\\n    y = dt.year + 4800 - a\\n    m = dt.month + 12*a - 3\\n    return dt.day + ((153*m + 2)//5) + 365*y + y//4 - y//100 + y//400 - 32045': 373,\n",
       " 'def smooth_gaussian(image, sigma=1):\\n    \"\"\"Returns Gaussian smoothed image.\\n\\n    :param image: numpy array or :class:`jicimagelib.image.Image`\\n    :param sigma: standard deviation\\n    :returns: :class:`jicimagelib.image.Image`\\n    \"\"\"\\n    return scipy.ndimage.filters.gaussian_filter(image, sigma=sigma, mode=\"nearest\")': 374,\n",
       " 'def _time_to_json(value):\\n    \"\"\"Coerce \\'value\\' to an JSON-compatible representation.\"\"\"\\n    if isinstance(value, datetime.time):\\n        value = value.isoformat()\\n    return value': 375,\n",
       " 'def EvalGaussianPdf(x, mu, sigma):\\n    \"\"\"Computes the unnormalized PDF of the normal distribution.\\n\\n    x: value\\n    mu: mean\\n    sigma: standard deviation\\n    \\n    returns: float probability density\\n    \"\"\"\\n    return scipy.stats.norm.pdf(x, mu, sigma)': 376,\n",
       " 'def convert_timestamp(timestamp):\\n    \"\"\"\\n    Converts bokehJS timestamp to datetime64.\\n    \"\"\"\\n    datetime = dt.datetime.utcfromtimestamp(timestamp/1000.)\\n    return np.datetime64(datetime.replace(tzinfo=None))': 377,\n",
       " 'def _make_cmd_list(cmd_list):\\n    \"\"\"\\n    Helper function to easily create the proper json formated string from a list of strs\\n    :param cmd_list: list of strings\\n    :return: str json formatted\\n    \"\"\"\\n    cmd = \\'\\'\\n    for i in cmd_list:\\n        cmd = cmd + \\'\"\\' + i + \\'\",\\'\\n    cmd = cmd[:-1]\\n    return cmd': 378,\n",
       " 'def accuracy(self):\\n        \"\"\"\\n        Calculates the accuracy of the tree by comparing\\n        the model predictions to the dataset\\n        (TP + TN) / (TP + TN + FP + FN) == (T / (T + F))\\n        \"\"\"\\n        sub_observed = np.array([self.observed.metadata[i] for i in self.observed.arr])\\n        return float((self.model_predictions() == sub_observed).sum()) / self.data_size': 379,\n",
       " 'def cli(yamlfile, format, context):\\n    \"\"\" Generate JSONLD file from biolink schema \"\"\"\\n    print(JSONLDGenerator(yamlfile, format).serialize(context=context))': 380,\n",
       " 'def double_sha256(data):\\n    \"\"\"A standard compound hash.\"\"\"\\n    return bytes_as_revhex(hashlib.sha256(hashlib.sha256(data).digest()).digest())': 381,\n",
       " 'def get_cantons(self):\\n        \"\"\"\\n        Return the list of unique cantons, sorted by name.\\n        \"\"\"\\n        return sorted(list(set([\\n            location.canton for location in self.get_locations().values()\\n        ])))': 382,\n",
       " 'def get_method_name(method):\\n    \"\"\"\\n    Returns given method name.\\n\\n    :param method: Method to retrieve the name.\\n    :type method: object\\n    :return: Method name.\\n    :rtype: unicode\\n    \"\"\"\\n\\n    name = get_object_name(method)\\n    if name.startswith(\"__\") and not name.endswith(\"__\"):\\n        name = \"_{0}{1}\".format(get_object_name(method.im_class), name)\\n    return name': 383,\n",
       " 'def _add_default_arguments(parser):\\n    \"\"\"Add the default arguments to the parser.\\n\\n    :param argparse.ArgumentParser parser: The argument parser\\n\\n    \"\"\"\\n    parser.add_argument(\\'-c\\', \\'--config\\', action=\\'store\\', dest=\\'config\\',\\n                        help=\\'Path to the configuration file\\')\\n    parser.add_argument(\\'-f\\', \\'--foreground\\', action=\\'store_true\\', dest=\\'foreground\\',\\n                        help=\\'Run the application interactively\\')': 384,\n",
       " 'def get_methods(*objs):\\n    \"\"\" Return the names of all callable attributes of an object\"\"\"\\n    return set(\\n        attr\\n        for obj in objs\\n        for attr in dir(obj)\\n        if not attr.startswith(\\'_\\') and callable(getattr(obj, attr))\\n    )': 385,\n",
       " 'def computeDelaunayTriangulation(points):\\n    \"\"\" Takes a list of point objects (which must have x and y fields).\\n        Returns a list of 3-tuples: the indices of the points that form a\\n        Delaunay triangle.\\n    \"\"\"\\n    siteList = SiteList(points)\\n    context  = Context()\\n    context.triangulate = True\\n    voronoi(siteList,context)\\n    return context.triangles': 386,\n",
       " 'def get_keys_from_class(cc):\\n    \"\"\"Return list of the key property names for a class \"\"\"\\n    return [prop.name for prop in cc.properties.values() \\\\\\n            if \\'key\\' in prop.qualifiers]': 387,\n",
       " 'def rm(venv_name):\\n    \"\"\" Removes the venv by name \"\"\"\\n    inenv = InenvManager()\\n    venv = inenv.get_venv(venv_name)\\n    click.confirm(\"Delete dir {}\".format(venv.path))\\n    shutil.rmtree(venv.path)': 388,\n",
       " 'def columns(self):\\n        \"\"\"Return names of all the addressable columns (including foreign keys) referenced in user supplied model\"\"\"\\n        res = [col[\\'name\\'] for col in self.column_definitions]\\n        res.extend([col[\\'name\\'] for col in self.foreign_key_definitions])\\n        return res': 389,\n",
       " 'def remove_non_magic_cols(self):\\n        \"\"\"\\n        Remove all non-MagIC columns from all tables.\\n        \"\"\"\\n        for table_name in self.tables:\\n            table = self.tables[table_name]\\n            table.remove_non_magic_cols_from_table()': 390,\n",
       " 'def get_obj(ref):\\n    \"\"\"Get object from string reference.\"\"\"\\n    oid = int(ref)\\n    return server.id2ref.get(oid) or server.id2obj[oid]': 391,\n",
       " 'def _split_comma_separated(string):\\n    \"\"\"Return a set of strings.\"\"\"\\n    return set(text.strip() for text in string.split(\\',\\') if text.strip())': 392,\n",
       " 'def angle(x0, y0, x1, y1):\\n    \"\"\" Returns the angle between two points.\\n    \"\"\"\\n    return degrees(atan2(y1-y0, x1-x0))': 393,\n",
       " 'def delete_duplicates(seq):\\n    \"\"\"\\n    Remove duplicates from an iterable, preserving the order.\\n\\n    Args:\\n        seq: Iterable of various type.\\n\\n    Returns:\\n        list: List of unique objects.\\n\\n    \"\"\"\\n    seen = set()\\n    seen_add = seen.add\\n    return [x for x in seq if not (x in seen or seen_add(x))]': 394,\n",
       " 'def guess_extension(amimetype, normalize=False):\\n    \"\"\"\\n    Tries to guess extension for a mimetype.\\n\\n    @param amimetype: name of a mimetype\\n    @time amimetype: string\\n    @return: the extension\\n    @rtype: string\\n    \"\"\"\\n    ext = _mimes.guess_extension(amimetype)\\n    if ext and normalize:\\n        # Normalize some common magic mis-interpreation\\n        ext = {\\'.asc\\': \\'.txt\\', \\'.obj\\': \\'.bin\\'}.get(ext, ext)\\n        from invenio.legacy.bibdocfile.api_normalizer import normalize_format\\n        return normalize_format(ext)\\n    return ext': 395,\n",
       " 'def reset():\\n    \"\"\"Delete the session and clear temporary directories\\n\\n    \"\"\"\\n    shutil.rmtree(session[\\'img_input_dir\\'])\\n    shutil.rmtree(session[\\'img_output_dir\\'])\\n    session.clear()\\n    return jsonify(ok=\\'true\\')': 396,\n",
       " 'def boolean(value):\\n    \"\"\"\\n    Configuration-friendly boolean type converter.\\n\\n    Supports both boolean-valued and string-valued inputs (e.g. from env vars).\\n\\n    \"\"\"\\n    if isinstance(value, bool):\\n        return value\\n\\n    if value == \"\":\\n        return False\\n\\n    return strtobool(value)': 397,\n",
       " 'def detokenize(s):\\n    \"\"\" Detokenize a string by removing spaces before punctuation.\"\"\"\\n    print(s)\\n    s = re.sub(\"\\\\s+([;:,\\\\.\\\\?!])\", \"\\\\\\\\1\", s)\\n    s = re.sub(\"\\\\s+(n\\'t)\", \"\\\\\\\\1\", s)\\n    return s': 398,\n",
       " 'def get_colors(img):\\n    \"\"\"\\n    Returns a list of all the image\\'s colors.\\n    \"\"\"\\n    w, h = img.size\\n    return [color[:3] for count, color in img.convert(\\'RGB\\').getcolors(w * h)]': 399,\n",
       " 'def pop(h):\\n    \"\"\"Pop the heap value from the heap.\"\"\"\\n    n = h.size() - 1\\n    h.swap(0, n)\\n    down(h, 0, n)\\n    return h.pop()': 400,\n",
       " 'def memory():\\n    \"\"\"Determine memory specifications of the machine.\\n\\n    Returns\\n    -------\\n    mem_info : dictonary\\n        Holds the current values for the total, free and used memory of the system.\\n    \"\"\"\\n\\n    mem_info = dict()\\n\\n    for k, v in psutil.virtual_memory()._asdict().items():\\n           mem_info[k] = int(v)\\n           \\n    return mem_info': 401,\n",
       " 'def check_precomputed_distance_matrix(X):\\n    \"\"\"Perform check_array(X) after removing infinite values (numpy.inf) from the given distance matrix.\\n    \"\"\"\\n    tmp = X.copy()\\n    tmp[np.isinf(tmp)] = 1\\n    check_array(tmp)': 402,\n",
       " 'def calculate_month(birth_date):\\n    \"\"\"\\n    Calculates and returns a month number basing on PESEL standard.\\n    \"\"\"\\n    year = int(birth_date.strftime(\\'%Y\\'))\\n    month = int(birth_date.strftime(\\'%m\\')) + ((int(year / 100) - 14) % 5) * 20\\n\\n    return month': 403,\n",
       " 'def linedelimited (inlist,delimiter):\\n    \"\"\"\\nReturns a string composed of elements in inlist, with each element\\nseparated by \\'delimiter.\\'  Used by function writedelimited.  Use \\'\\\\t\\'\\nfor tab-delimiting.\\n\\nUsage:   linedelimited (inlist,delimiter)\\n\"\"\"\\n    outstr = \\'\\'\\n    for item in inlist:\\n        if type(item) != StringType:\\n            item = str(item)\\n        outstr = outstr + item + delimiter\\n    outstr = outstr[0:-1]\\n    return outstr': 404,\n",
       " 'def get_month_start_end_day():\\n    \"\"\"\\n    Get the month start date a nd end date\\n    \"\"\"\\n    t = date.today()\\n    n = mdays[t.month]\\n    return (date(t.year, t.month, 1), date(t.year, t.month, n))': 405,\n",
       " 'def dequeue(self, block=True):\\n        \"\"\"Dequeue a record and return item.\"\"\"\\n        return self.queue.get(block, self.queue_get_timeout)': 406,\n",
       " 'def return_value(self, *args, **kwargs):\\n        \"\"\"Extracts the real value to be returned from the wrapping callable.\\n\\n        :return: The value the double should return when called.\\n        \"\"\"\\n\\n        self._called()\\n        return self._return_value(*args, **kwargs)': 407,\n",
       " 'def get_best_encoding(stream):\\n    \"\"\"Returns the default stream encoding if not found.\"\"\"\\n    rv = getattr(stream, \\'encoding\\', None) or sys.getdefaultencoding()\\n    if is_ascii_encoding(rv):\\n        return \\'utf-8\\'\\n    return rv': 408,\n",
       " 'def relpath(self):\\n        \"\"\" Return this path as a relative path,\\n        based from the current working directory.\\n        \"\"\"\\n        cwd = self.__class__(os.getcwdu())\\n        return cwd.relpathto(self)': 409,\n",
       " 'def we_are_in_lyon():\\n    \"\"\"Check if we are on a Lyon machine\"\"\"\\n    import socket\\n    try:\\n        hostname = socket.gethostname()\\n        ip = socket.gethostbyname(hostname)\\n    except socket.gaierror:\\n        return False\\n    return ip.startswith(\"134.158.\")': 410,\n",
       " 'def skip_connection_distance(a, b):\\n    \"\"\"The distance between two skip-connections.\"\"\"\\n    if a[2] != b[2]:\\n        return 1.0\\n    len_a = abs(a[1] - a[0])\\n    len_b = abs(b[1] - b[0])\\n    return (abs(a[0] - b[0]) + abs(len_a - len_b)) / (max(a[0], b[0]) + max(len_a, len_b))': 411,\n",
       " 'def eqstr(a, b):\\n    \"\"\"\\n    Determine whether two strings are equivalent.\\n\\n    http://naif.jpl.nasa.gov/pub/naif/toolkit_docs/C/cspice/eqstr_c.html\\n\\n    :param a: Arbitrary character string.\\n    :type a: str\\n    :param b: Arbitrary character string.\\n    :type b: str\\n    :return: True if A and B are equivalent.\\n    :rtype: bool\\n    \"\"\"\\n    return bool(libspice.eqstr_c(stypes.stringToCharP(a), stypes.stringToCharP(b)))': 412,\n",
       " 'def get_by(self, name):\\n    \"\"\"get element by name\"\"\"\\n    return next((item for item in self if item.name == name), None)': 413,\n",
       " 'def validate(self, *args, **kwargs): # pylint: disable=arguments-differ\\n        \"\"\"\\n        Validate a parameter dict against a parameter schema from an ocrd-tool.json\\n\\n        Args:\\n            obj (dict):\\n            schema (dict):\\n        \"\"\"\\n        return super(ParameterValidator, self)._validate(*args, **kwargs)': 414,\n",
       " 'def get_parent_dir(name):\\n    \"\"\"Get the parent directory of a filename.\"\"\"\\n    parent_dir = os.path.dirname(os.path.dirname(name))\\n    if parent_dir:\\n        return parent_dir\\n    return os.path.abspath(\\'.\\')': 415,\n",
       " 'def me(self):\\n        \"\"\"Similar to :attr:`.Guild.me` except it may return the :class:`.ClientUser` in private message contexts.\"\"\"\\n        return self.guild.me if self.guild is not None else self.bot.user': 416,\n",
       " 'def get_size_in_bytes(self, handle):\\n        \"\"\"Return the size in bytes.\"\"\"\\n        fpath = self._fpath_from_handle(handle)\\n        return os.stat(fpath).st_size': 417,\n",
       " 'def show_guestbook():\\n    \"\"\"Returns all existing guestbook records.\"\"\"\\n    cursor = flask.g.db.execute(\\n        \\'SELECT name, message FROM entry ORDER BY id DESC;\\')\\n    entries = [{\\'name\\': row[0], \\'message\\': row[1]} for row in cursor.fetchall()]\\n    return jinja2.Template(LAYOUT).render(entries=entries)': 418,\n",
       " 'def get_month_start(day=None):\\n    \"\"\"Returns the first day of the given month.\"\"\"\\n    day = add_timezone(day or datetime.date.today())\\n    return day.replace(day=1)': 419,\n",
       " 'def rank(idx, dim):\\n    \"\"\"Calculate the index rank according to Bertran\\'s notation.\"\"\"\\n    idxm = multi_index(idx, dim)\\n    out = 0\\n    while idxm[-1:] == (0,):\\n        out += 1\\n        idxm = idxm[:-1]\\n    return out': 420,\n",
       " 'def get_last_commit(git_path=None):\\n    \"\"\"\\n    Get the HEAD commit SHA1 of repository in current dir.\\n    \"\"\"\\n    if git_path is None: git_path = GIT_PATH\\n    line = get_last_commit_line(git_path)\\n    revision_id = line.split()[1]\\n    return revision_id': 421,\n",
       " 'def csvpretty(csvfile: csvfile=sys.stdin):\\n    \"\"\" Pretty print a CSV file. \"\"\"\\n    shellish.tabulate(csv.reader(csvfile))': 422,\n",
       " 'def array_dim(arr):\\n    \"\"\"Return the size of a multidimansional array.\\n    \"\"\"\\n    dim = []\\n    while True:\\n        try:\\n            dim.append(len(arr))\\n            arr = arr[0]\\n        except TypeError:\\n            return dim': 423,\n",
       " 'def _split_str(s, n):\\n    \"\"\"\\n    split string into list of strings by specified number.\\n    \"\"\"\\n    length = len(s)\\n    return [s[i:i + n] for i in range(0, length, n)]': 424,\n",
       " 'def qsize(self):\\n        \"\"\"Return the approximate size of the queue (not reliable!).\"\"\"\\n        self.mutex.acquire()\\n        n = self._qsize()\\n        self.mutex.release()\\n        return n': 425,\n",
       " 'def is_static(self, filename):\\n        \"\"\"Check if a file is a static file (which should be copied, rather\\n        than compiled using Jinja2).\\n\\n        A file is considered static if it lives in any of the directories\\n        specified in ``staticpaths``.\\n\\n        :param filename: the name of the file to check\\n\\n        \"\"\"\\n        if self.staticpaths is None:\\n            # We\\'re not using static file support\\n            return False\\n\\n        for path in self.staticpaths:\\n            if filename.startswith(path):\\n                return True\\n        return False': 426,\n",
       " 'def serve_static(request, path, insecure=False, **kwargs):\\n    \"\"\"Collect and serve static files.\\n\\n    This view serves up static files, much like Django\\'s\\n    :py:func:`~django.views.static.serve` view, with the addition that it\\n    collects static files first (if enabled). This allows images, fonts, and\\n    other assets to be served up without first loading a page using the\\n    ``{% javascript %}`` or ``{% stylesheet %}`` template tags.\\n\\n    You can use this view by adding the following to any :file:`urls.py`::\\n\\n        urlpatterns += static(\\'static/\\', view=\\'pipeline.views.serve_static\\')\\n    \"\"\"\\n    # Follow the same logic Django uses for determining access to the\\n    # static-serving view.\\n    if not django_settings.DEBUG and not insecure:\\n        raise ImproperlyConfigured(\"The staticfiles view can only be used in \"\\n                                   \"debug mode or if the --insecure \"\\n                                   \"option of \\'runserver\\' is used\")\\n\\n    if not settings.PIPELINE_ENABLED and settings.PIPELINE_COLLECTOR_ENABLED:\\n        # Collect only the requested file, in order to serve the result as\\n        # fast as possible. This won\\'t interfere with the template tags in any\\n        # way, as those will still cause Django to collect all media.\\n        default_collector.collect(request, files=[path])\\n\\n    return serve(request, path, document_root=django_settings.STATIC_ROOT,\\n                 **kwargs)': 427,\n",
       " 'def go_to_new_line(self):\\n        \"\"\"Go to the end of the current line and create a new line\"\"\"\\n        self.stdkey_end(False, False)\\n        self.insert_text(self.get_line_separator())': 428,\n",
       " 'def get_font_list():\\n    \"\"\"Returns a sorted list of all system font names\"\"\"\\n\\n    font_map = pangocairo.cairo_font_map_get_default()\\n    font_list = [f.get_name() for f in font_map.list_families()]\\n    font_list.sort()\\n\\n    return font_list': 429,\n",
       " 'def has_parent(self, term):\\n        \"\"\"Return True if this GO object has a parent GO ID.\"\"\"\\n        for parent in self.parents:\\n            if parent.item_id == term or parent.has_parent(term):\\n                return True\\n        return False': 430,\n",
       " 'def unique_list_dicts(dlist, key):\\n    \"\"\"Return a list of dictionaries which are sorted for only unique entries.\\n\\n    :param dlist:\\n    :param key:\\n    :return list:\\n    \"\"\"\\n\\n    return list(dict((val[key], val) for val in dlist).values())': 431,\n",
       " 'def _get_local_ip():\\n        \"\"\"\\n        Get the local ip of this device\\n\\n        :return: Ip of this computer\\n        :rtype: str\\n        \"\"\"\\n        return set([x[4][0] for x in socket.getaddrinfo(\\n            socket.gethostname(),\\n            80,\\n            socket.AF_INET\\n        )]).pop()': 432,\n",
       " 'def get_public_members(obj):\\n    \"\"\"\\n    Retrieves a list of member-like objects (members or properties) that are\\n    publically exposed.\\n\\n    :param obj: The object to probe.\\n    :return:    A list of strings.\\n    \"\"\"\\n    return {attr: getattr(obj, attr) for attr in dir(obj)\\n            if not attr.startswith(\"_\")\\n            and not hasattr(getattr(obj, attr), \\'__call__\\')}': 433,\n",
       " 'def timer():\\n    \"\"\"\\n    Timer used for calculate time elapsed\\n    \"\"\"\\n    if sys.platform == \"win32\":\\n        default_timer = time.clock\\n    else:\\n        default_timer = time.time\\n\\n    return default_timer()': 434,\n",
       " 'def last_day(year=_year, month=_month):\\n    \"\"\"\\n    get the current month\\'s last day\\n    :param year:  default to current year\\n    :param month:  default to current month\\n    :return: month\\'s last day\\n    \"\"\"\\n    last_day = calendar.monthrange(year, month)[1]\\n    return datetime.date(year=year, month=month, day=last_day)': 435,\n",
       " 'def unit_tangent(self, t):\\n        \"\"\"returns the unit tangent vector of the segment at t (centered at\\n        the origin and expressed as a complex number).\"\"\"\\n        dseg = self.derivative(t)\\n        return dseg/abs(dseg)': 436,\n",
       " 'def get_obj_cols(df):\\n    \"\"\"\\n    Returns names of \\'object\\' columns in the DataFrame.\\n    \"\"\"\\n    obj_cols = []\\n    for idx, dt in enumerate(df.dtypes):\\n        if dt == \\'object\\' or is_category(dt):\\n            obj_cols.append(df.columns.values[idx])\\n\\n    return obj_cols': 437,\n",
       " 'def match_aspect_to_viewport(self):\\n        \"\"\"Updates Camera.aspect to match the viewport\\'s aspect ratio.\"\"\"\\n        viewport = self.viewport\\n        self.aspect = float(viewport.width) / viewport.height': 438,\n",
       " 'def get_property_by_name(pif, name):\\n    \"\"\"Get a property by name\"\"\"\\n    return next((x for x in pif.properties if x.name == name), None)': 439,\n",
       " 'def _uniquify(_list):\\n    \"\"\"Remove duplicates in a list.\"\"\"\\n    seen = set()\\n    result = []\\n    for x in _list:\\n        if x not in seen:\\n            result.append(x)\\n            seen.add(x)\\n    return result': 440,\n",
       " 'def fmt_duration(secs):\\n    \"\"\"Format a duration in seconds.\"\"\"\\n    return \\' \\'.join(fmt.human_duration(secs, 0, precision=2, short=True).strip().split())': 441,\n",
       " 'def get_module_path(modname):\\n    \"\"\"Return module *modname* base path\"\"\"\\n    return osp.abspath(osp.dirname(sys.modules[modname].__file__))': 442,\n",
       " 'def np_hash(a):\\n    \"\"\"Return a hash of a NumPy array.\"\"\"\\n    if a is None:\\n        return hash(None)\\n    # Ensure that hashes are equal whatever the ordering in memory (C or\\n    # Fortran)\\n    a = np.ascontiguousarray(a)\\n    # Compute the digest and return a decimal int\\n    return int(hashlib.sha1(a.view(a.dtype)).hexdigest(), 16)': 443,\n",
       " 'def get(s, delimiter=\\'\\', format=\"diacritical\"):\\n    \"\"\"Return pinyin of string, the string must be unicode\\n    \"\"\"\\n    return delimiter.join(_pinyin_generator(u(s), format=format))': 444,\n",
       " 'def center_eigenvalue_diff(mat):\\n    \"\"\"Compute the eigvals of mat and then find the center eigval difference.\"\"\"\\n    N = len(mat)\\n    evals = np.sort(la.eigvals(mat))\\n    diff = np.abs(evals[N/2] - evals[N/2-1])\\n    return diff': 445,\n",
       " 'def get_file_size(fileobj):\\n    \"\"\"\\n    Returns the size of a file-like object.\\n    \"\"\"\\n    currpos = fileobj.tell()\\n    fileobj.seek(0, 2)\\n    total_size = fileobj.tell()\\n    fileobj.seek(currpos)\\n    return total_size': 446,\n",
       " 'def array_bytes(array):\\n    \"\"\" Estimates the memory of the supplied array in bytes \"\"\"\\n    return np.product(array.shape)*np.dtype(array.dtype).itemsize': 447,\n",
       " 'def clear_es():\\n        \"\"\"Clear all indexes in the es core\"\"\"\\n        # TODO: should receive a catalog slug.\\n        ESHypermap.es.indices.delete(ESHypermap.index_name, ignore=[400, 404])\\n        LOGGER.debug(\\'Elasticsearch: Index cleared\\')': 448,\n",
       " 'def get_idx_rect(index_list):\\n    \"\"\"Extract the boundaries from a list of indexes\"\"\"\\n    rows, cols = list(zip(*[(i.row(), i.column()) for i in index_list]))\\n    return ( min(rows), max(rows), min(cols), max(cols) )': 449,\n",
       " 'def _get_node_parent(self, age, pos):\\n        \"\"\"Get the parent node of node, whch is located in tree\\'s node list.\\n\\n        Returns:\\n            object: The parent node.\\n        \"\"\"\\n        return self.nodes[age][int(pos / self.comp)]': 450,\n",
       " 'def __repr__(self):\\n        \"\"\"Return list-lookalike of representation string of objects\"\"\"\\n        strings = []\\n        for currItem in self:\\n            strings.append(\"%s\" % currItem)\\n        return \"(%s)\" % (\", \".join(strings))': 451,\n",
       " 'def dedup_list(l):\\n    \"\"\"Given a list (l) will removing duplicates from the list,\\n       preserving the original order of the list. Assumes that\\n       the list entrie are hashable.\"\"\"\\n    dedup = set()\\n    return [ x for x in l if not (x in dedup or dedup.add(x))]': 452,\n",
       " 'def tf2():\\n  \"\"\"Provide the root module of a TF-2.0 API for use within TensorBoard.\\n\\n  Returns:\\n    The root module of a TF-2.0 API, if available.\\n\\n  Raises:\\n    ImportError: if a TF-2.0 API is not available.\\n  \"\"\"\\n  # Import the `tf` compat API from this file and check if it\\'s already TF 2.0.\\n  if tf.__version__.startswith(\\'2.\\'):\\n    return tf\\n  elif hasattr(tf, \\'compat\\') and hasattr(tf.compat, \\'v2\\'):\\n    # As a fallback, try `tensorflow.compat.v2` if it\\'s defined.\\n    return tf.compat.v2\\n  raise ImportError(\\'cannot import tensorflow 2.0 API\\')': 453,\n",
       " 'def split_addresses(email_string_list):\\n    \"\"\"\\n    Converts a string containing comma separated email addresses\\n    into a list of email addresses.\\n    \"\"\"\\n    return [f for f in [s.strip() for s in email_string_list.split(\",\")] if f]': 454,\n",
       " 'def size():\\n    \"\"\"Determines the height and width of the console window\\n\\n        Returns:\\n            tuple of int: The height in lines, then width in characters\\n    \"\"\"\\n    try:\\n        assert os != \\'nt\\' and sys.stdout.isatty()\\n        rows, columns = os.popen(\\'stty size\\', \\'r\\').read().split()\\n    except (AssertionError, AttributeError, ValueError):\\n        # in case of failure, use dimensions of a full screen 13\" laptop\\n        rows, columns = DEFAULT_HEIGHT, DEFAULT_WIDTH\\n\\n    return int(rows), int(columns)': 455,\n",
       " 'def get_list_index(lst, index_or_name):\\n    \"\"\"\\n    Return the index of an element in the list.\\n\\n    Args:\\n        lst (list): The list.\\n        index_or_name (int or str): The value of the reference element, or directly its numeric index.\\n\\n    Returns:\\n        (int) The index of the element in the list.\\n    \"\"\"\\n    if isinstance(index_or_name, six.integer_types):\\n        return index_or_name\\n\\n    return lst.index(index_or_name)': 456,\n",
       " 'def write_enum(fo, datum, schema):\\n    \"\"\"An enum is encoded by a int, representing the zero-based position of\\n    the symbol in the schema.\"\"\"\\n    index = schema[\\'symbols\\'].index(datum)\\n    write_int(fo, index)': 457,\n",
       " 'def get_bottomrect_idx(self, pos):\\n        \"\"\" Determine if cursor is on bottom right corner of a hot spot.\"\"\"\\n        for i, r in enumerate(self.link_bottom_rects):\\n            if r.Contains(pos):\\n                return i\\n        return -1': 458,\n",
       " 'def _dt_to_epoch(dt):\\n        \"\"\"Convert datetime to epoch seconds.\"\"\"\\n        try:\\n            epoch = dt.timestamp()\\n        except AttributeError:  # py2\\n            epoch = (dt - datetime(1970, 1, 1)).total_seconds()\\n        return epoch': 459,\n",
       " 'def plot_epsilon_residuals(self):\\n        \"\"\"Plots the epsilon residuals for the variogram fit.\"\"\"\\n        fig = plt.figure()\\n        ax = fig.add_subplot(111)\\n        ax.scatter(range(self.epsilon.size), self.epsilon, c=\\'k\\', marker=\\'*\\')\\n        ax.axhline(y=0.0)\\n        plt.show()': 460,\n",
       " 'def _get_column_types(self, data):\\n        \"\"\"Get a list of the data types for each column in *data*.\"\"\"\\n        columns = list(zip_longest(*data))\\n        return [self._get_column_type(column) for column in columns]': 461,\n",
       " 'def forceupdate(self, *args, **kw):\\n        \"\"\"Like a bulk :meth:`forceput`.\"\"\"\\n        self._update(False, self._ON_DUP_OVERWRITE, *args, **kw)': 462,\n",
       " 'def get_nt_system_uid():\\n    \"\"\"Get the MachineGuid from\\n    HKEY_LOCAL_MACHINE\\\\Software\\\\Microsoft\\\\Cryptography\\\\MachineGuid\\n    \"\"\"\\n    try:\\n        import _winreg as winreg\\n    except ImportError:\\n        import winreg\\n    lm = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)\\n    try:\\n        key = winreg.OpenKey(lm, r\"Software\\\\Microsoft\\\\Cryptography\")\\n        try:\\n            return winreg.QueryValueEx(key, \"MachineGuid\")[0]\\n        finally:\\n            key.Close()\\n    finally:\\n        lm.Close()': 463,\n",
       " 'def _escape(s):\\n    \"\"\" Helper method that escapes parameters to a SQL query. \"\"\"\\n    e = s\\n    e = e.replace(\\'\\\\\\\\\\', \\'\\\\\\\\\\\\\\\\\\')\\n    e = e.replace(\\'\\\\n\\', \\'\\\\\\\\n\\')\\n    e = e.replace(\\'\\\\r\\', \\'\\\\\\\\r\\')\\n    e = e.replace(\"\\'\", \"\\\\\\\\\\'\")\\n    e = e.replace(\\'\"\\', \\'\\\\\\\\\"\\')\\n    return e': 464,\n",
       " 'def get_element_with_id(self, id):\\n        \"\"\"Return the element with the specified ID.\"\"\"\\n        # Should we maintain a hashmap of ids to make this more efficient? Probably overkill.\\n        # TODO: Elements can contain nested elements (captions, footnotes, table cells, etc.)\\n        return next((el for el in self.elements if el.id == id), None)': 465,\n",
       " 'def vector_distance(a, b):\\n    \"\"\"The Euclidean distance between two vectors.\"\"\"\\n    a = np.array(a)\\n    b = np.array(b)\\n    return np.linalg.norm(a - b)': 466,\n",
       " 'def url(self):\\n        \"\"\" The url of this window \"\"\"\\n        with switch_window(self._browser, self.name):\\n            return self._browser.url': 467,\n",
       " 'def euclidean(c1, c2):\\n    \"\"\"Square of the euclidean distance\"\"\"\\n    diffs = ((i - j) for i, j in zip(c1, c2))\\n    return sum(x * x for x in diffs)': 468,\n",
       " 'def get_free_memory_win():\\n    \"\"\"Return current free memory on the machine for windows.\\n\\n    Warning : this script is really not robust\\n    Return in MB unit\\n    \"\"\"\\n    stat = MEMORYSTATUSEX()\\n    ctypes.windll.kernel32.GlobalMemoryStatusEx(ctypes.byref(stat))\\n    return int(stat.ullAvailPhys / 1024 / 1024)': 469,\n",
       " 'def xpathEvalExpression(self, str):\\n        \"\"\"Evaluate the XPath expression in the given context. \"\"\"\\n        ret = libxml2mod.xmlXPathEvalExpression(str, self._o)\\n        if ret is None:raise xpathError(\\'xmlXPathEvalExpression() failed\\')\\n        return xpathObjectRet(ret)': 470,\n",
       " 'def EnumValueName(self, enum, value):\\n    \"\"\"Returns the string name of an enum value.\\n\\n    This is just a small helper method to simplify a common operation.\\n\\n    Args:\\n      enum: string name of the Enum.\\n      value: int, value of the enum.\\n\\n    Returns:\\n      string name of the enum value.\\n\\n    Raises:\\n      KeyError if either the Enum doesn\\'t exist or the value is not a valid\\n        value for the enum.\\n    \"\"\"\\n    return self.enum_types_by_name[enum].values_by_number[value].name': 471,\n",
       " 'def is_in(self, point_x, point_y):\\n        \"\"\" Test if a point is within this polygonal region \"\"\"\\n\\n        point_array = array(((point_x, point_y),))\\n        vertices = array(self.points)\\n        winding = self.inside_rule == \"winding\"\\n        result = points_in_polygon(point_array, vertices, winding)\\n        return result[0]': 472,\n",
       " 'def extent_count(self):\\n        \"\"\"\\n        Returns the volume group extent count.\\n        \"\"\"\\n        self.open()\\n        count = lvm_vg_get_extent_count(self.handle)\\n        self.close()\\n        return count': 473,\n",
       " 'def title(self):\\n        \"\"\" The title of this window \"\"\"\\n        with switch_window(self._browser, self.name):\\n            return self._browser.title': 474,\n",
       " 'def visit_BoolOp(self, node):\\n        \"\"\" Return type may come from any boolop operand. \"\"\"\\n        return sum((self.visit(value) for value in node.values), [])': 475,\n",
       " 'def __get_xml_text(root):\\n    \"\"\" Return the text for the given root node (xml.dom.minidom). \"\"\"\\n    txt = \"\"\\n    for e in root.childNodes:\\n        if (e.nodeType == e.TEXT_NODE):\\n            txt += e.data\\n    return txt': 476,\n",
       " 'def runcode(code):\\n\\t\"\"\"Run the given code line by line with printing, as list of lines, and return variable \\'ans\\'.\"\"\"\\n\\tfor line in code:\\n\\t\\tprint(\\'# \\'+line)\\n\\t\\texec(line,globals())\\n\\tprint(\\'# return ans\\')\\n\\treturn ans': 477,\n",
       " 'def fetch_event(urls):\\n    \"\"\"\\n    This parallel fetcher uses gevent one uses gevent\\n    \"\"\"\\n    rs = (grequests.get(u) for u in urls)\\n    return [content.json() for content in grequests.map(rs)]': 478,\n",
       " 'def get_order(self, codes):\\n        \"\"\"Return evidence codes in order shown in code2name.\"\"\"\\n        return sorted(codes, key=lambda e: [self.ev2idx.get(e)])': 479,\n",
       " 'def equal(list1, list2):\\n    \"\"\" takes flags returns indexes of True values \"\"\"\\n    return [item1 == item2 for item1, item2 in broadcast_zip(list1, list2)]': 480,\n",
       " 'def select(self, cmd, *args, **kwargs):\\n        \"\"\" Execute the SQL command and return the data rows as tuples\\n        \"\"\"\\n        self.cursor.execute(cmd, *args, **kwargs)\\n        return self.cursor.fetchall()': 481,\n",
       " 'def go_to_parent_directory(self):\\n        \"\"\"Go to parent directory\"\"\"\\n        self.chdir(osp.abspath(osp.join(getcwd_or_home(), os.pardir)))': 482,\n",
       " 'def _convert_to_float_if_possible(s):\\n    \"\"\"\\n    A small helper function to convert a string to a numeric value\\n    if appropriate\\n\\n    :param s: the string to be converted\\n    :type s: str\\n    \"\"\"\\n    try:\\n        ret = float(s)\\n    except (ValueError, TypeError):\\n        ret = s\\n    return ret': 483,\n",
       " 'def _top(self):\\n        \"\"\" g \"\"\"\\n        # Goto top of the list\\n        self.top.body.focus_position = 2 if self.compact is False else 0\\n        self.top.keypress(self.size, \"\")': 484,\n",
       " 'def to_gtp(coord):\\n    \"\"\"Converts from a Minigo coordinate to a GTP coordinate.\"\"\"\\n    if coord is None:\\n        return \\'pass\\'\\n    y, x = coord\\n    return \\'{}{}\\'.format(_GTP_COLUMNS[x], go.N - y)': 485,\n",
       " 'def nb_to_python(nb_path):\\n    \"\"\"convert notebook to python script\"\"\"\\n    exporter = python.PythonExporter()\\n    output, resources = exporter.from_filename(nb_path)\\n    return output': 486,\n",
       " 'def searchlast(self,n=10):\\n        \"\"\"Return the last n results (or possibly less if not found). Note that the last results are not necessarily the best ones! Depending on the search type.\"\"\"            \\n        solutions = deque([], n)\\n        for solution in self:\\n            solutions.append(solution)\\n        return solutions': 487,\n",
       " 'def to_json(df, state_index, color_index, fills):\\n        \"\"\"Transforms dataframe to json response\"\"\"\\n        records = {}\\n        for i, row in df.iterrows():\\n\\n            records[row[state_index]] = {\\n                \"fillKey\": row[color_index]\\n            }\\n\\n        return {\\n            \"data\": records,\\n            \"fills\": fills\\n        }': 488,\n",
       " 'def _text_to_graphiz(self, text):\\n        \"\"\"create a graphviz graph from text\"\"\"\\n        dot = Source(text, format=\\'svg\\')\\n        return dot.pipe().decode(\\'utf-8\\')': 489,\n",
       " 'def _round_half_hour(record):\\n    \"\"\"\\n    Round a time DOWN to half nearest half-hour.\\n    \"\"\"\\n    k = record.datetime + timedelta(minutes=-(record.datetime.minute % 30))\\n    return datetime(k.year, k.month, k.day, k.hour, k.minute, 0)': 490,\n",
       " 'def get_X0(X):\\n    \"\"\" Return zero-th element of a one-element data container.\\n    \"\"\"\\n    if pandas_available and isinstance(X, pd.DataFrame):\\n        assert len(X) == 1\\n        x = np.array(X.iloc[0])\\n    else:\\n        x, = X\\n    return x': 491,\n",
       " 'def threads_init(gtk=True):\\n    \"\"\"Enables multithreading support in Xlib and PyGTK.\\n    See the module docstring for more info.\\n    \\n    :Parameters:\\n      gtk : bool\\n        May be set to False to skip the PyGTK module.\\n    \"\"\"\\n    # enable X11 multithreading\\n    x11.XInitThreads()\\n    if gtk:\\n        from gtk.gdk import threads_init\\n        threads_init()': 492,\n",
       " 'def security(self):\\n        \"\"\"Print security object information for a pdf document\"\"\"\\n        return {k: v for i in self.pdf.resolvedObjects.items() for k, v in i[1].items()}': 493,\n",
       " 'def enable_gtk3(self, app=None):\\n        \"\"\"Enable event loop integration with Gtk3 (gir bindings).\\n\\n        Parameters\\n        ----------\\n        app : ignored\\n           Ignored, it\\'s only a placeholder to keep the call signature of all\\n           gui activation methods consistent, which simplifies the logic of\\n           supporting magics.\\n\\n        Notes\\n        -----\\n        This methods sets the PyOS_InputHook for Gtk3, which allows\\n        the Gtk3 to integrate with terminal based applications like\\n        IPython.\\n        \"\"\"\\n        from pydev_ipython.inputhookgtk3 import create_inputhook_gtk3\\n        self.set_inputhook(create_inputhook_gtk3(self._stdin_file))\\n        self._current_gui = GUI_GTK': 494,\n",
       " 'def dot(a, b):\\n    \"\"\"Take arrays `a` and `b` and form the dot product between the last axis\\n    of `a` and the first of `b`.\\n    \"\"\"\\n    b = numpy.asarray(b)\\n    return numpy.dot(a, b.reshape(b.shape[0], -1)).reshape(a.shape[:-1] + b.shape[1:])': 495,\n",
       " 'def __gzip(filename):\\n\\t\\t\"\"\" Compress a file returning the new filename (.gz)\\n\\t\\t\"\"\"\\n\\t\\tzipname = filename + \\'.gz\\'\\n\\t\\tfile_pointer = open(filename,\\'rb\\')\\n\\t\\tzip_pointer = gzip.open(zipname,\\'wb\\')\\n\\t\\tzip_pointer.writelines(file_pointer)\\n\\t\\tfile_pointer.close()\\n\\t\\tzip_pointer.close()\\n\\t\\treturn zipname': 496,\n",
       " 'def create_h5py_with_large_cache(filename, cache_size_mb):\\n    \"\"\"\\nAllows to open the hdf5 file with specified cache size\\n    \"\"\"\\n    # h5py does not allow to control the cache size from the high level\\n    # we employ the workaround\\n    # sources:\\n    #http://stackoverflow.com/questions/14653259/how-to-set-cache-settings-while-using-h5py-high-level-interface\\n    #https://groups.google.com/forum/#!msg/h5py/RVx1ZB6LpE4/KH57vq5yw2AJ\\n    propfaid = h5py.h5p.create(h5py.h5p.FILE_ACCESS)\\n    settings = list(propfaid.get_cache())\\n    settings[2] = 1024 * 1024 * cache_size_mb\\n    propfaid.set_cache(*settings)\\n    fid = h5py.h5f.create(filename, flags=h5py.h5f.ACC_EXCL, fapl=propfaid)\\n    fin = h5py.File(fid)\\n    return fin': 497,\n",
       " 'def rfft2d_freqs(h, w):\\n    \"\"\"Computes 2D spectrum frequencies.\"\"\"\\n\\n    fy = np.fft.fftfreq(h)[:, None]\\n    # when we have an odd input dimension we need to keep one additional\\n    # frequency and later cut off 1 pixel\\n    if w % 2 == 1:\\n        fx = np.fft.fftfreq(w)[: w // 2 + 2]\\n    else:\\n        fx = np.fft.fftfreq(w)[: w // 2 + 1]\\n    return np.sqrt(fx * fx + fy * fy)': 498,\n",
       " 'def md5_hash_file(fh):\\n    \"\"\"Return the md5 hash of the given file-object\"\"\"\\n    md5 = hashlib.md5()\\n    while True:\\n        data = fh.read(8192)\\n        if not data:\\n            break\\n        md5.update(data)\\n    return md5.hexdigest()': 499,\n",
       " 'def software_fibonacci(n):\\n    \"\"\" a normal old python function to return the Nth fibonacci number. \"\"\"\\n    a, b = 0, 1\\n    for i in range(n):\\n        a, b = b, a + b\\n    return a': 500,\n",
       " 'def h5ToDict(h5, readH5pyDataset=True):\\n    \"\"\" Read a hdf5 file into a dictionary \"\"\"\\n    h = h5py.File(h5, \"r\")\\n    ret = unwrapArray(h, recursive=True, readH5pyDataset=readH5pyDataset)\\n    if readH5pyDataset: h.close()\\n    return ret': 501,\n",
       " 'def current_zipfile():\\n    \"\"\"A function to vend the current zipfile, if any\"\"\"\\n    if zipfile.is_zipfile(sys.argv[0]):\\n        fd = open(sys.argv[0], \"rb\")\\n        return zipfile.ZipFile(fd)': 502,\n",
       " 'def __unixify(self, s):\\n        \"\"\" stupid windows. converts the backslash to forwardslash for consistency \"\"\"\\n        return os.path.normpath(s).replace(os.sep, \"/\")': 503,\n",
       " 'def __init__(self, encoding=\\'utf-8\\'):\\n    \"\"\"Initializes an stdin input reader.\\n\\n    Args:\\n      encoding (Optional[str]): input encoding.\\n    \"\"\"\\n    super(StdinInputReader, self).__init__(sys.stdin, encoding=encoding)': 504,\n",
       " 'def _add_hash(source):\\n    \"\"\"Add a leading hash \\'#\\' at the beginning of every line in the source.\"\"\"\\n    source = \\'\\\\n\\'.join(\\'# \\' + line.rstrip()\\n                       for line in source.splitlines())\\n    return source': 505,\n",
       " 'def apply(f, obj, *args, **kwargs):\\n    \"\"\"Apply a function in parallel to each element of the input\"\"\"\\n    return vectorize(f)(obj, *args, **kwargs)': 506,\n",
       " 'def drop_empty(rows):\\n    \"\"\"Transpose the columns into rows, remove all of the rows that are empty after the first cell, then\\n    transpose back. The result is that columns that have a header but no data in the body are removed, assuming\\n    the header is the first row. \"\"\"\\n    return zip(*[col for col in zip(*rows) if bool(filter(bool, col[1:]))])': 507,\n",
       " 'def heappush_max(heap, item):\\n    \"\"\"Push item onto heap, maintaining the heap invariant.\"\"\"\\n    heap.append(item)\\n    _siftdown_max(heap, 0, len(heap) - 1)': 508,\n",
       " 'def _heappush_max(heap, item):\\n    \"\"\" why is this not in heapq \"\"\"\\n    heap.append(item)\\n    heapq._siftdown_max(heap, 0, len(heap) - 1)': 509,\n",
       " 'def _remove_keywords(d):\\n    \"\"\"\\n    copy the dict, filter_keywords\\n\\n    Parameters\\n    ----------\\n    d : dict\\n    \"\"\"\\n    return { k:v for k, v in iteritems(d) if k not in RESERVED }': 510,\n",
       " 'def _heapify_max(x):\\n    \"\"\"Transform list into a maxheap, in-place, in O(len(x)) time.\"\"\"\\n    n = len(x)\\n    for i in reversed(range(n//2)):\\n        _siftup_max(x, i)': 511,\n",
       " 'def uniq(seq):\\n    \"\"\" Return a copy of seq without duplicates. \"\"\"\\n    seen = set()\\n    return [x for x in seq if str(x) not in seen and not seen.add(str(x))]': 512,\n",
       " 'def replace_all(filepath, searchExp, replaceExp):\\n    \"\"\"\\n    Replace all the ocurrences (in a file) of a string with another value.\\n    \"\"\"\\n    for line in fileinput.input(filepath, inplace=1):\\n        if searchExp in line:\\n            line = line.replace(searchExp, replaceExp)\\n        sys.stdout.write(line)': 513,\n",
       " 'def __call__(self, kind: Optional[str] = None, **kwargs):\\n        \"\"\"Use the plotter as callable.\"\"\"\\n        return plot(self.histogram, kind=kind, **kwargs)': 514,\n",
       " 'def ci(a, which=95, axis=None):\\n    \"\"\"Return a percentile range from an array of values.\"\"\"\\n    p = 50 - which / 2, 50 + which / 2\\n    return percentiles(a, p, axis)': 515,\n",
       " 'def dtype(self):\\n        \"\"\"Pixel data type.\"\"\"\\n        try:\\n            return self.data.dtype\\n        except AttributeError:\\n            return numpy.dtype(\\'%s%d\\' % (self._sample_type, self._sample_bytes))': 516,\n",
       " 'def tuple_search(t, i, v):\\n    \"\"\"\\n    Search tuple array by index and value\\n    :param t: tuple array\\n    :param i: index of the value in each tuple\\n    :param v: value\\n    :return: the first tuple in the array with the specific index / value\\n    \"\"\"\\n    for e in t:\\n        if e[i] == v:\\n            return e\\n    return None': 517,\n",
       " 'def from_pairs_to_array_values(pairs):\\n    \"\"\"\\n        Like from pairs but combines duplicate key values into arrays\\n    :param pairs:\\n    :return:\\n    \"\"\"\\n    result = {}\\n    for pair in pairs:\\n        result[pair[0]] = concat(prop_or([], pair[0], result), [pair[1]])\\n    return result': 518,\n",
       " 'def area(x,y):\\n    \"\"\"\\n    Calculate the area of a polygon given as x(...),y(...)\\n    Implementation of Shoelace formula\\n    \"\"\"\\n    # http://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates\\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))': 519,\n",
       " 'def _getSuperFunc(self, s, func):\\n        \"\"\"Return the the super function.\"\"\"\\n\\n        return getattr(super(self.cls(), s), func.__name__)': 520,\n",
       " 'def val_to_bin(edges, x):\\n    \"\"\"Convert axis coordinate to bin index.\"\"\"\\n    ibin = np.digitize(np.array(x, ndmin=1), edges) - 1\\n    return ibin': 521,\n",
       " 'def compare(dicts):\\n    \"\"\"Compare by iteration\"\"\"\\n\\n    common_members = {}\\n    common_keys = reduce(lambda x, y: x & y, map(dict.keys, dicts))\\n    for k in common_keys:\\n        common_members[k] = list(\\n            reduce(lambda x, y: x & y, [set(d[k]) for d in dicts]))\\n\\n    return common_members': 522,\n",
       " 'def _get_compiled_ext():\\n    \"\"\"Official way to get the extension of compiled files (.pyc or .pyo)\"\"\"\\n    for ext, mode, typ in imp.get_suffixes():\\n        if typ == imp.PY_COMPILED:\\n            return ext': 523,\n",
       " 'def list_add_capitalize(l):\\n    \"\"\"\\n    @type l: list\\n    @return: list\\n    \"\"\"\\n    nl = []\\n\\n    for i in l:\\n        nl.append(i)\\n\\n        if hasattr(i, \"capitalize\"):\\n            nl.append(i.capitalize())\\n\\n    return list(set(nl))': 524,\n",
       " 'def to_camel_case(text):\\n    \"\"\"Convert to camel case.\\n\\n    :param str text:\\n    :rtype: str\\n    :return:\\n    \"\"\"\\n    split = text.split(\\'_\\')\\n    return split[0] + \"\".join(x.title() for x in split[1:])': 525,\n",
       " 'def median(lst):\\n    \"\"\" Calcuates the median value in a @lst \"\"\"\\n    #: http://stackoverflow.com/a/24101534\\n    sortedLst = sorted(lst)\\n    lstLen = len(lst)\\n    index = (lstLen - 1) // 2\\n    if (lstLen % 2):\\n        return sortedLst[index]\\n    else:\\n        return (sortedLst[index] + sortedLst[index + 1])/2.0': 526,\n",
       " 'def _IsRetryable(error):\\n  \"\"\"Returns whether error is likely to be retryable.\"\"\"\\n  if not isinstance(error, MySQLdb.OperationalError):\\n    return False\\n  if not error.args:\\n    return False\\n  code = error.args[0]\\n  return code in _RETRYABLE_ERRORS': 527,\n",
       " 'def pid_exists(pid):\\n    \"\"\" Determines if a system process identifer exists in process table.\\n        \"\"\"\\n    try:\\n        os.kill(pid, 0)\\n    except OSError as exc:\\n        return exc.errno == errno.EPERM\\n    else:\\n        return True': 528,\n",
       " 'def getPrimeFactors(n):\\n    \"\"\"\\n    Get all the prime factor of given integer\\n    @param n integer\\n    @return list [1, ..., n]\\n    \"\"\"\\n    lo = [1]\\n    n2 = n // 2\\n    k = 2\\n    for k in range(2, n2 + 1):\\n        if (n // k)*k == n:\\n            lo.append(k)\\n    return lo + [n, ]': 529,\n",
       " 'def _isstring(dtype):\\n    \"\"\"Given a numpy dtype, determines whether it is a string. Returns True\\n    if the dtype is string or unicode.\\n    \"\"\"\\n    return dtype.type == numpy.unicode_ or dtype.type == numpy.string_': 530,\n",
       " 'def _is_override(meta, method):\\n        \"\"\"Checks whether given class or instance method has been marked\\n        with the ``@override`` decorator.\\n        \"\"\"\\n        from taipan.objective.modifiers import _OverriddenMethod\\n        return isinstance(method, _OverriddenMethod)': 531,\n",
       " 'def should_skip_logging(func):\\n    \"\"\"\\n    Should we skip logging for this handler?\\n\\n    \"\"\"\\n    disabled = strtobool(request.headers.get(\"x-request-nolog\", \"false\"))\\n    return disabled or getattr(func, SKIP_LOGGING, False)': 532,\n",
       " 'def calc_cR(Q2, sigma):\\n    \"\"\"Returns the cR statistic for the variogram fit (see [1]).\"\"\"\\n    return Q2 * np.exp(np.sum(np.log(sigma**2))/sigma.shape[0])': 533,\n",
       " 'def is_builtin_type(tp):\\n    \"\"\"Checks if the given type is a builtin one.\\n    \"\"\"\\n    return hasattr(__builtins__, tp.__name__) and tp is getattr(__builtins__, tp.__name__)': 534,\n",
       " 'def forget_coords(self):\\n        \"\"\"Forget all loaded coordinates.\"\"\"\\n        self.w.ntotal.set_text(\\'0\\')\\n        self.coords_dict.clear()\\n        self.redo()': 535,\n",
       " 'def flat_list(lst):\\n    \"\"\"This function flatten given nested list.\\n    Argument:\\n        nested list\\n    Returns:\\n        flat list\\n    \"\"\"\\n    if isinstance(lst, list):\\n        for item in lst:\\n            for i in flat_list(item):\\n                yield i\\n    else:\\n        yield lst': 536,\n",
       " 'def safe_exit(output):\\n    \"\"\"exit without breaking pipes.\"\"\"\\n    try:\\n        sys.stdout.write(output)\\n        sys.stdout.flush()\\n    except IOError:\\n        pass': 537,\n",
       " 'def imflip(img, direction=\\'horizontal\\'):\\n    \"\"\"Flip an image horizontally or vertically.\\n\\n    Args:\\n        img (ndarray): Image to be flipped.\\n        direction (str): The flip direction, either \"horizontal\" or \"vertical\".\\n\\n    Returns:\\n        ndarray: The flipped image.\\n    \"\"\"\\n    assert direction in [\\'horizontal\\', \\'vertical\\']\\n    if direction == \\'horizontal\\':\\n        return np.flip(img, axis=1)\\n    else:\\n        return np.flip(img, axis=0)': 538,\n",
       " 'def get_order(self):\\n        \"\"\"\\n        Return a list of dicionaries. See `set_order`.\\n        \"\"\"\\n        return [dict(reverse=r[0], key=r[1]) for r in self.get_model()]': 539,\n",
       " 'def hflip(img):\\n    \"\"\"Horizontally flip the given PIL Image.\\n\\n    Args:\\n        img (PIL Image): Image to be flipped.\\n\\n    Returns:\\n        PIL Image:  Horizontall flipped image.\\n    \"\"\"\\n    if not _is_pil_image(img):\\n        raise TypeError(\\'img should be PIL Image. Got {}\\'.format(type(img)))\\n\\n    return img.transpose(Image.FLIP_LEFT_RIGHT)': 540,\n",
       " 'def get_document_frequency(self, term):\\n        \"\"\"\\n        Returns the number of documents the specified term appears in.\\n        \"\"\"\\n        if term not in self._terms:\\n            raise IndexError(TERM_DOES_NOT_EXIST)\\n        else:\\n            return len(self._terms[term])': 541,\n",
       " 'def destroy(self):\\n        \"\"\" Cleanup the activty lifecycle listener \"\"\"\\n        if self.widget:\\n            self.set_active(False)\\n        super(AndroidBarcodeView, self).destroy()': 542,\n",
       " 'def one_for_all(self, deps):\\n        \"\"\"Because there are dependencies that depend on other\\n        dependencies are created lists into other lists.\\n        Thus creating this loop create one-dimensional list and\\n        remove double packages from dependencies.\\n        \"\"\"\\n        requires, dependencies = [], []\\n        deps.reverse()\\n        # Inverting the list brings the\\n        # dependencies in order to be installed.\\n        requires = Utils().dimensional_list(deps)\\n        dependencies = Utils().remove_dbs(requires)\\n        return dependencies': 543,\n",
       " 'def trigger_fullscreen_action(self, fullscreen):\\n        \"\"\"\\n        Toggle fullscreen from outside the GUI,\\n        causes the GUI to updated and run all its actions.\\n        \"\"\"\\n        action = self.action_group.get_action(\\'fullscreen\\')\\n        action.set_active(fullscreen)': 544,\n",
       " 'def download_json(local_filename, url, clobber=False):\\n    \"\"\"Download the given JSON file, and pretty-print before we output it.\"\"\"\\n    with open(local_filename, \\'w\\') as json_file:\\n        json_file.write(json.dumps(requests.get(url).json(), sort_keys=True, indent=2, separators=(\\',\\', \\': \\')))': 545,\n",
       " 'def is_password_valid(password):\\n    \"\"\"\\n    Check if a password is valid\\n    \"\"\"\\n    pattern = re.compile(r\"^.{4,75}$\")\\n    return bool(pattern.match(password))': 546,\n",
       " 'def drag_and_drop(self, droppable):\\n        \"\"\"\\n        Performs drag a element to another elmenet.\\n\\n        Currently works only on Chrome driver.\\n        \"\"\"\\n        self.scroll_to()\\n        ActionChains(self.parent.driver).drag_and_drop(self._element, droppable._element).perform()': 547,\n",
       " 'def url_encode(url):\\n    \"\"\"\\n    Convert special characters using %xx escape.\\n\\n    :param url: str\\n    :return: str - encoded url\\n    \"\"\"\\n    if isinstance(url, text_type):\\n        url = url.encode(\\'utf8\\')\\n    return quote(url, \\':/%?&=\\')': 548,\n",
       " 'def ExecuteRaw(self, position, command):\\n    \"\"\"Send a command string to gdb.\"\"\"\\n    self.EnsureGdbPosition(position[0], None, None)\\n    return gdb.execute(command, to_string=True)': 549,\n",
       " 'def finish():\\n    \"\"\"Print warning about interrupt and empty the job queue.\"\"\"\\n    out.warn(\"Interrupted!\")\\n    for t in threads:\\n        t.stop()\\n    jobs.clear()\\n    out.warn(\"Waiting for download threads to finish.\")': 550,\n",
       " 'def rlognormal(mu, tau, size=None):\\n    \"\"\"\\n    Return random lognormal variates.\\n    \"\"\"\\n\\n    return np.random.lognormal(mu, np.sqrt(1. / tau), size)': 551,\n",
       " 'def calculate_boundingbox(lng, lat, miles):\\n    \"\"\"\\n    Given a latitude, longitude and a distance in miles, calculate\\n    the co-ordinates of the bounding box 2*miles on long each side with the\\n    given co-ordinates at the center.\\n    \"\"\"\\n\\n    latChange = change_in_latitude(miles)\\n    latSouth = lat - latChange\\n    latNorth = lat + latChange\\n    lngChange = change_in_longitude(lat, miles)\\n    lngWest = lng + lngChange\\n    lngEast = lng - lngChange\\n    return (lngWest, latSouth, lngEast, latNorth)': 552,\n",
       " 'def uniqueID(size=6, chars=string.ascii_uppercase + string.digits):\\n    \"\"\"A quick and dirty way to get a unique string\"\"\"\\n    return \\'\\'.join(random.choice(chars) for x in xrange(size))': 553,\n",
       " 'def toBase64(s):\\n    \"\"\"Represent string / bytes s as base64, omitting newlines\"\"\"\\n    if isinstance(s, str):\\n        s = s.encode(\"utf-8\")\\n    return binascii.b2a_base64(s)[:-1]': 554,\n",
       " 'def _generate_key_map(entity_list, key, entity_class):\\n    \"\"\" Helper method to generate map from key to entity object for given list of dicts.\\n\\n    Args:\\n      entity_list: List consisting of dict.\\n      key: Key in each dict which will be key in the map.\\n      entity_class: Class representing the entity.\\n\\n    Returns:\\n      Map mapping key to entity object.\\n    \"\"\"\\n\\n    key_map = {}\\n    for obj in entity_list:\\n      key_map[obj[key]] = entity_class(**obj)\\n\\n    return key_map': 555,\n",
       " 'def intersect(d1, d2):\\n    \"\"\"Intersect dictionaries d1 and d2 by key *and* value.\"\"\"\\n    return dict((k, d1[k]) for k in d1 if k in d2 and d1[k] == d2[k])': 556,\n",
       " 'def _rndPointDisposition(dx, dy):\\n        \"\"\"Return random disposition point.\"\"\"\\n        x = int(random.uniform(-dx, dx))\\n        y = int(random.uniform(-dy, dy))\\n        return (x, y)': 557,\n",
       " 'def sine_wave(frequency):\\n  \"\"\"Emit a sine wave at the given frequency.\"\"\"\\n  xs = tf.reshape(tf.range(_samples(), dtype=tf.float32), [1, _samples(), 1])\\n  ts = xs / FLAGS.sample_rate\\n  return tf.sin(2 * math.pi * frequency * ts)': 558,\n",
       " 'def bitsToString(arr):\\n  \"\"\"Returns a string representing a numpy array of 0\\'s and 1\\'s\"\"\"\\n  s = array(\\'c\\',\\'.\\'*len(arr))\\n  for i in xrange(len(arr)):\\n    if arr[i] == 1:\\n      s[i]=\\'*\\'\\n  return s': 559,\n",
       " 'def find_nearest_index(arr, value):\\n    \"\"\"For a given value, the function finds the nearest value\\n    in the array and returns its index.\"\"\"\\n    arr = np.array(arr)\\n    index = (abs(arr-value)).argmin()\\n    return index': 560,\n",
       " 'def make_file_read_only(file_path):\\n    \"\"\"\\n    Removes the write permissions for the given file for owner, groups and others.\\n\\n    :param file_path: The file whose privileges are revoked.\\n    :raise FileNotFoundError: If the given file does not exist.\\n    \"\"\"\\n    old_permissions = os.stat(file_path).st_mode\\n    os.chmod(file_path, old_permissions & ~WRITE_PERMISSIONS)': 561,\n",
       " 'def copy(self):\\n        \"\"\"\\n        Return a copy of the dictionary.\\n\\n        This is a middle-deep copy; the copy is independent of the original in\\n        all attributes that have mutable types except for:\\n\\n        * The values in the dictionary\\n\\n        Note that the Python functions :func:`py:copy.copy` and\\n        :func:`py:copy.deepcopy` can be used to create completely shallow or\\n        completely deep copies of objects of this class.\\n        \"\"\"\\n        result = NocaseDict()\\n        result._data = self._data.copy()  # pylint: disable=protected-access\\n        return result': 562,\n",
       " 'def longest_run(da, dim=\\'time\\'):\\n    \"\"\"Return the length of the longest consecutive run of True values.\\n\\n        Parameters\\n        ----------\\n        arr : N-dimensional array (boolean)\\n          Input array\\n        dim : Xarray dimension (default = \\'time\\')\\n          Dimension along which to calculate consecutive run\\n\\n        Returns\\n        -------\\n        N-dimensional array (int)\\n          Length of longest run of True values along dimension\\n        \"\"\"\\n\\n    d = rle(da, dim=dim)\\n    rl_long = d.max(dim=dim)\\n\\n    return rl_long': 563,\n",
       " 'def fopenat(base_fd, path):\\n    \"\"\"\\n    Does openat read-only, then does fdopen to get a file object\\n    \"\"\"\\n\\n    return os.fdopen(openat(base_fd, path, os.O_RDONLY), \\'rb\\')': 564,\n",
       " 'def vars_class(cls):\\n    \"\"\"Return a dict of vars for the given class, including all ancestors.\\n\\n    This differs from the usual behaviour of `vars` which returns attributes\\n    belonging to the given class and not its ancestors.\\n    \"\"\"\\n    return dict(chain.from_iterable(\\n        vars(cls).items() for cls in reversed(cls.__mro__)))': 565,\n",
       " 'def flatten(l, types=(list, float)):\\n    \"\"\"\\n    Flat nested list of lists into a single list.\\n    \"\"\"\\n    l = [item if isinstance(item, types) else [item] for item in l]\\n    return [item for sublist in l for item in sublist]': 566,\n",
       " 'def _ensure_element(tup, elem):\\n    \"\"\"\\n    Create a tuple containing all elements of tup, plus elem.\\n\\n    Returns the new tuple and the index of elem in the new tuple.\\n    \"\"\"\\n    try:\\n        return tup, tup.index(elem)\\n    except ValueError:\\n        return tuple(chain(tup, (elem,))), len(tup)': 567,\n",
       " 'def bitdepth(self):\\n        \"\"\"The number of bits per sample in the audio encoding (an int).\\n        Only available for certain file formats (zero where\\n        unavailable).\\n        \"\"\"\\n        if hasattr(self.mgfile.info, \\'bits_per_sample\\'):\\n            return self.mgfile.info.bits_per_sample\\n        return 0': 568,\n",
       " 'def to_python(self, value):\\n        \"\"\"\\n        Convert a string from a form into an Enum value.\\n        \"\"\"\\n        if value is None:\\n            return value\\n        if isinstance(value, self.enum):\\n            return value\\n        return self.enum[value]': 569,\n",
       " 'def force_iterable(f):\\n    \"\"\"Will make any functions return an iterable objects by wrapping its result in a list.\"\"\"\\n    def wrapper(*args, **kwargs):\\n        r = f(*args, **kwargs)\\n        if hasattr(r, \\'__iter__\\'):\\n            return r\\n        else:\\n            return [r]\\n    return wrapper': 570,\n",
       " 'def _read_date_from_string(str1):\\n    \"\"\"\\n    Reads the date from a string in the format YYYY/MM/DD and returns\\n    :class: datetime.date\\n    \"\"\"\\n    full_date = [int(x) for x in str1.split(\\'/\\')]\\n    return datetime.date(full_date[0], full_date[1], full_date[2])': 571,\n",
       " 'def wr_row_mergeall(self, worksheet, txtstr, fmt, row_idx):\\n        \"\"\"Merge all columns and place text string in widened cell.\"\"\"\\n        hdridxval = len(self.hdrs) - 1\\n        worksheet.merge_range(row_idx, 0, row_idx, hdridxval, txtstr, fmt)\\n        return row_idx + 1': 572,\n",
       " 'def dates_in_range(start_date, end_date):\\n    \"\"\"Returns all dates between two dates.\\n\\n    Inclusive of the start date but not the end date.\\n\\n    Args:\\n        start_date (datetime.date)\\n        end_date (datetime.date)\\n\\n    Returns:\\n        (list) of datetime.date objects\\n    \"\"\"\\n    return [\\n        start_date + timedelta(n)\\n        for n in range(int((end_date - start_date).days))\\n    ]': 573,\n",
       " 'def unique(input_list):\\n    \"\"\"\\n    Return a list of unique items (similar to set functionality).\\n\\n    Parameters\\n    ----------\\n    input_list : list\\n        A list containg some items that can occur more than once.\\n\\n    Returns\\n    -------\\n    list\\n        A list with only unique occurances of an item.\\n\\n    \"\"\"\\n    output = []\\n    for item in input_list:\\n        if item not in output:\\n            output.append(item)\\n    return output': 574,\n",
       " 'def sort_fn_list(fn_list):\\n    \"\"\"Sort input filename list by datetime\\n    \"\"\"\\n    dt_list = get_dt_list(fn_list)\\n    fn_list_sort = [fn for (dt,fn) in sorted(zip(dt_list,fn_list))]\\n    return fn_list_sort': 575,\n",
       " 'def fast_distinct(self):\\n        \"\"\"\\n        Because standard distinct used on the all fields are very slow and works only with PostgreSQL database\\n        this method provides alternative to the standard distinct method.\\n        :return: qs with unique objects\\n        \"\"\"\\n        return self.model.objects.filter(pk__in=self.values_list(\\'pk\\', flat=True))': 576,\n",
       " 'def Proxy(f):\\n  \"\"\"A helper to create a proxy method in a class.\"\"\"\\n\\n  def Wrapped(self, *args):\\n    return getattr(self, f)(*args)\\n\\n  return Wrapped': 577,\n",
       " 'def metres2latlon(mx, my, origin_shift= 2 * pi * 6378137 / 2.0):\\n    \"\"\"Converts XY point from Spherical Mercator EPSG:900913 to lat/lon in\\n    WGS84 Datum\"\"\"\\n    lon = (mx / origin_shift) * 180.0\\n    lat = (my / origin_shift) * 180.0\\n\\n    lat = 180 / pi * (2 * atan( exp( lat * pi / 180.0)) - pi / 2.0)\\n    return lat, lon': 578,\n",
       " 'def next (self):    # File-like object.\\n\\n        \"\"\"This is to support iterators over a file-like object.\\n        \"\"\"\\n\\n        result = self.readline()\\n        if result == self._empty_buffer:\\n            raise StopIteration\\n        return result': 579,\n",
       " 'def _factor_generator(n):\\n    \"\"\"\\n    From a given natural integer, returns the prime factors and their multiplicity\\n    :param n: Natural integer\\n    :return:\\n    \"\"\"\\n    p = prime_factors(n)\\n    factors = {}\\n    for p1 in p:\\n        try:\\n            factors[p1] += 1\\n        except KeyError:\\n            factors[p1] = 1\\n    return factors': 580,\n",
       " 'def unique(seq):\\n    \"\"\"Return the unique elements of a collection even if those elements are\\n       unhashable and unsortable, like dicts and sets\"\"\"\\n    cleaned = []\\n    for each in seq:\\n        if each not in cleaned:\\n            cleaned.append(each)\\n    return cleaned': 581,\n",
       " 'def get_md5_for_file(file):\\n    \"\"\"Get the md5 hash for a file.\\n\\n    :param file: the file to get the md5 hash for\\n    \"\"\"\\n    md5 = hashlib.md5()\\n\\n    while True:\\n        data = file.read(md5.block_size)\\n\\n        if not data:\\n            break\\n\\n        md5.update(data)\\n\\n    return md5.hexdigest()': 582,\n",
       " 'def _rank(self, ranking, n):\\n    \"\"\" return the first n sentences with highest ranking \"\"\"\\n    return nlargest(n, ranking, key=ranking.get)': 583,\n",
       " 'def drop_indexes(self):\\n        \"\"\"Delete all indexes for the database\"\"\"\\n        LOG.warning(\"Dropping all indexe\")\\n        for collection_name in INDEXES:\\n            LOG.warning(\"Dropping all indexes for collection name %s\", collection_name)\\n            self.db[collection_name].drop_indexes()': 584,\n",
       " 'def last(self):\\n        \"\"\"Get the last object in file.\"\"\"\\n        # End of file\\n        self.__file.seek(0, 2)\\n\\n        # Get the last struct\\n        data = self.get(self.length - 1)\\n\\n        return data': 585,\n",
       " 'def debug_src(src, pm=False, globs=None):\\n    \"\"\"Debug a single doctest docstring, in argument `src`\\'\"\"\"\\n    testsrc = script_from_examples(src)\\n    debug_script(testsrc, pm, globs)': 586,\n",
       " 'def get_last_row(dbconn, tablename, n=1, uuid=None):\\n    \"\"\"\\n    Returns the last `n` rows in the table\\n    \"\"\"\\n    return fetch(dbconn, tablename, n, uuid, end=True)': 587,\n",
       " 'def save(self, fname: str):\\n        \"\"\"\\n        Saves this training state to fname.\\n        \"\"\"\\n        with open(fname, \"wb\") as fp:\\n            pickle.dump(self, fp)': 588,\n",
       " 'def display_len(text):\\n    \"\"\"\\n    Get the display length of a string. This can differ from the character\\n    length if the string contains wide characters.\\n    \"\"\"\\n    text = unicodedata.normalize(\\'NFD\\', text)\\n    return sum(char_width(char) for char in text)': 589,\n",
       " 'def isString(s):\\n    \"\"\"Convenience method that works with all 2.x versions of Python\\n    to determine whether or not something is stringlike.\"\"\"\\n    try:\\n        return isinstance(s, unicode) or isinstance(s, basestring)\\n    except NameError:\\n        return isinstance(s, str)': 590,\n",
       " 'def rel_path(filename):\\n    \"\"\"\\n    Function that gets relative path to the filename\\n    \"\"\"\\n    return os.path.join(os.getcwd(), os.path.dirname(__file__), filename)': 591,\n",
       " 'def const_rand(size, seed=23980):\\n    \"\"\" Generate a random array with a fixed seed.\\n    \"\"\"\\n    old_seed = np.random.seed()\\n    np.random.seed(seed)\\n    out = np.random.rand(size)\\n    np.random.seed(old_seed)\\n    return out': 592,\n",
       " 'def get_action_methods(self):\\n        \"\"\"\\n        return a list of methods on this class for executing actions.\\n        methods are return as a list of (name, func) tuples\\n        \"\"\"\\n        return [(name, getattr(self, name))\\n                for name, _ in Action.get_command_types()]': 593,\n",
       " 'def start():\\n    \"\"\"Starts the web server.\"\"\"\\n    global app\\n    bottle.run(app, host=conf.WebHost, port=conf.WebPort,\\n               debug=conf.WebAutoReload, reloader=conf.WebAutoReload,\\n               quiet=conf.WebQuiet)': 594,\n",
       " 'async def sysinfo(dev: Device):\\n    \"\"\"Print out system information (version, MAC addrs).\"\"\"\\n    click.echo(await dev.get_system_info())\\n    click.echo(await dev.get_interface_information())': 595,\n",
       " 'def count_(self):\\n        \"\"\"\\n        Returns the number of rows of the main dataframe\\n        \"\"\"\\n        try:\\n            num = len(self.df.index)\\n        except Exception as e:\\n            self.err(e, \"Can not count data\")\\n            return\\n        return num': 596,\n",
       " 'def post_object_async(self, path, **kwds):\\n    \"\"\"POST to an object.\"\"\"\\n    return self.do_request_async(self.api_url + path, \\'POST\\', **kwds)': 597,\n",
       " 'def findfirst(f, coll):\\n    \"\"\"Return first occurrence matching f, otherwise None\"\"\"\\n    result = list(dropwhile(f, coll))\\n    return result[0] if result else None': 598,\n",
       " 'def start(self):\\n        \"\"\"Create a background thread for httpd and serve \\'forever\\'\"\"\"\\n        self._process = threading.Thread(target=self._background_runner)\\n        self._process.start()': 599,\n",
       " 'def return_letters_from_string(text):\\n    \"\"\"Get letters from string only.\"\"\"\\n    out = \"\"\\n    for letter in text:\\n        if letter.isalpha():\\n            out += letter\\n    return out': 600,\n",
       " 'def parse_querystring(self, req, name, field):\\n        \"\"\"Pull a querystring value from the request.\"\"\"\\n        return core.get_value(req.args, name, field)': 601,\n",
       " 'def inject_into_urllib3():\\n    \"\"\"\\n    Monkey-patch urllib3 with SecureTransport-backed SSL-support.\\n    \"\"\"\\n    util.ssl_.SSLContext = SecureTransportContext\\n    util.HAS_SNI = HAS_SNI\\n    util.ssl_.HAS_SNI = HAS_SNI\\n    util.IS_SECURETRANSPORT = True\\n    util.ssl_.IS_SECURETRANSPORT = True': 602,\n",
       " 'def strip_spaces(x):\\n    \"\"\"\\n    Strips spaces\\n    :param x:\\n    :return:\\n    \"\"\"\\n    x = x.replace(b\\' \\', b\\'\\')\\n    x = x.replace(b\\'\\\\t\\', b\\'\\')\\n    return x': 603,\n",
       " 'def argsort_indices(a, axis=-1):\\n    \"\"\"Like argsort, but returns an index suitable for sorting the\\n    the original array even if that array is multidimensional\\n    \"\"\"\\n    a = np.asarray(a)\\n    ind = list(np.ix_(*[np.arange(d) for d in a.shape]))\\n    ind[axis] = a.argsort(axis)\\n    return tuple(ind)': 604,\n",
       " 'def file_or_default(path, default, function = None):\\n    \"\"\" Return a default value if a file does not exist \"\"\"\\n    try:\\n        result = file_get_contents(path)\\n        if function != None: return function(result)\\n        return result\\n    except IOError as e:\\n        if e.errno == errno.ENOENT: return default\\n        raise': 605,\n",
       " 'def this_quarter():\\n        \"\"\" Return start and end date of this quarter. \"\"\"\\n        since = TODAY + delta(day=1)\\n        while since.month % 3 != 0:\\n            since -= delta(months=1)\\n        until = since + delta(months=3)\\n        return Date(since), Date(until)': 606,\n",
       " 'def strToBool(val):\\n    \"\"\"\\n    Helper function to turn a string representation of \"true\" into\\n    boolean True.\\n    \"\"\"\\n    if isinstance(val, str):\\n        val = val.lower()\\n\\n    return val in [\\'true\\', \\'on\\', \\'yes\\', True]': 607,\n",
       " 'def clear_list_value(self, value):\\n        \"\"\"\\n        Clean the argument value to eliminate None or Falsy values if needed.\\n        \"\"\"\\n        # Don\\'t go any further: this value is empty.\\n        if not value:\\n            return self.empty_value\\n        # Clean empty items if wanted\\n        if self.clean_empty:\\n            value = [v for v in value if v]\\n        return value or self.empty_value': 608,\n",
       " 'def call_out(command):\\n  \"\"\"\\n  Run the given command (with shell=False) and return a tuple of\\n  (int returncode, str output). Strip the output of enclosing whitespace.\\n  \"\"\"\\n  # start external command process\\n  p = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n\\n  # get outputs\\n  out, _ = p.communicate()\\n\\n  return p.returncode, out.strip()': 609,\n",
       " 'def run(self, value):\\n        \"\"\" Determines if value value is empty.\\n        Keyword arguments:\\n        value str -- the value of the associated field to compare\\n        \"\"\"\\n        if self.pass_ and not value.strip():\\n            return True\\n\\n        if not value:\\n            return False\\n        return True': 610,\n",
       " 'def _string_width(self, s):\\n        \"\"\"Get width of a string in the current font\"\"\"\\n        s = str(s)\\n        w = 0\\n        for i in s:\\n            w += self.character_widths[i]\\n        return w * self.font_size / 1000.0': 611,\n",
       " 'def find_le(a, x):\\n    \"\"\"Find rightmost value less than or equal to x.\"\"\"\\n    i = bs.bisect_right(a, x)\\n    if i: return i - 1\\n    raise ValueError': 612,\n",
       " 'def crop_box(im, box=False, **kwargs):\\n    \"\"\"Uses box coordinates to crop an image without resizing it first.\"\"\"\\n    if box:\\n        im = im.crop(box)\\n    return im': 613,\n",
       " 'def datatype(dbtype, description, cursor):\\n    \"\"\"Google AppEngine Helper to convert a data type into a string.\"\"\"\\n    dt = cursor.db.introspection.get_field_type(dbtype, description)\\n    if type(dt) is tuple:\\n        return dt[0]\\n    else:\\n        return dt': 614,\n",
       " 'def normalize(im, invert=False, scale=None, dtype=np.float64):\\n    \"\"\"\\n    Normalize a field to a (min, max) exposure range, default is (0, 255).\\n    (min, max) exposure values. Invert the image if requested.\\n    \"\"\"\\n    if dtype not in {np.float16, np.float32, np.float64}:\\n        raise ValueError(\\'dtype must be numpy.float16, float32, or float64.\\')\\n    out = im.astype(\\'float\\').copy()\\n\\n    scale = scale or (0.0, 255.0)\\n    l, u = (float(i) for i in scale)\\n    out = (out - l) / (u - l)\\n    if invert:\\n        out = -out + (out.max() + out.min())\\n    return out.astype(dtype)': 615,\n",
       " 'def end_index(self):\\n        \"\"\"Return the 1-based index of the last item on this page.\"\"\"\\n        paginator = self.paginator\\n        # Special case for the last page because there can be orphans.\\n        if self.number == paginator.num_pages:\\n            return paginator.count\\n        return (self.number - 1) * paginator.per_page + paginator.first_page': 616,\n",
       " 'def filtered_image(self, im):\\n        \"\"\"Returns a filtered image after applying the Fourier-space filters\"\"\"\\n        q = np.fft.fftn(im)\\n        for k,v in self.filters:\\n            q[k] -= v\\n        return np.real(np.fft.ifftn(q))': 617,\n",
       " 'def get_buffer(self, data_np, header, format, output=None):\\n        \"\"\"Get image as a buffer in (format).\\n        Format should be \\'jpeg\\', \\'png\\', etc.\\n        \"\"\"\\n        if not have_pil:\\n            raise Exception(\"Install PIL to use this method\")\\n        image = PILimage.fromarray(data_np)\\n        buf = output\\n        if buf is None:\\n            buf = BytesIO()\\n        image.save(buf, format)\\n        return buf': 618,\n",
       " 'def uint32_to_uint8(cls, img):\\n        \"\"\"\\n        Cast uint32 RGB image to 4 uint8 channels.\\n        \"\"\"\\n        return np.flipud(img.view(dtype=np.uint8).reshape(img.shape + (4,)))': 619,\n",
       " 'def get_user_by_id(self, id):\\n        \"\"\"Retrieve a User object by ID.\"\"\"\\n        return self.db_adapter.get_object(self.UserClass, id=id)': 620,\n",
       " 'def reduce_fn(x):\\n    \"\"\"\\n    Aggregation function to get the first non-zero value.\\n    \"\"\"\\n    values = x.values if pd and isinstance(x, pd.Series) else x\\n    for v in values:\\n        if not is_nan(v):\\n            return v\\n    return np.NaN': 621,\n",
       " 'def _EnforceProcessMemoryLimit(self, memory_limit):\\n    \"\"\"Enforces a process memory limit.\\n\\n    Args:\\n      memory_limit (int): maximum number of bytes the process is allowed\\n          to allocate, where 0 represents no limit and None a default of\\n          4 GiB.\\n    \"\"\"\\n    # Resource is not supported on Windows.\\n    if resource:\\n      if memory_limit is None:\\n        memory_limit = 4 * 1024 * 1024 * 1024\\n      elif memory_limit == 0:\\n        memory_limit = resource.RLIM_INFINITY\\n\\n      resource.setrlimit(resource.RLIMIT_DATA, (memory_limit, memory_limit))': 622,\n",
       " 'def check_many(self, domains):\\n        \"\"\"\\n        Check availability for a number of domains. Returns a dictionary\\n        mapping the domain names to their statuses as a string\\n        (\"active\"/\"free\").\\n        \"\"\"\\n        return dict((item.domain, item.status) for item in self.check_domain_request(domains))': 623,\n",
       " 'def end_block(self):\\n        \"\"\"Ends an indentation block, leaving an empty line afterwards\"\"\"\\n        self.current_indent -= 1\\n\\n        # If we did not add a new line automatically yet, now it\\'s the time!\\n        if not self.auto_added_line:\\n            self.writeln()\\n            self.auto_added_line = True': 624,\n",
       " 'def get_weights_from_kmodel(kmodel):\\n        \"\"\"\\n        Convert kmodel\\'s weights to bigdl format.\\n        We are supposing the order is the same as the execution order.\\n        :param kmodel: keras model\\n        :return: list of ndarray\\n        \"\"\"\\n        layers_with_weights = [layer for layer in kmodel.layers if layer.weights]\\n        bweights = []\\n        for klayer in layers_with_weights:\\n            # bws would be [weights, bias] or [weights]\\n            bws = WeightsConverter.get_bigdl_weights_from_klayer(klayer)\\n            for w in bws:\\n                bweights.append(w)\\n        return bweights': 625,\n",
       " 'def MultiArgMax(x):\\n  \"\"\"\\n  Get tuple (actually a generator) of indices where the max value of\\n  array x occurs. Requires that x have a max() method, as x.max()\\n  (in the case of NumPy) is much faster than max(x).\\n  For a simpler, faster argmax when there is only a single maximum entry,\\n  or when knowing only the first index where the maximum occurs,\\n  call argmax() on a NumPy array.\\n\\n  :param x: Any sequence that has a max() method.\\n  :returns: Generator with the indices where the max value occurs.\\n  \"\"\"\\n  m = x.max()\\n  return (i for i, v in enumerate(x) if v == m)': 626,\n",
       " 'def __init__(self, find, subcon):\\n        \"\"\"Initialize.\"\"\"\\n        Subconstruct.__init__(self, subcon)\\n        self.find = find': 627,\n",
       " 'def value(self):\\n        \"\"\"Value of property.\"\"\"\\n        if self._prop.fget is None:\\n            raise AttributeError(\\'Unable to read attribute\\')\\n        return self._prop.fget(self._obj)': 628,\n",
       " 'def prepend_line(filepath, line):\\n    \"\"\"Rewrite a file adding a line to its beginning.\\n    \"\"\"\\n    with open(filepath) as f:\\n        lines = f.readlines()\\n\\n    lines.insert(0, line)\\n\\n    with open(filepath, \\'w\\') as f:\\n        f.writelines(lines)': 629,\n",
       " 'def find_coord_vars(ncds):\\n    \"\"\"\\n    Finds all coordinate variables in a dataset.\\n\\n    A variable with the same name as a dimension is called a coordinate variable.\\n    \"\"\"\\n    coord_vars = []\\n\\n    for d in ncds.dimensions:\\n        if d in ncds.variables and ncds.variables[d].dimensions == (d,):\\n            coord_vars.append(ncds.variables[d])\\n\\n    return coord_vars': 630,\n",
       " 'def get_func_posargs_name(f):\\n    \"\"\"Returns the name of the function f\\'s keyword argument parameter if it exists, otherwise None\"\"\"\\n    sigparams = inspect.signature(f).parameters\\n    for p in sigparams:\\n        if sigparams[p].kind == inspect.Parameter.VAR_POSITIONAL:\\n            return sigparams[p].name\\n    return None': 631,\n",
       " 'def check_git():\\n    \"\"\"Check if git command is available.\"\"\"\\n    try:\\n        with open(os.devnull, \"wb\") as devnull:\\n            subprocess.check_call([\"git\", \"--version\"], stdout=devnull, stderr=devnull)\\n    except:\\n        raise RuntimeError(\"Please make sure git is installed and on your path.\")': 632,\n",
       " 'def as_list(self):\\n        \"\"\"Return all child objects in nested lists of strings.\"\"\"\\n        return [self.name, self.value, [x.as_list for x in self.children]]': 633,\n",
       " 'def positive_integer(anon, obj, field, val):\\n    \"\"\"\\n    Returns a random positive integer (for a Django PositiveIntegerField)\\n    \"\"\"\\n    return anon.faker.positive_integer(field=field)': 634,\n",
       " 'def method(func):\\n    \"\"\"Wrap a function as a method.\"\"\"\\n    attr = abc.abstractmethod(func)\\n    attr.__imethod__ = True\\n    return attr': 635,\n",
       " 'def get_lines(handle, line):\\n    \"\"\"\\n    Get zero-indexed line from an open file-like.\\n    \"\"\"\\n    for i, l in enumerate(handle):\\n        if i == line:\\n            return l': 636,\n",
       " 'def is_int(value):\\n    \"\"\"Return `True` if ``value`` is an integer.\"\"\"\\n    if isinstance(value, bool):\\n        return False\\n    try:\\n        int(value)\\n        return True\\n    except (ValueError, TypeError):\\n        return False': 637,\n",
       " 'def norm(x, mu, sigma=1.0):\\n    \"\"\" Scipy norm function \"\"\"\\n    return stats.norm(loc=mu, scale=sigma).pdf(x)': 638,\n",
       " 'def add_noise(Y, sigma):\\n    \"\"\"Adds noise to Y\"\"\"\\n    return Y + np.random.normal(0, sigma, Y.shape)': 639,\n",
       " 'def spline_interpolate_by_datetime(datetime_axis, y_axis, datetime_new_axis):\\n    \"\"\"A datetime-version that takes datetime object list as x_axis\\n    \"\"\"\\n    numeric_datetime_axis = [\\n        totimestamp(a_datetime) for a_datetime in datetime_axis\\n    ]\\n\\n    numeric_datetime_new_axis = [\\n        totimestamp(a_datetime) for a_datetime in datetime_new_axis\\n    ]\\n\\n    return spline_interpolate(\\n        numeric_datetime_axis, y_axis, numeric_datetime_new_axis)': 640,\n",
       " 'def _load_data(filepath):\\n  \"\"\"Loads the images and latent values into Numpy arrays.\"\"\"\\n  with h5py.File(filepath, \"r\") as h5dataset:\\n    image_array = np.array(h5dataset[\"images\"])\\n    # The \\'label\\' data set in the hdf5 file actually contains the float values\\n    # and not the class labels.\\n    values_array = np.array(h5dataset[\"labels\"])\\n  return image_array, values_array': 641,\n",
       " 'def invertDictMapping(d):\\n    \"\"\" Invert mapping of dictionary (i.e. map values to list of keys) \"\"\"\\n    inv_map = {}\\n    for k, v in d.items():\\n        inv_map[v] = inv_map.get(v, [])\\n        inv_map[v].append(k)\\n    return inv_map': 642,\n",
       " 'def chunk_list(l, n):\\n    \"\"\"Return `n` size lists from a given list `l`\"\"\"\\n    return [l[i:i + n] for i in range(0, len(l), n)]': 643,\n",
       " 'def is_valid_ip(ip_address):\\n    \"\"\"\\n    Check Validity of an IP address\\n    \"\"\"\\n    valid = True\\n    try:\\n        socket.inet_aton(ip_address.strip())\\n    except:\\n        valid = False\\n    return valid': 644,\n",
       " 'def main(idle):\\n    \"\"\"Any normal python logic which runs a loop. Can take arguments.\"\"\"\\n    while True:\\n\\n        LOG.debug(\"Sleeping for {0} seconds.\".format(idle))\\n        time.sleep(idle)': 645,\n",
       " 'def unique(_list):\\n    \"\"\"\\n    Makes the list have unique items only and maintains the order\\n\\n    list(set()) won\\'t provide that\\n\\n    :type _list list\\n    :rtype: list\\n    \"\"\"\\n    ret = []\\n\\n    for item in _list:\\n        if item not in ret:\\n            ret.append(item)\\n\\n    return ret': 646,\n",
       " 'def is_a_sequence(var, allow_none=False):\\n    \"\"\" Returns True if var is a list or a tuple (but not a string!)\\n    \"\"\"\\n    return isinstance(var, (list, tuple)) or (var is None and allow_none)': 647,\n",
       " 'def isin(elems, line):\\n    \"\"\"Check if an element from a list is in a string.\\n\\n    :type elems: list\\n    :type line: str\\n\\n    \"\"\"\\n    found = False\\n    for e in elems:\\n        if e in line.lower():\\n            found = True\\n            break\\n    return found': 648,\n",
       " 'def _notnull(expr):\\n    \"\"\"\\n    Return a sequence or scalar according to the input indicating if the values are not null.\\n\\n    :param expr: sequence or scalar\\n    :return: sequence or scalar\\n    \"\"\"\\n\\n    if isinstance(expr, SequenceExpr):\\n        return NotNull(_input=expr, _data_type=types.boolean)\\n    elif isinstance(expr, Scalar):\\n        return NotNull(_input=expr, _value_type=types.boolean)': 649,\n",
       " 'def conv_dict(self):\\n        \"\"\"dictionary of conversion\"\"\"\\n        return dict(integer=self.integer, real=self.real, no_type=self.no_type)': 650,\n",
       " 'def _writable_dir(path):\\n    \"\"\"Whether `path` is a directory, to which the user has write access.\"\"\"\\n    return os.path.isdir(path) and os.access(path, os.W_OK)': 651,\n",
       " 'def make_qs(n, m=None):\\n    \"\"\"Make sympy symbols q0, q1, ...\\n    \\n    Args:\\n        n(int), m(int, optional):\\n            If specified both n and m, returns [qn, q(n+1), ..., qm],\\n            Only n is specified, returns[q0, q1, ..., qn].\\n\\n    Return:\\n        tuple(Symbol): Tuple of sympy symbols.\\n    \"\"\"\\n    try:\\n        import sympy\\n    except ImportError:\\n        raise ImportError(\"This function requires sympy. Please install it.\")\\n    if m is None:\\n        syms = sympy.symbols(\" \".join(f\"q{i}\" for i in range(n)))\\n        if isinstance(syms, tuple):\\n            return syms\\n        else:\\n            return (syms,)\\n    syms = sympy.symbols(\" \".join(f\"q{i}\" for i in range(n, m)))\\n    if isinstance(syms, tuple):\\n        return syms\\n    else:\\n        return (syms,)': 652,\n",
       " 'def isdir(path, **kwargs):\\n    \"\"\"Check if *path* is a directory\"\"\"\\n    import os.path\\n    return os.path.isdir(path, **kwargs)': 653,\n",
       " 'def batch(items, size):\\n    \"\"\"Batches a list into a list of lists, with sub-lists sized by a specified\\n    batch size.\"\"\"\\n    return [items[x:x + size] for x in xrange(0, len(items), size)]': 654,\n",
       " 'def is_float_array(l):\\n    r\"\"\"Checks if l is a numpy array of floats (any dimension\\n\\n    \"\"\"\\n    if isinstance(l, np.ndarray):\\n        if l.dtype.kind == \\'f\\':\\n            return True\\n    return False': 655,\n",
       " 'def myreplace(astr, thefind, thereplace):\\n    \"\"\"in string astr replace all occurences of thefind with thereplace\"\"\"\\n    alist = astr.split(thefind)\\n    new_s = alist.split(thereplace)\\n    return new_s': 656,\n",
       " 'def is_iter_non_string(obj):\\n    \"\"\"test if object is a list or tuple\"\"\"\\n    if isinstance(obj, list) or isinstance(obj, tuple):\\n        return True\\n    return False': 657,\n",
       " 'def round_to_x_digits(number, digits):\\n    \"\"\"\\n    Returns \\'number\\' rounded to \\'digits\\' digits.\\n    \"\"\"\\n    return round(number * math.pow(10, digits)) / math.pow(10, digits)': 658,\n",
       " 'def __next__(self):\\n    \"\"\"Pop the head off the iterator and return it.\"\"\"\\n    res = self._head\\n    self._fill()\\n    if res is None:\\n      raise StopIteration()\\n    return res': 659,\n",
       " 'def as_tuple(self, value):\\n        \"\"\"Utility function which converts lists to tuples.\"\"\"\\n        if isinstance(value, list):\\n            value = tuple(value)\\n        return value': 660,\n",
       " 'def __reversed__(self):\\n        \"\"\"\\n        Return a reversed iterable over the items in the dictionary. Items are\\n        iterated over in their reverse sort order.\\n\\n        Iterating views while adding or deleting entries in the dictionary may\\n        raise a RuntimeError or fail to iterate over all entries.\\n        \"\"\"\\n        _dict = self._dict\\n        return iter((key, _dict[key]) for key in reversed(self._list))': 661,\n",
       " 'def register_modele(self, modele: Modele):\\n        \"\"\" Register a modele onto the lemmatizer\\n\\n        :param modele: Modele to register\\n        \"\"\"\\n        self.lemmatiseur._modeles[modele.gr()] = modele': 662,\n",
       " 'def split_every(n, iterable):\\n    \"\"\"Returns a generator that spits an iteratable into n-sized chunks. The last chunk may have\\n    less than n elements.\\n\\n    See http://stackoverflow.com/a/22919323/503377.\"\"\"\\n    items = iter(iterable)\\n    return itertools.takewhile(bool, (list(itertools.islice(items, n)) for _ in itertools.count()))': 663,\n",
       " 'def flatten(l):\\n    \"\"\"Flatten a nested list.\"\"\"\\n    return sum(map(flatten, l), []) \\\\\\n        if isinstance(l, list) or isinstance(l, tuple) else [l]': 664,\n",
       " 'def directory_files(path):\\n    \"\"\"Yield directory file names.\"\"\"\\n\\n    for entry in os.scandir(path):\\n        if not entry.name.startswith(\\'.\\') and entry.is_file():\\n            yield entry.name': 665,\n",
       " 'def read_array(path, mmap_mode=None):\\n    \"\"\"Read a .npy array.\"\"\"\\n    file_ext = op.splitext(path)[1]\\n    if file_ext == \\'.npy\\':\\n        return np.load(path, mmap_mode=mmap_mode)\\n    raise NotImplementedError(\"The file extension `{}` \".format(file_ext) +\\n                              \"is not currently supported.\")': 666,\n",
       " 'def group_by(iterable, key_func):\\n    \"\"\"Wrap itertools.groupby to make life easier.\"\"\"\\n    groups = (\\n        list(sub) for key, sub in groupby(iterable, key_func)\\n    )\\n    return zip(groups, groups)': 667,\n",
       " 'def get_python():\\n    \"\"\"Determine the path to the virtualenv python\"\"\"\\n    if sys.platform == \\'win32\\':\\n        python = path.join(VE_ROOT, \\'Scripts\\', \\'python.exe\\')\\n    else:\\n        python = path.join(VE_ROOT, \\'bin\\', \\'python\\')\\n    return python': 668,\n",
       " 'def render_template(template_name, **context):\\n    \"\"\"Render a template into a response.\"\"\"\\n    tmpl = jinja_env.get_template(template_name)\\n    context[\"url_for\"] = url_for\\n    return Response(tmpl.render(context), mimetype=\"text/html\")': 669,\n",
       " 'def selectnone(table, field, complement=False):\\n    \"\"\"Select rows where the given field is `None`.\"\"\"\\n\\n    return select(table, field, lambda v: v is None, complement=complement)': 670,\n",
       " 'def _join(verb):\\n    \"\"\"\\n    Join helper\\n    \"\"\"\\n    data = pd.merge(verb.x, verb.y, **verb.kwargs)\\n\\n    # Preserve x groups\\n    if isinstance(verb.x, GroupedDataFrame):\\n        data.plydata_groups = list(verb.x.plydata_groups)\\n    return data': 671,\n",
       " 'def stn(s, length, encoding, errors):\\n    \"\"\"Convert a string to a null-terminated bytes object.\\n    \"\"\"\\n    s = s.encode(encoding, errors)\\n    return s[:length] + (length - len(s)) * NUL': 672,\n",
       " 'def join_images(img_files, out_file):\\n    \"\"\"Join the list of images into the out file\"\"\"\\n    images = [PIL.Image.open(f) for f in img_files]\\n    joined = PIL.Image.new(\\n        \\'RGB\\',\\n        (sum(i.size[0] for i in images), max(i.size[1] for i in images))\\n    )\\n    left = 0\\n    for img in images:\\n        joined.paste(im=img, box=(left, 0))\\n        left = left + img.size[0]\\n    joined.save(out_file)': 673,\n",
       " 'def _dict(content):\\n    \"\"\"\\n    Helper funcation that converts text-based get response\\n    to a python dictionary for additional manipulation.\\n    \"\"\"\\n    if _has_pandas:\\n        data = _data_frame(content).to_dict(orient=\\'records\\')\\n    else:\\n        response = loads(content)\\n        key = [x for x in response.keys() if x in c.response_data][0]\\n        data = response[key]\\n    return data': 674,\n",
       " 'def get_join_cols(by_entry):\\n  \"\"\" helper function used for joins\\n  builds left and right join list for join function\\n  \"\"\"\\n  left_cols = []\\n  right_cols = []\\n  for col in by_entry:\\n    if isinstance(col, str):\\n      left_cols.append(col)\\n      right_cols.append(col)\\n    else:\\n      left_cols.append(col[0])\\n      right_cols.append(col[1])\\n  return left_cols, right_cols': 675,\n",
       " 'def IPYTHON_MAIN():\\n    \"\"\"Decide if the Ipython command line is running code.\"\"\"\\n    import pkg_resources\\n\\n    runner_frame = inspect.getouterframes(inspect.currentframe())[-2]\\n    return (\\n        getattr(runner_frame, \"function\", None)\\n        == pkg_resources.load_entry_point(\"ipython\", \"console_scripts\", \"ipython\").__name__\\n    )': 676,\n",
       " 'def flatten_dict_join_keys(dct, join_symbol=\" \"):\\n    \"\"\" Flatten dict with defined key join symbol.\\n\\n    :param dct: dict to flatten\\n    :param join_symbol: default value is \" \"\\n    :return:\\n    \"\"\"\\n    return dict( flatten_dict(dct, join=lambda a,b:a+join_symbol+b) )': 677,\n",
       " 'def hash_iterable(it):\\n\\t\"\"\"Perform a O(1) memory hash of an iterable of arbitrary length.\\n\\n\\thash(tuple(it)) creates a temporary tuple containing all values from it\\n\\twhich could be a problem if it is large.\\n\\n\\tSee discussion at:\\n\\thttps://groups.google.com/forum/#!msg/python-ideas/XcuC01a8SYs/e-doB9TbDwAJ\\n\\t\"\"\"\\n\\thash_value = hash(type(it))\\n\\tfor value in it:\\n\\t\\thash_value = hash((hash_value, value))\\n\\treturn hash_value': 678,\n",
       " 'def _to_diagonally_dominant(mat):\\n    \"\"\"Make matrix unweighted diagonally dominant using the Laplacian.\"\"\"\\n    mat += np.diag(np.sum(mat != 0, axis=1) + 0.01)\\n    return mat': 679,\n",
       " 'def traverse_setter(obj, attribute, value):\\n    \"\"\"\\n    Traverses the object and sets the supplied attribute on the\\n    object. Supports Dimensioned and DimensionedPlot types.\\n    \"\"\"\\n    obj.traverse(lambda x: setattr(x, attribute, value))': 680,\n",
       " 'def read_key(self, key, bucket_name=None):\\n        \"\"\"\\n        Reads a key from S3\\n\\n        :param key: S3 key that will point to the file\\n        :type key: str\\n        :param bucket_name: Name of the bucket in which the file is stored\\n        :type bucket_name: str\\n        \"\"\"\\n\\n        obj = self.get_key(key, bucket_name)\\n        return obj.get()[\\'Body\\'].read().decode(\\'utf-8\\')': 681,\n",
       " 'def dump_json(obj):\\n    \"\"\"Dump Python object as JSON string.\"\"\"\\n    return simplejson.dumps(obj, ignore_nan=True, default=json_util.default)': 682,\n",
       " 'def get_property(self, filename):\\n        \"\"\"Opens the file and reads the value\"\"\"\\n\\n        with open(self.filepath(filename)) as f:\\n            return f.read().strip()': 683,\n",
       " 'def pretty_dict_str(d, indent=2):\\n    \"\"\"shows JSON indented representation of d\"\"\"\\n    b = StringIO()\\n    write_pretty_dict_str(b, d, indent=indent)\\n    return b.getvalue()': 684,\n",
       " 'def help_for_command(command):\\n    \"\"\"Get the help text (signature + docstring) for a command (function).\"\"\"\\n    help_text = pydoc.text.document(command)\\n    # remove backspaces\\n    return re.subn(\\'.\\\\\\\\x08\\', \\'\\', help_text)[0]': 685,\n",
       " 'def save(self, fname):\\n        \"\"\" Saves the dictionary in json format\\n        :param fname: file to save to\\n        \"\"\"\\n        with open(fname, \\'wb\\') as f:\\n            json.dump(self, f)': 686,\n",
       " 'def validate(raw_schema, target=None, **kwargs):\\n    \"\"\"\\n    Given the python representation of a JSONschema as defined in the swagger\\n    spec, validate that the schema complies to spec.  If `target` is provided,\\n    that target will be validated against the provided schema.\\n    \"\"\"\\n    schema = schema_validator(raw_schema, **kwargs)\\n    if target is not None:\\n        validate_object(target, schema=schema, **kwargs)': 687,\n",
       " 'def build_output(self, fout):\\n        \"\"\"Squash self.out into string.\\n\\n        Join every line in self.out with a new line and write the\\n        result to the output file.\\n        \"\"\"\\n        fout.write(\\'\\\\n\\'.join([s for s in self.out]))': 688,\n",
       " 'def json_serial(obj):\\n    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\\n    if isinstance(obj, LegipyModel):\\n        return obj.to_json()\\n    elif isinstance(obj, (datetime.date, datetime.datetime)):\\n        return obj.isoformat()\\n    raise TypeError(\"Type {0} not serializable\".format(repr(type(obj))))': 689,\n",
       " 'def generic_add(a, b):\\n    \"\"\"Simple function to add two numbers\"\"\"\\n    logger.debug(\\'Called generic_add({}, {})\\'.format(a, b))\\n    return a + b': 690,\n",
       " 'def _unjsonify(x, isattributes=False):\\n    \"\"\"Convert JSON string to an ordered defaultdict.\"\"\"\\n    if isattributes:\\n        obj = json.loads(x)\\n        return dict_class(obj)\\n    return json.loads(x)': 691,\n",
       " 'def get_absolute_path(*args):\\n    \"\"\"Transform relative pathnames into absolute pathnames.\"\"\"\\n    directory = os.path.dirname(os.path.abspath(__file__))\\n    return os.path.join(directory, *args)': 692,\n",
       " 'def graphql_queries_to_json(*queries):\\n    \"\"\"\\n    Queries should be a list of GraphQL objects\\n    \"\"\"\\n    rtn = {}\\n    for i, query in enumerate(queries):\\n        rtn[\"q{}\".format(i)] = query.value\\n    return json.dumps(rtn)': 693,\n",
       " 'def synthesize(self, duration):\\n        \"\"\"\\n        Synthesize white noise\\n\\n        Args:\\n            duration (numpy.timedelta64): The duration of the synthesized sound\\n        \"\"\"\\n        sr = self.samplerate.samples_per_second\\n        seconds = duration / Seconds(1)\\n        samples = np.random.uniform(low=-1., high=1., size=int(sr * seconds))\\n        return AudioSamples(samples, self.samplerate)': 694,\n",
       " 'def _clean_dict(target_dict, whitelist=None):\\n    \"\"\" Convenience function that removes a dicts keys that have falsy values\\n    \"\"\"\\n    assert isinstance(target_dict, dict)\\n    return {\\n        ustr(k).strip(): ustr(v).strip()\\n        for k, v in target_dict.items()\\n        if v not in (None, Ellipsis, [], (), \"\")\\n        and (not whitelist or k in whitelist)\\n    }': 695,\n",
       " 'def calculate_embedding(self, batch_image_bytes):\\n    \"\"\"Get the embeddings for a given JPEG image.\\n\\n    Args:\\n      batch_image_bytes: As if returned from [ff.read() for ff in file_list].\\n\\n    Returns:\\n      The Inception embeddings (bottleneck layer output)\\n    \"\"\"\\n    return self.tf_session.run(\\n        self.embedding, feed_dict={self.input_jpeg: batch_image_bytes})': 696,\n",
       " 'def timeout_thread_handler(timeout, stop_event):\\n    \"\"\"A background thread to kill the process if it takes too long.\\n\\n    Args:\\n        timeout (float): The number of seconds to wait before killing\\n            the process.\\n        stop_event (Event): An optional event to cleanly stop the background\\n            thread if required during testing.\\n    \"\"\"\\n\\n    stop_happened = stop_event.wait(timeout)\\n    if stop_happened is False:\\n        print(\"Killing program due to %f second timeout\" % timeout)\\n\\n    os._exit(2)': 697,\n",
       " 'def copy_no_perm(src, dst):\\n    \"\"\"\\n    Copies a file from *src* to *dst* including meta data except for permission bits.\\n    \"\"\"\\n    shutil.copy(src, dst)\\n    perm = os.stat(dst).st_mode\\n    shutil.copystat(src, dst)\\n    os.chmod(dst, perm)': 698,\n",
       " 'def iter_with_last(iterable):\\n    \"\"\"\\n    :return: generator of tuples (isLastFlag, item)\\n    \"\"\"\\n    # Ensure it\\'s an iterator and get the first field\\n    iterable = iter(iterable)\\n    prev = next(iterable)\\n    for item in iterable:\\n        # Lag by one item so I know I\\'m not at the end\\n        yield False, prev\\n        prev = item\\n    # Last item\\n    yield True, prev': 699,\n",
       " 'def store_data(data):\\n    \"\"\"Use this function to store data in a JSON file.\\n\\n    This function is used for loading up a JSON file and appending additional\\n    data to the JSON file.\\n\\n    :param data: the data to add to the JSON file.\\n    :type data: dict\\n    \"\"\"\\n    with open(url_json_path) as json_file:\\n        try:\\n            json_file_data = load(json_file)\\n            json_file_data.update(data)\\n        except (AttributeError, JSONDecodeError):\\n            json_file_data = data\\n    with open(url_json_path, \\'w\\') as json_file:\\n        dump(json_file_data, json_file, indent=4, sort_keys=True)': 700,\n",
       " 'def filename_addstring(filename, text):\\n    \"\"\"\\n    Add `text` to filename, keeping the extension in place\\n    For example when adding a timestamp to the filename\\n    \"\"\"\\n    fn, ext = os.path.splitext(filename)\\n    return fn + text + ext': 701,\n",
       " 'def pop(self):\\n        \"\"\"\\n        return the last stack element and delete it from the list\\n        \"\"\"\\n        if not self.empty():\\n            val = self.stack[-1]\\n            del self.stack[-1]\\n            return val': 702,\n",
       " 'def interpolate_logscale_single(start, end, coefficient):\\n    \"\"\" Cosine interpolation \"\"\"\\n    return np.exp(np.log(start) + (np.log(end) - np.log(start)) * coefficient)': 703,\n",
       " 'def get_last_modified_timestamp(self):\\n        \"\"\"\\n        Looks at the files in a git root directory and grabs the last modified timestamp\\n        \"\"\"\\n        cmd = \"find . -print0 | xargs -0 stat -f \\'%T@ %p\\' | sort -n | tail -1 | cut -f2- -d\\' \\'\"\\n        ps = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\\n        output = ps.communicate()[0]\\n        print output': 704,\n",
       " 'def _stdin_(p):\\n    \"\"\"Takes input from user. Works for Python 2 and 3.\"\"\"\\n    _v = sys.version[0]\\n    return input(p) if _v is \\'3\\' else raw_input(p)': 705,\n",
       " 'def get_list_dimensions(_list):\\n    \"\"\"\\n    Takes a nested list and returns the size of each dimension followed\\n    by the element type in the list\\n    \"\"\"\\n    if isinstance(_list, list) or isinstance(_list, tuple):\\n        return [len(_list)] + get_list_dimensions(_list[0])\\n    return []': 706,\n",
       " 'def sort_filenames(filenames):\\n    \"\"\"\\n    sort a list of files by filename only, ignoring the directory names\\n    \"\"\"\\n    basenames = [os.path.basename(x) for x in filenames]\\n    indexes = [i[0] for i in sorted(enumerate(basenames), key=lambda x:x[1])]\\n    return [filenames[x] for x in indexes]': 707,\n",
       " 'def levenshtein_distance_metric(a, b):\\n    \"\"\" 1 - farthest apart (same number of words, all diff). 0 - same\"\"\"\\n    return (levenshtein_distance(a, b) / (2.0 * max(len(a), len(b), 1)))': 708,\n",
       " 'def wait_until_exit(self):\\n        \"\"\" Wait until thread exit\\n\\n            Used for testing purpose only\\n        \"\"\"\\n\\n        if self._timeout is None:\\n            raise Exception(\"Thread will never exit. Use stop or specify timeout when starting it!\")\\n\\n        self._thread.join()\\n        self.stop()': 709,\n",
       " 'def timed (log=sys.stderr, limit=2.0):\\n    \"\"\"Decorator to run a function with timing info.\"\"\"\\n    return lambda func: timeit(func, log, limit)': 710,\n",
       " 'def dict_jsonp(param):\\n    \"\"\"Convert the parameter into a dictionary before calling jsonp, if it\\'s not already one\"\"\"\\n    if not isinstance(param, dict):\\n        param = dict(param)\\n    return jsonp(param)': 711,\n",
       " 'def txt_line_iterator(path):\\n  \"\"\"Iterate through lines of file.\"\"\"\\n  with tf.gfile.Open(path) as f:\\n    for line in f:\\n      yield line.strip()': 712,\n",
       " 'def get_size(objects):\\n    \"\"\"Compute the total size of all elements in objects.\"\"\"\\n    res = 0\\n    for o in objects:\\n        try:\\n            res += _getsizeof(o)\\n        except AttributeError:\\n            print(\"IGNORING: type=%s; o=%s\" % (str(type(o)), str(o)))\\n    return res': 713,\n",
       " 'def distinct(xs):\\n    \"\"\"Get the list of distinct values with preserving order.\"\"\"\\n    # don\\'t use collections.OrderedDict because we do support Python 2.6\\n    seen = set()\\n    return [x for x in xs if x not in seen and not seen.add(x)]': 714,\n",
       " 'def stderr(a):\\n    \"\"\"\\n    Calculate the standard error of a.\\n    \"\"\"\\n    return np.nanstd(a) / np.sqrt(sum(np.isfinite(a)))': 715,\n",
       " 'def get_table_names(connection):\\n\\t\"\"\"\\n\\tReturn a list of the table names in the database.\\n\\t\"\"\"\\n\\tcursor = connection.cursor()\\n\\tcursor.execute(\"SELECT name FROM sqlite_master WHERE type == \\'table\\'\")\\n\\treturn [name for (name,) in cursor]': 716,\n",
       " 'def time(func, *args, **kwargs):\\n    \"\"\"\\n    Call the supplied function with the supplied arguments,\\n    and return the total execution time as a float in seconds.\\n\\n    The precision of the returned value depends on the precision of\\n    `time.time()` on your platform.\\n\\n    Arguments:\\n        func: the function to run.\\n        *args: positional arguments to pass into the function.\\n        **kwargs: keyword arguments to pass into the function.\\n    Returns:\\n        Execution time of the function as a float in seconds.\\n    \"\"\"\\n    start_time = time_module.time()\\n    func(*args, **kwargs)\\n    end_time = time_module.time()\\n    return end_time - start_time': 717,\n",
       " 'def camel_case_from_underscores(string):\\n    \"\"\"generate a CamelCase string from an underscore_string.\"\"\"\\n    components = string.split(\\'_\\')\\n    string = \\'\\'\\n    for component in components:\\n        string += component[0].upper() + component[1:]\\n    return string': 718,\n",
       " 'def list_get(l, idx, default=None):\\n    \"\"\"\\n    Get from a list with an optional default value.\\n    \"\"\"\\n    try:\\n        if l[idx]:\\n            return l[idx]\\n        else:\\n            return default\\n    except IndexError:\\n        return default': 719,\n",
       " 'def classnameify(s):\\n  \"\"\"\\n  Makes a classname\\n  \"\"\"\\n  return \\'\\'.join(w if w in ACRONYMS else w.title() for w in s.split(\\'_\\'))': 720,\n",
       " 'def dedupe_list(l):\\n    \"\"\"Remove duplicates from a list preserving the order.\\n\\n    We might be tempted to use the list(set(l)) idiom, but it doesn\\'t preserve\\n    the order, which hinders testability and does not work for lists with\\n    unhashable elements.\\n    \"\"\"\\n    result = []\\n\\n    for el in l:\\n        if el not in result:\\n            result.append(el)\\n\\n    return result': 721,\n",
       " 'def force_to_string(unknown):\\n    \"\"\"\\n    converts and unknown type to string for display purposes.\\n    \\n    \"\"\"\\n    result = \\'\\'\\n    if type(unknown) is str:\\n        result = unknown\\n    if type(unknown) is int:\\n        result = str(unknown)\\n    if type(unknown) is float:\\n        result = str(unknown)\\n    if type(unknown) is dict:\\n        result = Dict2String(unknown)\\n    if type(unknown) is list:\\n        result = List2String(unknown)\\n    return result': 722,\n",
       " 'def nan_pixels(self):\\n        \"\"\" Return an array of the NaN pixels.\\n\\n        Returns\\n        -------\\n        :obj:`numpy.ndarray`\\n             Nx2 array of the NaN pixels\\n        \"\"\"\\n        nan_px = np.where(np.isnan(np.sum(self.raw_data, axis=2)))\\n        nan_px = np.c_[nan_px[0], nan_px[1]]\\n        return nan_px': 723,\n",
       " 'def clean_error(err):\\n    \"\"\"\\n    Take stderr bytes returned from MicroPython and attempt to create a\\n    non-verbose error message.\\n    \"\"\"\\n    if err:\\n        decoded = err.decode(\\'utf-8\\')\\n        try:\\n            return decoded.split(\\'\\\\r\\\\n\\')[-2]\\n        except Exception:\\n            return decoded\\n    return \\'There was an error.\\'': 724,\n",
       " 'def downcaseTokens(s,l,t):\\n    \"\"\"Helper parse action to convert tokens to lower case.\"\"\"\\n    return [ tt.lower() for tt in map(_ustr,t) ]': 725,\n",
       " 'def arr_to_vector(arr):\\n    \"\"\"Reshape a multidimensional array to a vector.\\n    \"\"\"\\n    dim = array_dim(arr)\\n    tmp_arr = []\\n    for n in range(len(dim) - 1):\\n        for inner in arr:\\n            for i in inner:\\n                tmp_arr.append(i)\\n        arr = tmp_arr\\n        tmp_arr = []\\n    return arr': 726,\n",
       " 'def get_all_attributes(klass_or_instance):\\n    \"\"\"Get all attribute members (attribute, property style method).\\n    \"\"\"\\n    pairs = list()\\n    for attr, value in inspect.getmembers(\\n            klass_or_instance, lambda x: not inspect.isroutine(x)):\\n        if not (attr.startswith(\"__\") or attr.endswith(\"__\")):\\n            pairs.append((attr, value))\\n    return pairs': 727,\n",
       " 'def session_to_epoch(timestamp):\\n    \"\"\" converts Synergy Timestamp for session to UTC zone seconds since epoch \"\"\"\\n    utc_timetuple = datetime.strptime(timestamp, SYNERGY_SESSION_PATTERN).replace(tzinfo=None).utctimetuple()\\n    return calendar.timegm(utc_timetuple)': 728,\n",
       " 'def zero_pixels(self):\\n        \"\"\" Return an array of the zero pixels.\\n\\n        Returns\\n        -------\\n        :obj:`numpy.ndarray`\\n             Nx2 array of the zero pixels\\n        \"\"\"\\n        zero_px = np.where(np.sum(self.raw_data, axis=2) == 0)\\n        zero_px = np.c_[zero_px[0], zero_px[1]]\\n        return zero_px': 729,\n",
       " 'def end_table_header(self):\\n        r\"\"\"End the table header which will appear on every page.\"\"\"\\n\\n        if self.header:\\n            msg = \"Table already has a header\"\\n            raise TableError(msg)\\n\\n        self.header = True\\n\\n        self.append(Command(r\\'endhead\\'))': 730,\n",
       " 'def raise_os_error(_errno, path=None):\\n    \"\"\"\\n    Helper for raising the correct exception under Python 3 while still\\n    being able to raise the same common exception class in Python 2.7.\\n    \"\"\"\\n\\n    msg = \"%s: \\'%s\\'\" % (strerror(_errno), path) if path else strerror(_errno)\\n    raise OSError(_errno, msg)': 731,\n",
       " 'def get_mnist(data_type=\"train\", location=\"/tmp/mnist\"):\\n    \"\"\"\\n    Get mnist dataset with features and label as ndarray.\\n    Data would be downloaded automatically if it doesn\\'t present at the specific location.\\n\\n    :param data_type: \"train\" for training data and \"test\" for testing data.\\n    :param location: Location to store mnist dataset.\\n    :return: (features: ndarray, label: ndarray)\\n    \"\"\"\\n    X, Y = mnist.read_data_sets(location, data_type)\\n    return X, Y + 1': 732,\n",
       " 'def _multiline_width(multiline_s, line_width_fn=len):\\n    \"\"\"Visible width of a potentially multiline content.\"\"\"\\n    return max(map(line_width_fn, re.split(\"[\\\\r\\\\n]\", multiline_s)))': 733,\n",
       " 'def col_rename(df,col_name,new_col_name):\\n    \"\"\" Changes a column name in a DataFrame\\n    Parameters:\\n    df - DataFrame\\n        DataFrame to operate on\\n    col_name - string\\n        Name of column to change\\n    new_col_name - string\\n        New name of column\\n    \"\"\"\\n    col_list = list(df.columns)\\n    for index,value in enumerate(col_list):\\n        if value == col_name:\\n            col_list[index] = new_col_name\\n            break\\n    df.columns = col_list': 734,\n",
       " 'def _include_yaml(loader, node):\\n    \"\"\"Load another YAML file and embeds it using the !include tag.\\n\\n    Example:\\n        device_tracker: !include device_tracker.yaml\\n    \"\"\"\\n    return load_yaml(os.path.join(os.path.dirname(loader.name), node.value))': 735,\n",
       " 'def comma_converter(float_string):\\n    \"\"\"Convert numbers to floats whether the decimal point is \\'.\\' or \\',\\'\"\"\"\\n    trans_table = maketrans(b\\',\\', b\\'.\\')\\n    return float(float_string.translate(trans_table))': 736,\n",
       " 'def datetime_local_to_utc(local):\\n    \"\"\"\\n    Simple function to convert naive :std:`datetime.datetime` object containing\\n    local time to a naive :std:`datetime.datetime` object with UTC time.\\n    \"\"\"\\n    timestamp = time.mktime(local.timetuple())\\n    return datetime.datetime.utcfromtimestamp(timestamp)': 737,\n",
       " 'def to_identifier(s):\\n  \"\"\"\\n  Convert snake_case to camel_case.\\n  \"\"\"\\n  if s.startswith(\\'GPS\\'):\\n      s = \\'Gps\\' + s[3:]\\n  return \\'\\'.join([i.capitalize() for i in s.split(\\'_\\')]) if \\'_\\' in s else s': 738,\n",
       " 'def lock(self, block=True):\\n\\t\\t\"\"\"\\n\\t\\tLock connection from being used else where\\n\\t\\t\"\"\"\\n\\t\\tself._locked = True\\n\\t\\treturn self._lock.acquire(block)': 739,\n",
       " 'def _validate_pos(df):\\n    \"\"\"Validates the returned positional object\\n    \"\"\"\\n    assert isinstance(df, pd.DataFrame)\\n    assert [\"seqname\", \"position\", \"strand\"] == df.columns.tolist()\\n    assert df.position.dtype == np.dtype(\"int64\")\\n    assert df.strand.dtype == np.dtype(\"O\")\\n    assert df.seqname.dtype == np.dtype(\"O\")\\n    return df': 740,\n",
       " 'def lognorm(x, mu, sigma=1.0):\\n    \"\"\" Log-normal function from scipy \"\"\"\\n    return stats.lognorm(sigma, scale=mu).pdf(x)': 741,\n",
       " 'def autoconvert(string):\\n    \"\"\"Try to convert variables into datatypes.\"\"\"\\n    for fn in (boolify, int, float):\\n        try:\\n            return fn(string)\\n        except ValueError:\\n            pass\\n    return string': 742,\n",
       " 'def to_distribution_values(self, values):\\n        \"\"\"\\n        Returns numpy array of natural logarithms of ``values``.\\n        \"\"\"\\n        with warnings.catch_warnings():\\n            warnings.simplefilter(\"ignore\")\\n            # avoid RuntimeWarning: divide by zero encountered in log\\n            return numpy.log(values)': 743,\n",
       " 'def find_console_handler(logger):\\n    \"\"\"Return a stream handler, if it exists.\"\"\"\\n    for handler in logger.handlers:\\n        if (isinstance(handler, logging.StreamHandler) and\\n                handler.stream == sys.stderr):\\n            return handler': 744,\n",
       " 'def unicode_is_ascii(u_string):\\n    \"\"\"Determine if unicode string only contains ASCII characters.\\n\\n    :param str u_string: unicode string to check. Must be unicode\\n        and not Python 2 `str`.\\n    :rtype: bool\\n    \"\"\"\\n    assert isinstance(u_string, str)\\n    try:\\n        u_string.encode(\\'ascii\\')\\n        return True\\n    except UnicodeEncodeError:\\n        return False': 745,\n",
       " 'def clog(color):\\n    \"\"\"Same to ``log``, but this one centralizes the message first.\"\"\"\\n    logger = log(color)\\n    return lambda msg: logger(centralize(msg).rstrip())': 746,\n",
       " 'def is_defined(self, obj, force_import=False):\\n        \"\"\"Return True if object is defined in current namespace\"\"\"\\n        from spyder_kernels.utils.dochelpers import isdefined\\n\\n        ns = self._get_current_namespace(with_magics=True)\\n        return isdefined(obj, force_import=force_import, namespace=ns)': 747,\n",
       " 'def format(self, record, *args, **kwargs):\\n        \"\"\"\\n        Format a message in the log\\n\\n        Act like the normal format, but indent anything that is a\\n        newline within the message.\\n\\n        \"\"\"\\n        return logging.Formatter.format(\\n            self, record, *args, **kwargs).replace(\\'\\\\n\\', \\'\\\\n\\' + \\' \\' * 8)': 748,\n",
       " 'def is_delimiter(line):\\n    \"\"\" True if a line consists only of a single punctuation character.\"\"\"\\n    return bool(line) and line[0] in punctuation and line[0]*len(line) == line': 749,\n",
       " 'def load_config(filename=\"logging.ini\", *args, **kwargs):\\n    \"\"\"\\n    Load logger config from file\\n    \\n    Keyword arguments:\\n    filename -- configuration filename (Default: \"logging.ini\")\\n    *args -- options passed to fileConfig\\n    **kwargs -- options passed to fileConfigg\\n    \\n    \"\"\"\\n    logging.config.fileConfig(filename, *args, **kwargs)': 750,\n",
       " 'def is_parameter(self):\\n        \"\"\"Whether this is a function parameter.\"\"\"\\n        return (isinstance(self.scope, CodeFunction)\\n                and self in self.scope.parameters)': 751,\n",
       " 'def print_log(value_color=\"\", value_noncolor=\"\"):\\n    \"\"\"set the colors for text.\"\"\"\\n    HEADER = \\'\\\\033[92m\\'\\n    ENDC = \\'\\\\033[0m\\'\\n    print(HEADER + value_color + ENDC + str(value_noncolor))': 752,\n",
       " 'def is_seq(obj):\\n    \"\"\" Returns True if object is not a string but is iterable \"\"\"\\n    if not hasattr(obj, \\'__iter__\\'):\\n        return False\\n    if isinstance(obj, basestring):\\n        return False\\n    return True': 753,\n",
       " 'def logger(message, level=10):\\n    \"\"\"Handle logging.\"\"\"\\n    logging.getLogger(__name__).log(level, str(message))': 754,\n",
       " 'def is_listish(obj):\\n    \"\"\"Check if something quacks like a list.\"\"\"\\n    if isinstance(obj, (list, tuple, set)):\\n        return True\\n    return is_sequence(obj)': 755,\n",
       " 'def isin(value, values):\\n    \"\"\" Check that value is in values \"\"\"\\n    for i, v in enumerate(value):\\n        if v not in np.array(values)[:, i]:\\n            return False\\n    return True': 756,\n",
       " 'def is_non_empty_string(input_string):\\n    \"\"\"\\n    Validate if non empty string\\n\\n    :param input_string: Input is a *str*.\\n    :return: True if input is string and non empty.\\n       Raise :exc:`Exception` otherwise.\\n    \"\"\"\\n    try:\\n        if not input_string.strip():\\n            raise ValueError()\\n    except AttributeError as error:\\n        raise TypeError(error)\\n\\n    return True': 757,\n",
       " 'def get_naive(dt):\\n  \"\"\"Gets a naive datetime from a datetime.\\n\\n  datetime_tz objects can\\'t just have tzinfo replaced with None, you need to\\n  call asdatetime.\\n\\n  Args:\\n    dt: datetime object.\\n\\n  Returns:\\n    datetime object without any timezone information.\\n  \"\"\"\\n  if not dt.tzinfo:\\n    return dt\\n  if hasattr(dt, \"asdatetime\"):\\n    return dt.asdatetime()\\n  return dt.replace(tzinfo=None)': 758,\n",
       " 'def _match_literal(self, a, b=None):\\n        \"\"\"Match two names.\"\"\"\\n\\n        return a.lower() == b if not self.case_sensitive else a == b': 759,\n",
       " 'def make_symmetric(dict):\\n    \"\"\"Makes the given dictionary symmetric. Values are assumed to be unique.\"\"\"\\n    for key, value in list(dict.items()):\\n        dict[value] = key\\n    return dict': 760,\n",
       " 'def isnumber(*args):\\n    \"\"\"Checks if value is an integer, long integer or float.\\n\\n    NOTE: Treats booleans as numbers, where True=1 and False=0.\\n    \"\"\"\\n    return all(map(lambda c: isinstance(c, int) or isinstance(c, float), args))': 761,\n",
       " 'def relpath(path):\\n    \"\"\"Path helper, gives you a path relative to this file\"\"\"\\n    return os.path.normpath(\\n        os.path.join(os.path.abspath(os.path.dirname(__file__)), path)\\n    )': 762,\n",
       " 'def cudaDriverGetVersion():\\n    \"\"\"\\n    Get installed CUDA driver version.\\n\\n    Return the version of the installed CUDA driver as an integer. If\\n    no driver is detected, 0 is returned.\\n\\n    Returns\\n    -------\\n    version : int\\n        Driver version.\\n\\n    \"\"\"\\n\\n    version = ctypes.c_int()\\n    status = _libcudart.cudaDriverGetVersion(ctypes.byref(version))\\n    cudaCheckStatus(status)\\n    return version.value': 763,\n",
       " 'def israw(self, **kwargs):\\n        \"\"\"\\n        Returns True if the PTY should operate in raw mode.\\n\\n        If the container was not started with tty=True, this will return False.\\n        \"\"\"\\n\\n        if self.raw is None:\\n            info = self._container_info()\\n            self.raw = self.stdout.isatty() and info[\\'Config\\'][\\'Tty\\']\\n\\n        return self.raw': 764,\n",
       " 'def html(header_rows):\\n    \"\"\"\\n    Convert a list of tuples describing a table into a HTML string\\n    \"\"\"\\n    name = \\'table%d\\' % next(tablecounter)\\n    return HtmlTable([map(str, row) for row in header_rows], name).render()': 765,\n",
       " 'def isSquare(matrix):\\n    \"\"\"Check that ``matrix`` is square.\\n\\n    Returns\\n    =======\\n    is_square : bool\\n        ``True`` if ``matrix`` is square, ``False`` otherwise.\\n\\n    \"\"\"\\n    try:\\n        try:\\n            dim1, dim2 = matrix.shape\\n        except AttributeError:\\n            dim1, dim2 = _np.array(matrix).shape\\n    except ValueError:\\n        return False\\n    if dim1 == dim2:\\n        return True\\n    return False': 766,\n",
       " 'def ver_to_tuple(value):\\n    \"\"\"\\n    Convert version like string to a tuple of integers.\\n    \"\"\"\\n    return tuple(int(_f) for _f in re.split(r\\'\\\\D+\\', value) if _f)': 767,\n",
       " 'def is_type(value):\\n        \"\"\"Determine if value is an instance or subclass of the class Type.\"\"\"\\n        if isinstance(value, type):\\n            return issubclass(value, Type)\\n        return isinstance(value, Type)': 768,\n",
       " 'def _strvar(a, prec=\\'{:G}\\'):\\n    r\"\"\"Return variable as a string to print, with given precision.\"\"\"\\n    return \\' \\'.join([prec.format(i) for i in np.atleast_1d(a)])': 769,\n",
       " 'def check_filename(filename):\\n    \"\"\"\\n    Returns a boolean stating if the filename is safe to use or not. Note that\\n    this does not test for \"legal\" names accepted, but a more restricted set of:\\n    Letters, numbers, spaces, hyphens, underscores and periods.\\n\\n    :param filename: name of a file as a string\\n    :return: boolean if it is a safe file name\\n    \"\"\"\\n    if not isinstance(filename, str):\\n        raise TypeError(\"filename must be a string\")\\n    if regex.path.linux.filename.search(filename):\\n        return True\\n    return False': 770,\n",
       " 'def GeneratePassphrase(length=20):\\n  \"\"\"Create a 20 char passphrase with easily typeable chars.\"\"\"\\n  valid_chars = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\\n  valid_chars += \"0123456789 ,-_&$#\"\\n  return \"\".join(random.choice(valid_chars) for i in range(length))': 771,\n",
       " 'def is_float(value):\\n    \"\"\"must be a float\"\"\"\\n    return isinstance(value, float) or isinstance(value, int) or isinstance(value, np.float64), float(value)': 772,\n",
       " 'def _sub_patterns(patterns, text):\\n    \"\"\"\\n    Apply re.sub to bunch of (pattern, repl)\\n    \"\"\"\\n    for pattern, repl in patterns:\\n        text = re.sub(pattern, repl, text)\\n    return text': 773,\n",
       " 'def on_source_directory_chooser_clicked(self):\\n        \"\"\"Autoconnect slot activated when tbSourceDir is clicked.\"\"\"\\n\\n        title = self.tr(\\'Set the source directory for script and scenario\\')\\n        self.choose_directory(self.source_directory, title)': 774,\n",
       " 'def from_json_list(cls, api_client, data):\\n        \"\"\"Convert a list of JSON values to a list of models\\n        \"\"\"\\n        return [cls.from_json(api_client, item) for item in data]': 775,\n",
       " 'def clean_all(self, args):\\n        \"\"\"Delete all build components; the package cache, package builds,\\n        bootstrap builds and distributions.\"\"\"\\n        self.clean_dists(args)\\n        self.clean_builds(args)\\n        self.clean_download_cache(args)': 776,\n",
       " 'def _merge_maps(m1, m2):\\n    \"\"\"merge two Mapping objects, keeping the type of the first mapping\"\"\"\\n    return type(m1)(chain(m1.items(), m2.items()))': 777,\n",
       " 'def strip(notebook):\\n    \"\"\"Remove outputs from a notebook.\"\"\"\\n    for cell in notebook.cells:\\n        if cell.cell_type == \\'code\\':\\n            cell.outputs = []\\n            cell.execution_count = None': 778,\n",
       " 'def find_whole_word(w):\\n    \"\"\"\\n    Scan through string looking for a location where this word produces a match,\\n    and return a corresponding MatchObject instance.\\n    Return None if no position in the string matches the pattern;\\n    note that this is different from finding a zero-length match at some point in the string.\\n    \"\"\"\\n    return re.compile(r\\'\\\\b({0})\\\\b\\'.format(w), flags=re.IGNORECASE).search': 779,\n",
       " 'def __delitem__(self, resource):\\n        \"\"\"Remove resource instance from internal cache\"\"\"\\n        self.__caches[type(resource)].pop(resource.get_cache_internal_key(), None)': 780,\n",
       " 'def autozoom(self, n=None):\\n        \"\"\"\\n        Auto-scales the axes to fit all the data in plot index n. If n == None,\\n        auto-scale everyone.\\n        \"\"\"\\n        if n==None:\\n            for p in self.plot_widgets: p.autoRange()\\n        else:        self.plot_widgets[n].autoRange()\\n\\n        return self': 781,\n",
       " 'def color_to_hex(color):\\n    \"\"\"Convert matplotlib color code to hex color code\"\"\"\\n    if color is None or colorConverter.to_rgba(color)[3] == 0:\\n        return \\'none\\'\\n    else:\\n        rgb = colorConverter.to_rgb(color)\\n        return \\'#{0:02X}{1:02X}{2:02X}\\'.format(*(int(255 * c) for c in rgb))': 782,\n",
       " 'def erase_lines(n=1):\\n    \"\"\" Erases n lines from the screen and moves the cursor up to follow\\n    \"\"\"\\n    for _ in range(n):\\n        print(codes.cursor[\"up\"], end=\"\")\\n        print(codes.cursor[\"eol\"], end=\"\")': 783,\n",
       " 'def horizontal_line(ax, scale, i, **kwargs):\\n    \"\"\"\\n    Draws the i-th horizontal line parallel to the lower axis.\\n\\n    Parameters\\n    ----------\\n    ax: Matplotlib AxesSubplot\\n        The subplot to draw on.\\n    scale: float, 1.0\\n        Simplex scale size.\\n    i: float\\n        The index of the line to draw\\n    kwargs: Dictionary\\n        Any kwargs to pass through to Matplotlib.\\n    \"\"\"\\n\\n    p1 = (0, i, scale - i)\\n    p2 = (scale - i, i, 0)\\n    line(ax, p1, p2, **kwargs)': 784,\n",
       " 'def terminate(self):\\n        \"\"\"Terminate all workers and threads.\"\"\"\\n        for t in self._threads:\\n            t.quit()\\n        self._thread = []\\n        self._workers = []': 785,\n",
       " 'def raise_figure_window(f=0):\\n    \"\"\"\\n    Raises the supplied figure number or figure window.\\n    \"\"\"\\n    if _fun.is_a_number(f): f = _pylab.figure(f)\\n    f.canvas.manager.window.raise_()': 786,\n",
       " 'def linregress(x, y, return_stats=False):\\n    \"\"\"linear regression calculation\\n\\n    Parameters\\n    ----\\n    x :         independent variable (series)\\n    y :         dependent variable (series)\\n    return_stats : returns statistical values as well if required (bool)\\n    \\n\\n    Returns\\n    ----\\n    list of parameters (and statistics)\\n    \"\"\"\\n    a1, a0, r_value, p_value, stderr = scipy.stats.linregress(x, y)\\n\\n    retval = a1, a0\\n    if return_stats:\\n        retval += r_value, p_value, stderr\\n\\n    return retval': 787,\n",
       " 'def clear_matplotlib_ticks(self, axis=\"both\"):\\n        \"\"\"Clears the default matplotlib ticks.\"\"\"\\n        ax = self.get_axes()\\n        plotting.clear_matplotlib_ticks(ax=ax, axis=axis)': 788,\n",
       " 'def get_latex_table(self, parameters=None, transpose=False, caption=None,\\n                        label=\"tab:model_params\", hlines=True, blank_fill=\"--\"):  # pragma: no cover\\n        \"\"\" Generates a LaTeX table from parameter summaries.\\n\\n        Parameters\\n        ----------\\n        parameters : list[str], optional\\n            A list of what parameters to include in the table. By default, includes all parameters\\n        transpose : bool, optional\\n            Defaults to False, which gives each column as a parameter, each chain (framework)\\n            as a row. You can swap it so that you have a parameter each row and a framework\\n            each column by setting this to True\\n        caption : str, optional\\n            If you want to generate a caption for the table through Python, use this.\\n            Defaults to an empty string\\n        label : str, optional\\n            If you want to generate a label for the table through Python, use this.\\n            Defaults to an empty string\\n        hlines : bool, optional\\n            Inserts ``\\\\\\\\hline`` before and after the header, and at the end of table.\\n        blank_fill : str, optional\\n            If a framework does not have a particular parameter, will fill that cell of\\n            the table with this string.\\n\\n        Returns\\n        -------\\n        str\\n            the LaTeX table.\\n        \"\"\"\\n        if parameters is None:\\n            parameters = self.parent._all_parameters\\n        for p in parameters:\\n            assert isinstance(p, str), \\\\\\n                \"Generating a LaTeX table requires all parameters have labels\"\\n        num_parameters = len(parameters)\\n        num_chains = len(self.parent.chains)\\n        fit_values = self.get_summary(squeeze=False)\\n        if label is None:\\n            label = \"\"\\n        if caption is None:\\n            caption = \"\"\\n\\n        end_text = \" \\\\\\\\\\\\\\\\ \\\\n\"\\n        if transpose:\\n            column_text = \"c\" * (num_chains + 1)\\n        else:\\n            column_text = \"c\" * (num_parameters + 1)\\n\\n        center_text = \"\"\\n        hline_text = \"\\\\\\\\hline\\\\n\"\\n        if hlines:\\n            center_text += hline_text + \"\\\\t\\\\t\"\\n        if transpose:\\n            center_text += \" & \".join([\"Parameter\"] + [c.name for c in self.parent.chains]) + end_text\\n            if hlines:\\n                center_text += \"\\\\t\\\\t\" + hline_text\\n            for p in parameters:\\n                arr = [\"\\\\t\\\\t\" + p]\\n                for chain_res in fit_values:\\n                    if p in chain_res:\\n                        arr.append(self.get_parameter_text(*chain_res[p], wrap=True))\\n                    else:\\n                        arr.append(blank_fill)\\n                center_text += \" & \".join(arr) + end_text\\n        else:\\n            center_text += \" & \".join([\"Model\"] + parameters) + end_text\\n            if hlines:\\n                center_text += \"\\\\t\\\\t\" + hline_text\\n            for name, chain_res in zip([c.name for c in self.parent.chains], fit_values):\\n                arr = [\"\\\\t\\\\t\" + name]\\n                for p in parameters:\\n                    if p in chain_res:\\n                        arr.append(self.get_parameter_text(*chain_res[p], wrap=True))\\n                    else:\\n                        arr.append(blank_fill)\\n                center_text += \" & \".join(arr) + end_text\\n        if hlines:\\n            center_text += \"\\\\t\\\\t\" + hline_text\\n        final_text = get_latex_table_frame(caption, label) % (column_text, center_text)\\n\\n        return final_text': 789,\n",
       " 'def set_ylimits(self, row, column, min=None, max=None):\\n        \"\"\"Set y-axis limits of a subplot.\\n\\n        :param row,column: specify the subplot.\\n        :param min: minimal axis value\\n        :param max: maximum axis value\\n\\n        \"\"\"\\n        subplot = self.get_subplot_at(row, column)\\n        subplot.set_ylimits(min, max)': 790,\n",
       " 'def _norm(self, x):\\n    \"\"\"Compute the safe norm.\"\"\"\\n    return tf.sqrt(tf.reduce_sum(tf.square(x), keepdims=True, axis=-1) + 1e-7)': 791,\n",
       " 'def show(self, imgs, ax=None):\\n        \"\"\" Visualize the persistence image\\n\\n        \"\"\"\\n\\n        ax = ax or plt.gca()\\n\\n        if type(imgs) is not list:\\n            imgs = [imgs]\\n\\n        for i, img in enumerate(imgs):\\n            ax.imshow(img, cmap=plt.get_cmap(\"plasma\"))\\n            ax.axis(\"off\")': 792,\n",
       " 'def cross_join(df1, df2):\\n    \"\"\"\\n    Return a dataframe that is a cross between dataframes\\n    df1 and df2\\n\\n    ref: https://github.com/pydata/pandas/issues/5401\\n    \"\"\"\\n    if len(df1) == 0:\\n        return df2\\n\\n    if len(df2) == 0:\\n        return df1\\n\\n    # Add as lists so that the new index keeps the items in\\n    # the order that they are added together\\n    all_columns = pd.Index(list(df1.columns) + list(df2.columns))\\n    df1[\\'key\\'] = 1\\n    df2[\\'key\\'] = 1\\n    return pd.merge(df1, df2, on=\\'key\\').loc[:, all_columns]': 793,\n",
       " 'def downsample(array, k):\\n    \"\"\"Choose k random elements of array.\"\"\"\\n    length = array.shape[0]\\n    indices = random.sample(xrange(length), k)\\n    return array[indices]': 794,\n",
       " 'def cmp_contents(filename1, filename2):\\n    \"\"\" Returns True if contents of the files are the same\\n\\n    Parameters\\n    ----------\\n    filename1 : str\\n        filename of first file to compare\\n    filename2 : str\\n        filename of second file to compare\\n\\n    Returns\\n    -------\\n    tf : bool\\n        True if binary contents of `filename1` is same as binary contents of\\n        `filename2`, False otherwise.\\n    \"\"\"\\n    with open_readable(filename1, \\'rb\\') as fobj:\\n        contents1 = fobj.read()\\n    with open_readable(filename2, \\'rb\\') as fobj:\\n        contents2 = fobj.read()\\n    return contents1 == contents2': 795,\n",
       " 'def _digits(minval, maxval):\\n    \"\"\"Digits needed to comforatbly display values in [minval, maxval]\"\"\"\\n    if minval == maxval:\\n        return 3\\n    else:\\n        return min(10, max(2, int(1 + abs(np.log10(maxval - minval)))))': 796,\n",
       " 'def compare(a, b):\\n    \"\"\"\\n     Compare items in 2 arrays. Returns sum(abs(a(i)-b(i)))\\n    \"\"\"\\n    s=0\\n    for i in range(len(a)):\\n        s=s+abs(a[i]-b[i])\\n    return s': 797,\n",
       " 'def compare(left, right):\\n    \"\"\"\\n    yields EVENT,ENTRY pairs describing the differences between left\\n    and right, which are filenames for a pair of zip files\\n    \"\"\"\\n\\n    with open_zip(left) as l:\\n        with open_zip(right) as r:\\n            return compare_zips(l, r)': 798,\n",
       " 'def coverage():\\n    \"\"\"Run coverage tests.\"\"\"\\n    # Note: coverage options are controlled by .coveragerc file\\n    install()\\n    test_setup()\\n    sh(\"%s -m coverage run %s\" % (PYTHON, TEST_SCRIPT))\\n    sh(\"%s -m coverage report\" % PYTHON)\\n    sh(\"%s -m coverage html\" % PYTHON)\\n    sh(\"%s -m webbrowser -t htmlcov/index.html\" % PYTHON)': 799,\n",
       " 'def m(name=\\'\\', **kwargs):\\n    \"\"\"\\n    Print out memory usage at this point in time\\n\\n    http://docs.python.org/2/library/resource.html\\n    http://stackoverflow.com/a/15448600/5006\\n    http://stackoverflow.com/questions/110259/which-python-memory-profiler-is-recommended\\n    \"\"\"\\n    with Reflect.context(**kwargs) as r:\\n        kwargs[\"name\"] = name\\n        instance = M_CLASS(r, stream, **kwargs)\\n        instance()': 800,\n",
       " 'def cpp_prog_builder(build_context, target):\\n    \"\"\"Build a C++ binary executable\"\"\"\\n    yprint(build_context.conf, \\'Build CppProg\\', target)\\n    workspace_dir = build_context.get_workspace(\\'CppProg\\', target.name)\\n    build_cpp(build_context, target, target.compiler_config, workspace_dir)': 801,\n",
       " 'def dictmerge(x, y):\\n    \"\"\"\\n    merge two dictionaries\\n    \"\"\"\\n    z = x.copy()\\n    z.update(y)\\n    return z': 802,\n",
       " 'def merge(self, other):\\n        \"\"\" Merge another stats. \"\"\"\\n        Stats.merge(self, other)\\n        self.changes += other.changes': 803,\n",
       " 'def _message_to_string(message, data=None):\\n    \"\"\" Gives a string representation of a PB2 message. \"\"\"\\n    if data is None:\\n        data = _json_from_message(message)\\n\\n    return \"Message {} from {} to {}: {}\".format(\\n        message.namespace, message.source_id, message.destination_id, data)': 804,\n",
       " 'def fn_min(self, a, axis=None):\\n        \"\"\"\\n        Return the minimum of an array, ignoring any NaNs.\\n\\n        :param a: The array.\\n        :return: The minimum value of the array.\\n        \"\"\"\\n\\n        return numpy.nanmin(self._to_ndarray(a), axis=axis)': 805,\n",
       " 'def min_values(args):\\n    \"\"\" Return possible range for min function. \"\"\"\\n    return Interval(min(x.low for x in args), min(x.high for x in args))': 806,\n",
       " 'def makedirs(path, mode=0o777, exist_ok=False):\\n    \"\"\"A wrapper of os.makedirs().\"\"\"\\n    os.makedirs(path, mode, exist_ok)': 807,\n",
       " 'def _from_dict(cls, _dict):\\n        \"\"\"Initialize a ListCollectionsResponse object from a json dictionary.\"\"\"\\n        args = {}\\n        if \\'collections\\' in _dict:\\n            args[\\'collections\\'] = [\\n                Collection._from_dict(x) for x in (_dict.get(\\'collections\\'))\\n            ]\\n        return cls(**args)': 808,\n",
       " 'def most_common(items):\\n    \"\"\"\\n    Wanted functionality from Counters (new in Python 2.7).\\n    \"\"\"\\n    counts = {}\\n    for i in items:\\n        counts.setdefault(i, 0)\\n        counts[i] += 1\\n    return max(six.iteritems(counts), key=operator.itemgetter(1))': 809,\n",
       " 'def find_one(cls, *args, **kwargs):\\n        \"\"\"Run a find_one on this model\\'s collection.  The arguments to\\n        ``Model.find_one`` are the same as to ``pymongo.Collection.find_one``.\"\"\"\\n        database, collection = cls._collection_key.split(\\'.\\')\\n        return current()[database][collection].find_one(*args, **kwargs)': 810,\n",
       " 'def indentsize(line):\\n    \"\"\"Return the indent size, in spaces, at the start of a line of text.\"\"\"\\n    expline = string.expandtabs(line)\\n    return len(expline) - len(string.lstrip(expline))': 811,\n",
       " 'def mostCommonItem(lst):\\n    \"\"\"Choose the most common item from the list, or the first item if all\\n    items are unique.\"\"\"\\n    # This elegant solution from: http://stackoverflow.com/a/1518632/1760218\\n    lst = [l for l in lst if l]\\n    if lst:\\n        return max(set(lst), key=lst.count)\\n    else:\\n        return None': 812,\n",
       " 'def make_env_key(app_name, key):\\n    \"\"\"Creates an environment key-equivalent for the given key\"\"\"\\n    key = key.replace(\\'-\\', \\'_\\').replace(\\' \\', \\'_\\')\\n    return str(\"_\".join((x.upper() for x in (app_name, key))))': 813,\n",
       " 'def _go_to_line(editor, line):\\n    \"\"\"\\n    Move cursor to this line in the current buffer.\\n    \"\"\"\\n    b = editor.application.current_buffer\\n    b.cursor_position = b.document.translate_row_col_to_index(max(0, int(line) - 1), 0)': 814,\n",
       " 'def touch():\\n    \"\"\"Create new bucket.\"\"\"\\n    from .models import Bucket\\n    bucket = Bucket.create()\\n    db.session.commit()\\n    click.secho(str(bucket), fg=\\'green\\')': 815,\n",
       " 'def align_file_position(f, size):\\n    \"\"\" Align the position in the file to the next block of specified size \"\"\"\\n    align = (size - 1) - (f.tell() % size)\\n    f.seek(align, 1)': 816,\n",
       " 'def format_header_cell(val):\\n    \"\"\"\\n    Formats given header column. This involves changing \\'_Px_\\' to \\'(\\', \\'_xP_\\' to \\')\\' and\\n    all other \\'_\\' to spaces.\\n    \"\"\"\\n    return re.sub(\\'_\\', \\' \\', re.sub(r\\'(_Px_)\\', \\'(\\', re.sub(r\\'(_xP_)\\', \\')\\', str(val) )))': 817,\n",
       " 'def go_to_line(self, line):\\n        \"\"\"\\n        Moves the text cursor to given line.\\n\\n        :param line: Line to go to.\\n        :type line: int\\n        :return: Method success.\\n        :rtype: bool\\n        \"\"\"\\n\\n        cursor = self.textCursor()\\n        cursor.setPosition(self.document().findBlockByNumber(line - 1).position())\\n        self.setTextCursor(cursor)\\n        return True': 818,\n",
       " 'def copy(self):\\n        \"\"\"Return a shallow copy of the sorted dictionary.\"\"\"\\n        return self.__class__(self._key, self._load, self._iteritems())': 819,\n",
       " 'def singleton(class_):\\n    \"\"\"Singleton definition.\\n\\n    Method 1 from\\n    https://stackoverflow.com/questions/6760685/creating-a-singleton-in-python\\n    \"\"\"\\n    instances = {}\\n\\n    def get_instance(*args, **kwargs):\\n        if class_ not in instances:\\n            instances[class_] = class_(*args, **kwargs)\\n        return instances[class_]\\n    return get_instance': 820,\n",
       " 'def list_string_to_dict(string):\\n    \"\"\"Inputs ``[\\'a\\', \\'b\\', \\'c\\']``, returns ``{\\'a\\': 0, \\'b\\': 1, \\'c\\': 2}``.\"\"\"\\n    dictionary = {}\\n    for idx, c in enumerate(string):\\n        dictionary.update({c: idx})\\n    return dictionary': 821,\n",
       " 'def _match_space_at_line(line):\\n    \"\"\"Return a re.match object if an empty comment was found on line.\"\"\"\\n    regex = re.compile(r\"^{0}$\".format(_MDL_COMMENT))\\n    return regex.match(line)': 822,\n",
       " 'def _comment(string):\\n    \"\"\"return string as a comment\"\"\"\\n    lines = [line.strip() for line in string.splitlines()]\\n    return \"# \" + (\"%s# \" % linesep).join(lines)': 823,\n",
       " 'def count_generator(generator, memory_efficient=True):\\n    \"\"\"Count number of item in generator.\\n\\n    memory_efficient=True, 3 times slower, but memory_efficient.\\n    memory_efficient=False, faster, but cost more memory.\\n    \"\"\"\\n    if memory_efficient:\\n        counter = 0\\n        for _ in generator:\\n            counter += 1\\n        return counter\\n    else:\\n        return len(list(generator))': 824,\n",
       " 'def export_context(cls, context):\\n\\t\\t\"\"\" Export the specified context to be capable context transferring\\n\\n\\t\\t:param context: context to export\\n\\t\\t:return: tuple\\n\\t\\t\"\"\"\\n\\t\\tif context is None:\\n\\t\\t\\treturn\\n\\t\\tresult = [(x.context_name(), x.context_value()) for x in context]\\n\\t\\tresult.reverse()\\n\\t\\treturn tuple(result)': 825,\n",
       " 'def generate_matrices(dim = 40):\\n  \"\"\"\\n  Generates the matrices that positive and negative samples are multiplied\\n  with.  The matrix for positive samples is randomly drawn from a uniform\\n  distribution, with elements in [-1, 1].  The matrix for negative examples\\n  is the sum of the positive matrix with a matrix drawn from a normal\\n  distribution with mean 0 variance 1.\\n  \"\"\"\\n  positive = numpy.random.uniform(-1, 1, (dim, dim))\\n  negative = positive + numpy.random.normal(0, 1, (dim, dim))\\n  return positive, negative': 826,\n",
       " 'def qr(self,text):\\n        \"\"\" Print QR Code for the provided string \"\"\"\\n        qr_code = qrcode.QRCode(version=4, box_size=4, border=1)\\n        qr_code.add_data(text)\\n        qr_code.make(fit=True)\\n        qr_img = qr_code.make_image()\\n        im = qr_img._img.convert(\"RGB\")\\n        # Convert the RGB image in printable image\\n        self._convert_image(im)': 827,\n",
       " 'def compute(args):\\n    x, y, params = args\\n    \"\"\"Callable function for the multiprocessing pool.\"\"\"\\n    return x, y, mandelbrot(x, y, params)': 828,\n",
       " 'def clear_global(self):\\n        \"\"\"Clear only any cached global data.\\n\\n        \"\"\"\\n        vname = self.varname\\n        logger.debug(f\\'global clearning {vname}\\')\\n        if vname in globals():\\n            logger.debug(\\'removing global instance var: {}\\'.format(vname))\\n            del globals()[vname]': 829,\n",
       " 'def get(self):\\n        \"\"\"retrieve a result from the pool\\n\\n        if nothing is already completed when this method is called, it will\\n        block until something comes back\\n\\n        if the pool\\'s function exited via exception, that will come back as\\n        a result here as well, but will be re-raised in :meth:`get`.\\n\\n        .. note::\\n            if there is nothing in the pool\\'s output queue when this method is\\n            called, it will block until something is ready\\n\\n        :returns:\\n            a return value from one of the function\\'s invocations if it exited\\n            normally\\n\\n        :raises:\\n            :class:`PoolClosed` if the pool was closed before a result could be\\n            produced for thie call\\n\\n        :raises: any exception that was raised inside the worker function\\n        \"\"\"\\n        if self.closed:\\n            raise PoolClosed()\\n\\n        while self._getcount not in self._cache:\\n            counter, result = self.outq.get()\\n            self._cache[counter] = result\\n\\n        result, succeeded = self._cache.pop(self._getcount)\\n        self._getcount += 1\\n\\n        if not succeeded:\\n            klass, exc, tb = result\\n            raise klass, exc, tb\\n        return result': 830,\n",
       " 'def _release(self):\\n        \"\"\"Destroy self since closures cannot be called again.\"\"\"\\n        del self.funcs\\n        del self.variables\\n        del self.variable_values\\n        del self.satisfied': 831,\n",
       " 'def compute_capture(args):\\n    x, y, w, h, params = args\\n    \"\"\"Callable function for the multiprocessing pool.\"\"\"\\n    return x, y, mandelbrot_capture(x, y, w, h, params)': 832,\n",
       " 'def __delitem__(self, key):\\n        \"\"\"Remove a variable from this dataset.\\n        \"\"\"\\n        del self._variables[key]\\n        self._coord_names.discard(key)': 833,\n",
       " 'def remove_columns(self, data, columns):\\n        \"\"\" This method removes columns in data\\n\\n        :param data: original Pandas dataframe\\n        :param columns: list of columns to remove\\n        :type data: pandas.DataFrame\\n        :type columns: list of strings\\n\\n        :returns: Pandas dataframe with removed columns\\n        :rtype: pandas.DataFrame\\n        \"\"\"\\n\\n        for column in columns:\\n            if column in data.columns:\\n                data = data.drop(column, axis=1)\\n\\n        return data': 834,\n",
       " 'def _synced(method, self, args, kwargs):\\n    \"\"\"Underlying synchronized wrapper.\"\"\"\\n    with self._lock:\\n        return method(*args, **kwargs)': 835,\n",
       " 'def _delete_local(self, filename):\\n        \"\"\"Deletes the specified file from the local filesystem.\"\"\"\\n\\n        if os.path.exists(filename):\\n            os.remove(filename)': 836,\n",
       " 'def remove_elements(target, indices):\\n    \"\"\"Remove multiple elements from a list and return result.\\n    This implementation is faster than the alternative below.\\n    Also note the creation of a new list to avoid altering the\\n    original. We don\\'t have any current use for the original\\n    intact list, but may in the future...\"\"\"\\n\\n    copied = list(target)\\n\\n    for index in reversed(indices):\\n        del copied[index]\\n    return copied': 837,\n",
       " 'def get_window(self): \\n        \"\"\"\\n        Returns the object\\'s parent window. Returns None if no window found.\\n        \"\"\"\\n        x = self\\n        while not x._parent == None and \\\\\\n              not isinstance(x._parent, Window): \\n                  x = x._parent\\n        return x._parent': 838,\n",
       " 'def remove_bad(string):\\n    \"\"\"\\n    remove problem characters from string\\n    \"\"\"\\n    remove = [\\':\\', \\',\\', \\'(\\', \\')\\', \\' \\', \\'|\\', \\';\\', \\'\\\\\\'\\']\\n    for c in remove:\\n        string = string.replace(c, \\'_\\')\\n    return string': 839,\n",
       " 'def restore_scrollbar_position(self):\\n        \"\"\"Restoring scrollbar position after main window is visible\"\"\"\\n        scrollbar_pos = self.get_option(\\'scrollbar_position\\', None)\\n        if scrollbar_pos is not None:\\n            self.explorer.treewidget.set_scrollbar_position(scrollbar_pos)': 840,\n",
       " 'def rm_empty_indices(*args):\\n    \"\"\"\\n    Remove unwanted list indices. First argument is the list\\n    of indices to remove. Other elements are the lists\\n    to trim.\\n    \"\"\"\\n    rm_inds = args[0]\\n\\n    if not rm_inds:\\n        return args[1:]\\n\\n    keep_inds = [i for i in range(len(args[1])) if i not in rm_inds]\\n\\n    return [[a[i] for i in keep_inds] for a in args[1:]]': 841,\n",
       " 'def deprecate(func):\\n  \"\"\" A deprecation warning emmiter as a decorator. \"\"\"\\n  @wraps(func)\\n  def wrapper(*args, **kwargs):\\n    warn(\"Deprecated, this will be removed in the future\", DeprecationWarning)\\n    return func(*args, **kwargs)\\n  wrapper.__doc__ = \"Deprecated.\\\\n\" + (wrapper.__doc__ or \"\")\\n  return wrapper': 842,\n",
       " 'def remove_node(self, node):\\n        \"\"\" Remove a node from this network. \"\"\"\\n        if _debug: Network._debug(\"remove_node %r\", node)\\n\\n        self.nodes.remove(node)\\n        node.lan = None': 843,\n",
       " 'def wordify(text):\\n    \"\"\"Generate a list of words given text, removing punctuation.\\n\\n    Parameters\\n    ----------\\n    text : unicode\\n        A piece of english text.\\n\\n    Returns\\n    -------\\n    words : list\\n        List of words.\\n    \"\"\"\\n    stopset = set(nltk.corpus.stopwords.words(\\'english\\'))\\n    tokens = nltk.WordPunctTokenizer().tokenize(text)\\n    return [w for w in tokens if w not in stopset]': 844,\n",
       " 'def is_admin(self):\\n        \"\"\"Is the user a system administrator\"\"\"\\n        return self.role == self.roles.administrator.value and self.state == State.approved': 845,\n",
       " 'def start_connect(self):\\n    \"\"\"Tries to connect to the Heron Server\\n\\n    ``loop()`` method needs to be called after this.\\n    \"\"\"\\n    Log.debug(\"In start_connect() of %s\" % self._get_classname())\\n    # TODO: specify buffer size, exception handling\\n    self.create_socket(socket.AF_INET, socket.SOCK_STREAM)\\n\\n    # when ready, handle_connect is called\\n    self._connecting = True\\n    self.connect(self.endpoint)': 846,\n",
       " 'def contains_empty(features):\\n    \"\"\"Check features data are not empty\\n\\n    :param features: The features data to check.\\n    :type features: list of numpy arrays.\\n\\n    :return: True if one of the array is empty, False else.\\n\\n    \"\"\"\\n    if not features:\\n        return True\\n    for feature in features:\\n        if feature.shape[0] == 0:\\n            return True\\n    return False': 847,\n",
       " 'def _api_type(self, value):\\n        \"\"\"\\n        Returns the API type of the given value based on its python type.\\n\\n        \"\"\"\\n        if isinstance(value, six.string_types):\\n            return \\'string\\'\\n        elif isinstance(value, six.integer_types):\\n            return \\'integer\\'\\n        elif type(value) is datetime.datetime:\\n            return \\'date\\'': 848,\n",
       " 'def denorm(self,arr):\\n        \"\"\"Reverse the normalization done to a batch of images.\\n\\n        Arguments:\\n            arr: of shape/size (N,3,sz,sz)\\n        \"\"\"\\n        if type(arr) is not np.ndarray: arr = to_np(arr)\\n        if len(arr.shape)==3: arr = arr[None]\\n        return self.transform.denorm(np.rollaxis(arr,1,4))': 849,\n",
       " 'def is_seq(obj):\\n    \"\"\"\\n    Check if an object is a sequence.\\n    \"\"\"\\n    return (not is_str(obj) and not is_dict(obj) and\\n            (hasattr(obj, \"__getitem__\") or hasattr(obj, \"__iter__\")))': 850,\n",
       " 'def isTestCaseDisabled(test_case_class, method_name):\\n    \"\"\"\\n    I check to see if a method on a TestCase has been disabled via nose\\'s\\n    convention for disabling a TestCase.  This makes it so that users can\\n    mix nose\\'s parameterized tests with green as a runner.\\n    \"\"\"\\n    test_method = getattr(test_case_class, method_name)\\n    return getattr(test_method, \"__test__\", \\'not nose\\') is False': 851,\n",
       " 'def _histplot_bins(column, bins=100):\\n    \"\"\"Helper to get bins for histplot.\"\"\"\\n    col_min = np.min(column)\\n    col_max = np.max(column)\\n    return range(col_min, col_max + 2, max((col_max - col_min) // bins, 1))': 852,\n",
       " 'def path_for_import(name):\\n    \"\"\"\\n    Returns the directory path for the given package or module.\\n    \"\"\"\\n    return os.path.dirname(os.path.abspath(import_module(name).__file__))': 853,\n",
       " 'def as_float_array(a):\\n    \"\"\"View the quaternion array as an array of floats\\n\\n    This function is fast (of order 1 microsecond) because no data is\\n    copied; the returned quantity is just a \"view\" of the original.\\n\\n    The output view has one more dimension (of size 4) than the input\\n    array, but is otherwise the same shape.\\n\\n    \"\"\"\\n    return np.asarray(a, dtype=np.quaternion).view((np.double, 4))': 854,\n",
       " 'def tokenize(string):\\n    \"\"\"Match and yield all the tokens of the input string.\"\"\"\\n    for match in TOKENS_REGEX.finditer(string):\\n        yield Token(match.lastgroup, match.group().strip(), match.span())': 855,\n",
       " 'def A(*a):\\n    \"\"\"convert iterable object into numpy array\"\"\"\\n    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]': 856,\n",
       " 'def chunked(l, n):\\n    \"\"\"Chunk one big list into few small lists.\"\"\"\\n    return [l[i:i + n] for i in range(0, len(l), n)]': 857,\n",
       " 'def contains_all(self, array):\\n        \"\"\"Test if `array` is an array of real numbers.\"\"\"\\n        dtype = getattr(array, \\'dtype\\', None)\\n        if dtype is None:\\n            dtype = np.result_type(*array)\\n        return is_real_dtype(dtype)': 858,\n",
       " 'def quit(self):\\n        \"\"\" Exit the program due to user\\'s choices.\\n        \"\"\"\\n        self.script.LOG.warn(\"Abort due to user choice!\")\\n        sys.exit(self.QUIT_RC)': 859,\n",
       " 'def print_images(self, *printable_images):\\n        \"\"\"\\n        This method allows printing several images in one shot. This is useful if the client code does not want the\\n        printer to make pause during printing\\n        \"\"\"\\n        printable_image = reduce(lambda x, y: x.append(y), list(printable_images))\\n        self.print_image(printable_image)': 860,\n",
       " 'def ma(self):\\n        \"\"\"Represent data as a masked array.\\n\\n        The array is returned with column-first indexing, i.e. for a data file with\\n        columns X Y1 Y2 Y3 ... the array a will be a[0] = X, a[1] = Y1, ... .\\n\\n        inf and nan are filtered via :func:`numpy.isfinite`.\\n        \"\"\"\\n        a = self.array\\n        return numpy.ma.MaskedArray(a, mask=numpy.logical_not(numpy.isfinite(a)))': 861,\n",
       " 'def _divide(self, x1, x2, out):\\n        \"\"\"Raw pointwise multiplication of two elements.\"\"\"\\n        self.tspace._divide(x1.tensor, x2.tensor, out.tensor)': 862,\n",
       " 'def _to_json(self):\\n        \"\"\" Gets a dict of this object\\'s properties so that it can be used to send a dump to the client \"\"\"\\n        return dict(( (k, v) for k, v in self.__dict__.iteritems() if k != \\'server\\'))': 863,\n",
       " 'def _user_yes_no_query(self, question):\\n        \"\"\" Helper asking if the user want to download the file\\n\\n        Note:\\n            Dowloading huge file can take a while\\n\\n        \"\"\"\\n        sys.stdout.write(\\'%s [y/n]\\\\n\\' % question)\\n        while True:\\n            try:\\n                return strtobool(raw_input().lower())\\n            except ValueError:\\n                sys.stdout.write(\\'Please respond with \\\\\\'y\\\\\\' or \\\\\\'n\\\\\\'.\\\\n\\')': 864,\n",
       " 'def json_datetime_serial(obj):\\n    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\\n    if isinstance(obj, (datetime, date)):\\n        serial = obj.isoformat()\\n        return serial\\n\\n    if ObjectId is not None and isinstance(obj, ObjectId):\\n        # TODO: try to use bson.json_util instead\\n        return str(obj)\\n\\n    raise TypeError(\"Type not serializable\")': 865,\n",
       " 'def to_one_hot(dataY):\\n    \"\"\"Convert the vector of labels dataY into one-hot encoding.\\n\\n    :param dataY: vector of labels\\n    :return: one-hot encoded labels\\n    \"\"\"\\n    nc = 1 + np.max(dataY)\\n    onehot = [np.zeros(nc, dtype=np.int8) for _ in dataY]\\n    for i, j in enumerate(dataY):\\n        onehot[i][j] = 1\\n    return onehot': 866,\n",
       " 'def matrix_at_check(self, original, loc, tokens):\\n        \"\"\"Check for Python 3.5 matrix multiplication.\"\"\"\\n        return self.check_py(\"35\", \"matrix multiplication\", original, loc, tokens)': 867,\n",
       " 'def glob_by_extensions(directory, extensions):\\n    \"\"\" Returns files matched by all extensions in the extensions list \"\"\"\\n    directorycheck(directory)\\n    files = []\\n    xt = files.extend\\n    for ex in extensions:\\n        xt(glob.glob(\\'{0}/*.{1}\\'.format(directory, ex)))\\n    return files': 868,\n",
       " 'def is_equal_strings_ignore_case(first, second):\\n    \"\"\"The function compares strings ignoring case\"\"\"\\n    if first and second:\\n        return first.upper() == second.upper()\\n    else:\\n        return not (first or second)': 869,\n",
       " 'def _fix_up(self, cls, code_name):\\n    \"\"\"Internal helper called to tell the property its name.\\n\\n    This is called by _fix_up_properties() which is called by\\n    MetaModel when finishing the construction of a Model subclass.\\n    The name passed in is the name of the class attribute to which the\\n    Property is assigned (a.k.a. the code name).  Note that this means\\n    that each Property instance must be assigned to (at most) one\\n    class attribute.  E.g. to declare three strings, you must call\\n    StringProperty() three times, you cannot write\\n\\n      foo = bar = baz = StringProperty()\\n    \"\"\"\\n    self._code_name = code_name\\n    if self._name is None:\\n      self._name = code_name': 870,\n",
       " 'def dot_v3(v, w):\\n    \"\"\"Return the dotproduct of two vectors.\"\"\"\\n\\n    return sum([x * y for x, y in zip(v, w)])': 871,\n",
       " 'def read_img(path):\\n    \"\"\" Reads image specified by path into numpy.ndarray\"\"\"\\n    img = cv2.resize(cv2.imread(path, 0), (80, 30)).astype(np.float32) / 255\\n    img = np.expand_dims(img.transpose(1, 0), 0)\\n    return img': 872,\n",
       " 'def file_to_str(fname):\\n    \"\"\"\\n    Read a file into a string\\n    PRE: fname is a small file (to avoid hogging memory and its discontents)\\n    \"\"\"\\n    data = None\\n    # rU = read with Universal line terminator\\n    with open(fname, \\'rU\\') as fd:\\n        data = fd.read()\\n    return data': 873,\n",
       " 'def _download_py3(link, path, __hdr__):\\n    \"\"\"Download a file from a link in Python 3.\"\"\"\\n    try:\\n        req = urllib.request.Request(link, headers=__hdr__)\\n        u = urllib.request.urlopen(req)\\n    except Exception as e:\\n        raise Exception(\\' Download failed with the error:\\\\n{}\\'.format(e))\\n\\n    with open(path, \\'wb\\') as outf:\\n        for l in u:\\n            outf.write(l)\\n    u.close()': 874,\n",
       " 'def to_dotfile(self):\\n        \"\"\" Writes a DOT graphviz file of the domain structure, and returns the filename\"\"\"\\n        domain = self.get_domain()\\n        filename = \"%s.dot\" % (self.__class__.__name__)\\n        nx.write_dot(domain, filename)\\n        return filename': 875,\n",
       " 'def _openpyxl_read_xl(xl_path: str):\\n    \"\"\" Use openpyxl to read an Excel file. \"\"\"\\n    try:\\n        wb = load_workbook(filename=xl_path, read_only=True)\\n    except:\\n        raise\\n    else:\\n        return wb': 876,\n",
       " 'def _drop_str_columns(df):\\n    \"\"\"\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n\\n    Returns\\n    -------\\n\\n    \"\"\"\\n    str_columns = filter(lambda pair: pair[1].char == \\'S\\', df._gather_dtypes().items())\\n    str_column_names = list(map(lambda pair: pair[0], str_columns))\\n\\n    return df.drop(str_column_names)': 877,\n",
       " 'def upcaseTokens(s,l,t):\\n    \"\"\"Helper parse action to convert tokens to upper case.\"\"\"\\n    return [ tt.upper() for tt in map(_ustr,t) ]': 878,\n",
       " 'def C_dict2array(C):\\n    \"\"\"Convert an OrderedDict containing C values to a 1D array.\"\"\"\\n    return np.hstack([np.asarray(C[k]).ravel() for k in C_keys])': 879,\n",
       " 'def normalize_path(path):\\n    \"\"\"\\n    Convert a path to its canonical, case-normalized, absolute version.\\n\\n    \"\"\"\\n    return os.path.normcase(os.path.realpath(os.path.expanduser(path)))': 880,\n",
       " 'def haversine(x):\\n    \"\"\"Return the haversine of an angle\\n\\n    haversine(x) = sin(x/2)**2, where x is an angle in radians\\n    \"\"\"\\n    y = .5*x\\n    y = np.sin(y)\\n    return y*y': 881,\n",
       " 'def __get_float(section, name):\\n    \"\"\"Get the forecasted float from json section.\"\"\"\\n    try:\\n        return float(section[name])\\n    except (ValueError, TypeError, KeyError):\\n        return float(0)': 882,\n",
       " 'def write_color(string, name, style=\\'normal\\', when=\\'auto\\'):\\n    \"\"\" Write the given colored string to standard out. \"\"\"\\n    write(color(string, name, style, when))': 883,\n",
       " 'def close(self):\\n        \"\"\"Close port.\"\"\"\\n        os.close(self.in_d)\\n        os.close(self.out_d)': 884,\n",
       " 'def extract_keywords_from_text(self, text):\\n        \"\"\"Method to extract keywords from the text provided.\\n\\n        :param text: Text to extract keywords from, provided as a string.\\n        \"\"\"\\n        sentences = nltk.tokenize.sent_tokenize(text)\\n        self.extract_keywords_from_sentences(sentences)': 885,\n",
       " 'def deserialize_date(string):\\n    \"\"\"\\n    Deserializes string to date.\\n\\n    :param string: str.\\n    :type string: str\\n    :return: date.\\n    :rtype: date\\n    \"\"\"\\n    try:\\n        from dateutil.parser import parse\\n        return parse(string).date()\\n    except ImportError:\\n        return string': 886,\n",
       " 'def get_soup(page=\\'\\'):\\n    \"\"\"\\n    Returns a bs4 object of the page requested\\n    \"\"\"\\n    content = requests.get(\\'%s/%s\\' % (BASE_URL, page)).text\\n    return BeautifulSoup(content)': 887,\n",
       " 'def parse_date(s):\\n    \"\"\"\\n    Parse a date using dateutil.parser.parse if available,\\n    falling back to datetime.datetime.strptime if not\\n    \"\"\"\\n    if isinstance(s, (datetime.datetime, datetime.date)):\\n        return s\\n    try:\\n        from dateutil.parser import parse\\n    except ImportError:\\n        parse = lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\")\\n    return parse(s)': 888,\n",
       " 'def clean_dataframe(df):\\n    \"\"\"Fill NaNs with the previous value, the next value or if all are NaN then 1.0\"\"\"\\n    df = df.fillna(method=\\'ffill\\')\\n    df = df.fillna(0.0)\\n    return df': 889,\n",
       " 'def fsliceafter(astr, sub):\\n    \"\"\"Return the slice after at sub in string astr\"\"\"\\n    findex = astr.find(sub)\\n    return astr[findex + len(sub):]': 890,\n",
       " 'def map_wrap(f):\\n    \"\"\"Wrap standard function to easily pass into \\'map\\' processing.\\n    \"\"\"\\n    @functools.wraps(f)\\n    def wrapper(*args, **kwargs):\\n        return f(*args, **kwargs)\\n    return wrapper': 891,\n",
       " 'def list_formatter(handler, item, value):\\n    \"\"\"Format list.\"\"\"\\n    return u\\', \\'.join(str(v) for v in value)': 892,\n",
       " 'def debug(self, text):\\n\\t\\t\"\"\" Ajout d\\'un message de log de type DEBUG \"\"\"\\n\\t\\tself.logger.debug(\"{}{}\".format(self.message_prefix, text))': 893,\n",
       " 'def safe_int_conv(number):\\n    \"\"\"Safely convert a single number to integer.\"\"\"\\n    try:\\n        return int(np.array(number).astype(int, casting=\\'safe\\'))\\n    except TypeError:\\n        raise ValueError(\\'cannot safely convert {} to integer\\'.format(number))': 894,\n",
       " 'def quote(self, s):\\n        \"\"\"Return a shell-escaped version of the string s.\"\"\"\\n\\n        if six.PY2:\\n            from pipes import quote\\n        else:\\n            from shlex import quote\\n\\n        return quote(s)': 895,\n",
       " 'def translate_fourier(image, dx):\\n    \"\"\" Translate an image in fourier-space with plane waves \"\"\"\\n    N = image.shape[0]\\n\\n    f = 2*np.pi*np.fft.fftfreq(N)\\n    kx,ky,kz = np.meshgrid(*(f,)*3, indexing=\\'ij\\')\\n    kv = np.array([kx,ky,kz]).T\\n\\n    q = np.fft.fftn(image)*np.exp(-1.j*(kv*dx).sum(axis=-1)).T\\n    return np.real(np.fft.ifftn(q))': 896,\n",
       " 'def perform_pca(A):\\n    \"\"\"\\n    Computes eigenvalues and eigenvectors of covariance matrix of A.\\n    The rows of a correspond to observations, the columns to variables.\\n    \"\"\"\\n    # First subtract the mean\\n    M = (A-numpy.mean(A.T, axis=1)).T\\n    # Get eigenvectors and values of covariance matrix\\n    return numpy.linalg.eig(numpy.cov(M))': 897,\n",
       " 'def main_func(args=None):\\n    \"\"\"Main funcion when executing this module as script\\n\\n    :param args: commandline arguments\\n    :type args: list\\n    :returns: None\\n    :rtype: None\\n    :raises: None\\n    \"\"\"\\n    # we have to initialize a gui even if we dont need one right now.\\n    # as soon as you call maya.standalone.initialize(), a QApplication\\n    # with type Tty is created. This is the type for conosle apps.\\n    # Because i have not found a way to replace that, we just init the gui.\\n    guimain.init_gui()\\n\\n    main.init()\\n    launcher = Launcher()\\n    parsed, unknown = launcher.parse_args(args)\\n    parsed.func(parsed, unknown)': 898,\n",
       " 'def debug_on_error(type, value, tb):\\n    \"\"\"Code due to Thomas Heller - published in Python Cookbook (O\\'Reilley)\"\"\"\\n    traceback.print_exc(type, value, tb)\\n    print()\\n    pdb.pm()': 899,\n",
       " 'def set_trace():\\n    \"\"\"Start a Pdb instance at the calling frame, with stdout routed to sys.__stdout__.\"\"\"\\n    # https://github.com/nose-devs/nose/blob/master/nose/tools/nontrivial.py\\n    pdb.Pdb(stdout=sys.__stdout__).set_trace(sys._getframe().f_back)': 900,\n",
       " 'def _remove_duplicates(objects):\\n    \"\"\"Removes duplicate objects.\\n\\n    http://www.peterbe.com/plog/uniqifiers-benchmark.\\n    \"\"\"\\n    seen, uniq = set(), []\\n    for obj in objects:\\n        obj_id = id(obj)\\n        if obj_id in seen:\\n            continue\\n        seen.add(obj_id)\\n        uniq.append(obj)\\n    return uniq': 901,\n",
       " 'def to_camel_case(snake_case_string):\\n    \"\"\"\\n    Convert a string from snake case to camel case. For example, \"some_var\" would become \"someVar\".\\n\\n    :param snake_case_string: Snake-cased string to convert to camel case.\\n    :returns: Camel-cased version of snake_case_string.\\n    \"\"\"\\n    parts = snake_case_string.lstrip(\\'_\\').split(\\'_\\')\\n    return parts[0] + \\'\\'.join([i.title() for i in parts[1:]])': 902,\n",
       " 'def dimensions(self):\\n        \"\"\"Get width and height of a PDF\"\"\"\\n        size = self.pdf.getPage(0).mediaBox\\n        return {\\'w\\': float(size[2]), \\'h\\': float(size[3])}': 903,\n",
       " 'def do_history(self, line):\\n        \"\"\"history Display a list of commands that have been entered.\"\"\"\\n        self._split_args(line, 0, 0)\\n        for idx, item in enumerate(self._history):\\n            d1_cli.impl.util.print_info(\"{0: 3d} {1}\".format(idx, item))': 904,\n",
       " 'def quote(s, unsafe=\\'/\\'):\\n    \"\"\"Pass in a dictionary that has unsafe characters as the keys, and the percent\\n    encoded value as the value.\"\"\"\\n    res = s.replace(\\'%\\', \\'%25\\')\\n    for c in unsafe:\\n        res = res.replace(c, \\'%\\' + (hex(ord(c)).upper())[2:])\\n    return res': 905,\n",
       " 'def linearRegressionAnalysis(series):\\n    \"\"\"\\n    Returns factor and offset of linear regression function by least\\n    squares method.\\n\\n    \"\"\"\\n    n = safeLen(series)\\n    sumI = sum([i for i, v in enumerate(series) if v is not None])\\n    sumV = sum([v for i, v in enumerate(series) if v is not None])\\n    sumII = sum([i * i for i, v in enumerate(series) if v is not None])\\n    sumIV = sum([i * v for i, v in enumerate(series) if v is not None])\\n    denominator = float(n * sumII - sumI * sumI)\\n    if denominator == 0:\\n        return None\\n    else:\\n        factor = (n * sumIV - sumI * sumV) / denominator / series.step\\n        offset = sumII * sumV - sumIV * sumI\\n        offset = offset / denominator - factor * series.start\\n        return factor, offset': 906,\n",
       " 'def from_bytes(cls, b):\\n\\t\\t\"\"\"Create :class:`PNG` from raw bytes.\\n\\t\\t\\n\\t\\t:arg bytes b: The raw bytes of the PNG file.\\n\\t\\t:rtype: :class:`PNG`\\n\\t\\t\"\"\"\\n\\t\\tim = cls()\\n\\t\\tim.chunks = list(parse_chunks(b))\\n\\t\\tim.init()\\n\\t\\treturn im': 907,\n",
       " 'def less_strict_bool(x):\\n    \"\"\"Idempotent and None-safe version of strict_bool.\"\"\"\\n    if x is None:\\n        return False\\n    elif x is True or x is False:\\n        return x\\n    else:\\n        return strict_bool(x)': 908,\n",
       " 'def _get_token(self, oauth_request, token_type=\\'access\\'):\\n        \"\"\"Try to find the token for the provided request token key.\"\"\"\\n        token_field = oauth_request.get_parameter(\\'oauth_token\\')\\n        token = self.data_store.lookup_token(token_type, token_field)\\n        if not token:\\n            raise OAuthError(\\'Invalid %s token: %s\\' % (token_type, token_field))\\n        return token': 909,\n",
       " 'def pause(self):\\n        \"\"\"Pause the music\"\"\"\\n        mixer.music.pause()\\n        self.pause_time = self.get_time()\\n        self.paused = True': 910,\n",
       " 'def draw_image(self, ax, image):\\n        \"\"\"Process a matplotlib image object and call renderer.draw_image\"\"\"\\n        self.renderer.draw_image(imdata=utils.image_to_base64(image),\\n                                 extent=image.get_extent(),\\n                                 coordinates=\"data\",\\n                                 style={\"alpha\": image.get_alpha(),\\n                                        \"zorder\": image.get_zorder()},\\n                                 mplobj=image)': 911,\n",
       " 'def cart2pol(x, y):\\n    \"\"\"Cartesian to Polar coordinates conversion.\"\"\"\\n    theta = np.arctan2(y, x)\\n    rho = np.hypot(x, y)\\n    return theta, rho': 912,\n",
       " 'def get_column_keys_and_names(table):\\n    \"\"\"\\n    Return a generator of tuples k, c such that k is the name of the python attribute for\\n    the column and c is the name of the column in the sql table.\\n    \"\"\"\\n    ins = inspect(table)\\n    return ((k, c.name) for k, c in ins.mapper.c.items())': 913,\n",
       " 'def asyncStarCmap(asyncCallable, iterable):\\n    \"\"\"itertools.starmap for deferred callables using cooperative multitasking\\n    \"\"\"\\n    results = []\\n    yield coopStar(asyncCallable, results.append, iterable)\\n    returnValue(results)': 914,\n",
       " 'def _psutil_kill_pid(pid):\\n    \"\"\"\\n    http://stackoverflow.com/questions/1230669/subprocess-deleting-child-processes-in-windows\\n    \"\"\"\\n    try:\\n        parent = Process(pid)\\n        for child in parent.children(recursive=True):\\n            child.kill()\\n        parent.kill()\\n    except NoSuchProcess:\\n        return': 915,\n",
       " 'def paint_cube(self, x, y):\\n        \"\"\"\\n        Paints a cube at a certain position a color.\\n\\n        Parameters\\n        ----------\\n        x: int\\n            Horizontal position of the upper left corner of the cube.\\n        y: int\\n            Vertical position of the upper left corner of the cube.\\n\\n        \"\"\"\\n        # get the color\\n        color = self.next_color()\\n        # calculate the position\\n        cube_pos = [x, y, x + self.cube_size, y + self.cube_size]\\n        # draw the cube\\n        draw = ImageDraw.Draw(im=self.image)\\n        draw.rectangle(xy=cube_pos, fill=color)': 916,\n",
       " 'def onchange(self, value):\\n        \"\"\"Called when a new DropDownItem gets selected.\\n        \"\"\"\\n        log.debug(\\'combo box. selected %s\\' % value)\\n        self.select_by_value(value)\\n        return (value, )': 917,\n",
       " 'def p_postfix_expr(self, p):\\n        \"\"\"postfix_expr : left_hand_side_expr\\n                        | left_hand_side_expr PLUSPLUS\\n                        | left_hand_side_expr MINUSMINUS\\n        \"\"\"\\n        if len(p) == 2:\\n            p[0] = p[1]\\n        else:\\n            p[0] = ast.UnaryOp(op=p[2], value=p[1], postfix=True)': 918,\n",
       " 'def phantomjs_retrieve(url, data=None):\\n    \"\"\"Retrieve the given URL using PhantomJS.\\n    PhantomJS will evaluate all scripts and return the HTML after body.onload.\\n    \\n    url  - The page URL to retrieve\\n    data - The form data. TODO: Currently ignored.\\n\\n    Returns a status code (e.g. 200) and the HTML as a unicode string.\\n    \"\"\"\\n    range_limit()\\n    print \"pGET\", url\\n    process = subprocess.Popen([\\'phantomjs\\', PHANTOM_SCRIPT, url], stdout=subprocess.PIPE)\\n    out = process.communicate()\\n    process.wait()\\n    response = out[0].decode(\\'utf-8\\', \\'ignore\\')\\n    status = response[:2]\\n    body = response[3:] # After the \\'ok \\' part.\\n    if status == \\'ok\\':\\n        return 200, body\\n    else:\\n        return 404, body': 919,\n",
       " 'def pprint_for_ordereddict():\\n    \"\"\"\\n    Context manager that causes pprint() to print OrderedDict objects as nicely\\n    as standard Python dictionary objects.\\n    \"\"\"\\n    od_saved = OrderedDict.__repr__\\n    try:\\n        OrderedDict.__repr__ = dict.__repr__\\n        yield\\n    finally:\\n        OrderedDict.__repr__ = od_saved': 920,\n",
       " 'def getTypeStr(_type):\\n  r\"\"\"Gets the string representation of the given type.\\n  \"\"\"\\n  if isinstance(_type, CustomType):\\n    return str(_type)\\n\\n  if hasattr(_type, \\'__name__\\'):\\n    return _type.__name__\\n\\n  return \\'\\'': 921,\n",
       " 'def iget_list_column_slice(list_, start=None, stop=None, stride=None):\\n    \"\"\" iterator version of get_list_column \"\"\"\\n    if isinstance(start, slice):\\n        slice_ = start\\n    else:\\n        slice_ = slice(start, stop, stride)\\n    return (row[slice_] for row in list_)': 922,\n",
       " 'def pformat(o, indent=1, width=80, depth=None):\\n    \"\"\"Format a Python o into a pretty-printed representation.\"\"\"\\n    return PrettyPrinter(indent=indent, width=width, depth=depth).pformat(o)': 923,\n",
       " 'def print_trace(self):\\n        \"\"\"\\n        Prints stack trace for current exceptions chain.\\n        \"\"\"\\n        traceback.print_exc()\\n        for tb in self.tracebacks:\\n            print tb,\\n        print \\'\\'': 924,\n",
       " 'def py(self, output):\\n        \"\"\"Output data as a nicely-formatted python data structure\"\"\"\\n        import pprint\\n        pprint.pprint(output, stream=self.outfile)': 925,\n",
       " 'def pretty(obj, verbose=False, max_width=79, newline=\\'\\\\n\\'):\\n    \"\"\"\\n    Pretty print the object\\'s representation.\\n    \"\"\"\\n    stream = StringIO()\\n    printer = RepresentationPrinter(stream, verbose, max_width, newline)\\n    printer.pretty(obj)\\n    printer.flush()\\n    return stream.getvalue()': 926,\n",
       " 'def file_length(file_obj):\\n    \"\"\"\\n    Returns the length in bytes of a given file object.\\n    Necessary because os.fstat only works on real files and not file-like\\n    objects. This works on more types of streams, primarily StringIO.\\n    \"\"\"\\n    file_obj.seek(0, 2)\\n    length = file_obj.tell()\\n    file_obj.seek(0)\\n    return length': 927,\n",
       " 'def prnt(self):\\n        \"\"\"\\n        Prints DB data representation of the object.\\n        \"\"\"\\n        print(\"= = = =\\\\n\\\\n%s object key: \\\\033[32m%s\\\\033[0m\" % (self.__class__.__name__, self.key))\\n        pprnt(self._data or self.clean_value())': 928,\n",
       " 'def timestamp_to_microseconds(timestamp):\\n    \"\"\"Convert a timestamp string into a microseconds value\\n    :param timestamp\\n    :return time in microseconds\\n    \"\"\"\\n    timestamp_str = datetime.datetime.strptime(timestamp, ISO_DATETIME_REGEX)\\n    epoch_time_secs = calendar.timegm(timestamp_str.timetuple())\\n    epoch_time_mus = epoch_time_secs * 1e6 + timestamp_str.microsecond\\n    return epoch_time_mus': 929,\n",
       " 'def stdout_display():\\n    \"\"\" Print results straight to stdout \"\"\"\\n    if sys.version_info[0] == 2:\\n        yield SmartBuffer(sys.stdout)\\n    else:\\n        yield SmartBuffer(sys.stdout.buffer)': 930,\n",
       " 'def start(self, timeout=None):\\n        \"\"\"\\n        Startup of the node.\\n        :param join: optionally wait for the process to end (default : True)\\n        :return: None\\n        \"\"\"\\n\\n        assert super(PyrosBase, self).start(timeout=timeout)\\n        # Because we currently use this to setup connection\\n        return self.name': 931,\n",
       " 'def filter_regex(names, regex):\\n    \"\"\"\\n    Return a tuple of strings that match the regular expression pattern.\\n    \"\"\"\\n    return tuple(name for name in names\\n                 if regex.search(name) is not None)': 932,\n",
       " 'def line_count(fn):\\n    \"\"\" Get line count of file\\n\\n    Args:\\n        fn (str): Path to file\\n\\n    Return:\\n          Number of lines in file (int)\\n    \"\"\"\\n\\n    with open(fn) as f:\\n        for i, l in enumerate(f):\\n            pass\\n    return i + 1': 933,\n",
       " 'def load(self):\\n        \"\"\"Load proxy list from configured proxy source\"\"\"\\n        self._list = self._source.load()\\n        self._list_iter = itertools.cycle(self._list)': 934,\n",
       " 'def _get_points(self):\\n        \"\"\"\\n        Subclasses may override this method.\\n        \"\"\"\\n        return tuple([self._getitem__points(i)\\n                     for i in range(self._len__points())])': 935,\n",
       " 'def format_pylint_disables(error_names, tag=True):\\n    \"\"\"\\n    Format a list of error_names into a \\'pylint: disable=\\' line.\\n    \"\"\"\\n    tag_str = \"lint-amnesty, \" if tag else \"\"\\n    if error_names:\\n        return u\"  # {tag}pylint: disable={disabled}\".format(\\n            disabled=\", \".join(sorted(error_names)),\\n            tag=tag_str,\\n        )\\n    else:\\n        return \"\"': 936,\n",
       " 'def qrandom(n):\\n  \"\"\"\\n  Creates an array of n true random numbers obtained from the quantum random\\n  number generator at qrng.anu.edu.au\\n\\n  This function requires the package quantumrandom and an internet connection.\\n\\n  Args:\\n    n (int):\\n      length of the random array\\n\\n  Return:\\n    array of ints:\\n      array of truly random unsigned 16 bit int values\\n  \"\"\"\\n  import quantumrandom\\n  return np.concatenate([\\n    quantumrandom.get_data(data_type=\\'uint16\\', array_length=1024)\\n    for i in range(int(np.ceil(n/1024.0)))\\n  ])[:n]': 937,\n",
       " 'def clear_table(dbconn, table_name):\\n    \"\"\"\\n    Delete all rows from a table\\n    :param dbconn: data base connection\\n    :param table_name: name of the table\\n    :return:\\n    \"\"\"\\n    cur = dbconn.cursor()\\n    cur.execute(\"DELETE FROM \\'{name}\\'\".format(name=table_name))\\n    dbconn.commit()': 938,\n",
       " 'def lowstrip(term):\\n    \"\"\"Convert to lowercase and strip spaces\"\"\"\\n    term = re.sub(\\'\\\\s+\\', \\' \\', term)\\n    term = term.lower()\\n    return term': 939,\n",
       " 'def chmod(self, mode):\\n        \"\"\"\\n        Change the mode (permissions) of this file.  The permissions are\\n        unix-style and identical to those used by python\\'s C{os.chmod}\\n        function.\\n\\n        @param mode: new permissions\\n        @type mode: int\\n        \"\"\"\\n        self.sftp._log(DEBUG, \\'chmod(%s, %r)\\' % (hexlify(self.handle), mode))\\n        attr = SFTPAttributes()\\n        attr.st_mode = mode\\n        self.sftp._request(CMD_FSETSTAT, self.handle, attr)': 940,\n",
       " 'def region_from_segment(image, segment):\\n    \"\"\"given a segment (rectangle) and an image, returns it\\'s corresponding subimage\"\"\"\\n    x, y, w, h = segment\\n    return image[y:y + h, x:x + w]': 941,\n",
       " 'def test(ctx, all=False, verbose=False):\\n    \"\"\"Run the tests.\"\"\"\\n    cmd = \\'tox\\' if all else \\'py.test\\'\\n    if verbose:\\n        cmd += \\' -v\\'\\n    return ctx.run(cmd, pty=True).return_code': 942,\n",
       " 'def set_value(self, value):\\n        \"\"\"Set value of the checkbox.\\n\\n        Parameters\\n        ----------\\n        value : bool\\n            value for the checkbox\\n\\n        \"\"\"\\n        if value:\\n            self.setCheckState(Qt.Checked)\\n        else:\\n            self.setCheckState(Qt.Unchecked)': 943,\n",
       " 'def show_xticklabels(self, row, column):\\n        \"\"\"Show the x-axis tick labels for a subplot.\\n\\n        :param row,column: specify the subplot.\\n\\n        \"\"\"\\n        subplot = self.get_subplot_at(row, column)\\n        subplot.show_xticklabels()': 944,\n",
       " 'def resizeEvent(self, event):\\n        \"\"\"Reimplement Qt method\"\"\"\\n        if not self.isMaximized() and not self.fullscreen_flag:\\n            self.window_size = self.size()\\n        QMainWindow.resizeEvent(self, event)\\n\\n        # To be used by the tour to be able to resize\\n        self.sig_resized.emit(event)': 945,\n",
       " 'def PrintSummaryTable(self):\\n    \"\"\"Prints a summary table.\"\"\"\\n    print(\"\"\"\\n\\nAs of {0:s} the repository contains:\\n\\n| **File paths covered** | **{1:d}** |\\n| :------------------ | ------: |\\n| **Registry keys covered** | **{2:d}** |\\n| **Total artifacts** | **{3:d}** |\\n\"\"\".format(\\n    time.strftime(\\'%Y-%m-%d\\'), self.path_count, self.reg_key_count,\\n    self.total_count))': 946,\n",
       " 'def state(self):\\n    \"\"\"Returns the current LED state by querying the remote controller.\"\"\"\\n    ev = self._query_waiters.request(self.__do_query_state)\\n    ev.wait(1.0)\\n    return self._state': 947,\n",
       " 'def refresh_swagger(self):\\n        \"\"\"\\n        Manually refresh the swagger document. This can help resolve errors communicate with the API.\\n        \"\"\"\\n        try:\\n            os.remove(self._get_swagger_filename(self.swagger_url))\\n        except EnvironmentError as e:\\n            logger.warn(os.strerror(e.errno))\\n        else:\\n            self.__init__()': 948,\n",
       " 'def full(self):\\n        \"\"\"Return True if the queue is full\"\"\"\\n        if not self.size: return False\\n        return len(self.pq) == (self.size + self.removed_count)': 949,\n",
       " 'def get_tablenames(cur):\\n    \"\"\" Conveinience: \"\"\"\\n    cur.execute(\"SELECT name FROM sqlite_master WHERE type=\\'table\\'\")\\n    tablename_list_ = cur.fetchall()\\n    tablename_list = [str(tablename[0]) for tablename in tablename_list_ ]\\n    return tablename_list': 950,\n",
       " 'def get_file_name(url):\\n  \"\"\"Returns file name of file at given url.\"\"\"\\n  return os.path.basename(urllib.parse.urlparse(url).path) or \\'unknown_name\\'': 951,\n",
       " 'def _quit(self, *args):\\n        \"\"\" quit crash \"\"\"\\n        self.logger.warn(\\'Bye!\\')\\n        sys.exit(self.exit())': 952,\n",
       " 'def sorted_index(values, x):\\n    \"\"\"\\n    For list, values, returns the index location of element x. If x does not exist will raise an error.\\n\\n    :param values: list\\n    :param x: item\\n    :return: integer index\\n    \"\"\"\\n    i = bisect_left(values, x)\\n    j = bisect_right(values, x)\\n    return values[i:j].index(x) + i': 953,\n",
       " 'def prepare(self):\\n        \"\"\"Prepare the handler, ensuring RabbitMQ is connected or start a new\\n        connection attempt.\\n\\n        \"\"\"\\n        super(RabbitMQRequestHandler, self).prepare()\\n        if self._rabbitmq_is_closed:\\n            self._connect_to_rabbitmq()': 954,\n",
       " 'def rnormal(mu, tau, size=None):\\n    \"\"\"\\n    Random normal variates.\\n    \"\"\"\\n    return np.random.normal(mu, 1. / np.sqrt(tau), size)': 955,\n",
       " 'def _num_cpus_darwin():\\n    \"\"\"Return the number of active CPUs on a Darwin system.\"\"\"\\n    p = subprocess.Popen([\\'sysctl\\',\\'-n\\',\\'hw.ncpu\\'],stdout=subprocess.PIPE)\\n    return p.stdout.read()': 956,\n",
       " 'def endless_permutations(N, random_state=None):\\n    \"\"\"\\n    Generate an endless sequence of random integers from permutations of the\\n    set [0, ..., N).\\n\\n    If we call this N times, we will sweep through the entire set without\\n    replacement, on the (N+1)th call a new permutation will be created, etc.\\n\\n    Parameters\\n    ----------\\n    N: int\\n        the length of the set\\n    random_state: int or RandomState, optional\\n        random seed\\n\\n    Yields\\n    ------\\n    int:\\n        a random int from the set [0, ..., N)\\n    \"\"\"\\n    generator = check_random_state(random_state)\\n    while True:\\n        batch_inds = generator.permutation(N)\\n        for b in batch_inds:\\n            yield b': 957,\n",
       " 'def newest_file(file_iterable):\\n  \"\"\"\\n  Returns the name of the newest file given an iterable of file names.\\n\\n  \"\"\"\\n  return max(file_iterable, key=lambda fname: os.path.getmtime(fname))': 958,\n",
       " 'def timeit(output):\\n    \"\"\"\\n    If output is string, then print the string and also time used\\n    \"\"\"\\n    b = time.time()\\n    yield\\n    print output, \\'time used: %.3fs\\' % (time.time()-b)': 959,\n",
       " 'def read_string(buff, byteorder=\\'big\\'):\\n    \"\"\"Read a string from a file-like object.\"\"\"\\n    length = read_numeric(USHORT, buff, byteorder)\\n    return buff.read(length).decode(\\'utf-8\\')': 960,\n",
       " 'def add_to_toolbar(self, toolbar, widget):\\n        \"\"\"Add widget actions to toolbar\"\"\"\\n        actions = widget.toolbar_actions\\n        if actions is not None:\\n            add_actions(toolbar, actions)': 961,\n",
       " 'def load_data(filename):\\n    \"\"\"\\n    :rtype : numpy matrix\\n    \"\"\"\\n    data = pandas.read_csv(filename, header=None, delimiter=\\'\\\\t\\', skiprows=9)\\n    return data.as_matrix()': 962,\n",
       " 'def get_system_uid():\\n    \"\"\"Get a (probably) unique ID to identify a system.\\n    Used to differentiate votes.\\n    \"\"\"\\n    try:\\n        if os.name == \\'nt\\':\\n            return get_nt_system_uid()\\n        if sys.platform == \\'darwin\\':\\n            return get_osx_system_uid()\\n    except Exception:\\n        return get_mac_uid()\\n    else:\\n        return get_mac_uid()': 963,\n",
       " 'def lines(input):\\n    \"\"\"Remove comments and empty lines\"\"\"\\n    for raw_line in input:\\n        line = raw_line.strip()\\n        if line and not line.startswith(\\'#\\'):\\n            yield strip_comments(line)': 964,\n",
       " 'def get_user_name():\\n    \"\"\"Get user name provide by operating system\\n    \"\"\"\\n\\n    if sys.platform == \\'win32\\':\\n        #user = os.getenv(\\'USERPROFILE\\')\\n        user = os.getenv(\\'USERNAME\\')\\n    else:\\n        user = os.getenv(\\'LOGNAME\\')\\n\\n    return user': 965,\n",
       " 'def getlines(filename, module_globals=None):\\n    \"\"\"Get the lines for a file from the cache.\\n    Update the cache if it doesn\\'t contain an entry for this file already.\"\"\"\\n\\n    if filename in cache:\\n        return cache[filename][2]\\n\\n    try:\\n        return updatecache(filename, module_globals)\\n    except MemoryError:\\n        clearcache()\\n        return []': 966,\n",
       " 'def compute_y(self, coefficients, num_x):\\n        \"\"\" Return calculated y-values for the domain of x-values in [1, num_x]. \"\"\"\\n        y_vals = []\\n\\n        for x in range(1, num_x + 1):\\n            y = sum([c * x ** i for i, c in enumerate(coefficients[::-1])])\\n            y_vals.append(y)\\n\\n        return y_vals': 967,\n",
       " 'def _readuntil(f, end=_TYPE_END):\\n\\t\"\"\"Helper function to read bytes until a certain end byte is hit\"\"\"\\n\\tbuf = bytearray()\\n\\tbyte = f.read(1)\\n\\twhile byte != end:\\n\\t\\tif byte == b\\'\\':\\n\\t\\t\\traise ValueError(\\'File ended unexpectedly. Expected end byte {}.\\'.format(end))\\n\\t\\tbuf += byte\\n\\t\\tbyte = f.read(1)\\n\\treturn buf': 968,\n",
       " 'def _add_pos1(token):\\n    \"\"\"\\n    Adds a \\'pos1\\' element to a frog token.\\n    \"\"\"\\n    result = token.copy()\\n    result[\\'pos1\\'] = _POSMAP[token[\\'pos\\'].split(\"(\")[0]]\\n    return result': 969,\n",
       " 'def read_string_from_file(path, encoding=\"utf8\"):\\n  \"\"\"\\n  Read entire contents of file into a string.\\n  \"\"\"\\n  with codecs.open(path, \"rb\", encoding=encoding) as f:\\n    value = f.read()\\n  return value': 970,\n",
       " 'def getfirstline(file, default):\\n    \"\"\"\\n    Returns the first line of a file.\\n    \"\"\"\\n    with open(file, \\'rb\\') as fh:\\n        content = fh.readlines()\\n        if len(content) == 1:\\n            return content[0].decode(\\'utf-8\\').strip(\\'\\\\n\\')\\n\\n    return default': 971,\n",
       " 'def page_guiref(arg_s=None):\\n    \"\"\"Show a basic reference about the GUI Console.\"\"\"\\n    from IPython.core import page\\n    page.page(gui_reference, auto_html=True)': 972,\n",
       " 'def _read_stdin():\\n    \"\"\"\\n    Generator for reading from standard input in nonblocking mode.\\n\\n    Other ways of reading from ``stdin`` in python waits, until the buffer is\\n    big enough, or until EOF character is sent.\\n\\n    This functions yields immediately after each line.\\n    \"\"\"\\n    line = sys.stdin.readline()\\n    while line:\\n        yield line\\n        line = sys.stdin.readline()': 973,\n",
       " 'def save_excel(self, fd):\\n        \"\"\" Saves the case as an Excel spreadsheet.\\n        \"\"\"\\n        from pylon.io.excel import ExcelWriter\\n        ExcelWriter(self).write(fd)': 974,\n",
       " 'async def async_input(prompt):\\n    \"\"\"\\n    Python\\'s ``input()`` is blocking, which means the event loop we set\\n    above can\\'t be running while we\\'re blocking there. This method will\\n    let the loop run while we wait for input.\\n    \"\"\"\\n    print(prompt, end=\\'\\', flush=True)\\n    return (await loop.run_in_executor(None, sys.stdin.readline)).rstrip()': 975,\n",
       " 'def set_font_size(self, size):\\n        \"\"\"Convenience method for just changing font size.\"\"\"\\n        if self.font.font_size == size:\\n            pass\\n        else:\\n            self.font._set_size(size)': 976,\n",
       " 'def open_json(file_name):\\n    \"\"\"\\n    returns json contents as string\\n    \"\"\"\\n    with open(file_name, \"r\") as json_data:\\n        data = json.load(json_data)\\n        return data': 977,\n",
       " 'def is_read_only(object):\\n    \"\"\"\\n    Returns if given object is read only ( built-in or extension ).\\n\\n    :param object: Object.\\n    :type object: object\\n    :return: Is object read only.\\n    :rtype: bool\\n    \"\"\"\\n\\n    try:\\n        attribute = \"_trace__read__\"\\n        setattr(object, attribute, True)\\n        delattr(object, attribute)\\n        return False\\n    except (TypeError, AttributeError):\\n        return True': 978,\n",
       " 'def draw_header(self, stream, header):\\n        \"\"\"Draw header with underline\"\"\"\\n        stream.writeln(\\'=\\' * (len(header) + 4))\\n        stream.writeln(\\'| \\' + header + \\' |\\')\\n        stream.writeln(\\'=\\' * (len(header) + 4))\\n        stream.writeln()': 979,\n",
       " 'def url_read_text(url, verbose=True):\\n    r\"\"\"\\n    Directly reads text data from url\\n    \"\"\"\\n    data = url_read(url, verbose)\\n    text = data.decode(\\'utf8\\')\\n    return text': 980,\n",
       " 'def get_xy_grids(ds, stride=1, getval=False):\\n    \"\"\"Return 2D arrays of x and y map coordinates for input GDAL Dataset \\n    \"\"\"\\n    gt = ds.GetGeoTransform()\\n    #stride = stride_m/gt[1]\\n    pX = np.arange(0, ds.RasterXSize, stride)\\n    pY = np.arange(0, ds.RasterYSize, stride)\\n    psamp = np.meshgrid(pX, pY)\\n    mX, mY = pixelToMap(psamp[0], psamp[1], gt)\\n    return mX, mY': 981,\n",
       " 'def _parse_config(config_file_path):\\n    \"\"\" Parse Config File from yaml file. \"\"\"\\n    config_file = open(config_file_path, \\'r\\')\\n    config = yaml.load(config_file)\\n    config_file.close()\\n    return config': 982,\n",
       " 'def json_iter (path):\\n    \"\"\"\\n    iterator for JSON-per-line in a file pattern\\n    \"\"\"\\n    with open(path, \\'r\\') as f:\\n        for line in f.readlines():\\n            yield json.loads(line)': 983,\n",
       " 'def mouse_move_event(self, event):\\n        \"\"\"\\n        Forward mouse cursor position events to the example\\n        \"\"\"\\n        self.example.mouse_position_event(event.x(), event.y())': 984,\n",
       " 'def exit(self):\\n        \"\"\"\\n        Closes the connection\\n        \"\"\"\\n        self.pubsub.unsubscribe()\\n        self.client.connection_pool.disconnect()\\n\\n        logger.info(\"Connection to Redis closed\")': 985,\n",
       " 'def get_var_type(self, name):\\n        \"\"\"\\n        Return type string, compatible with numpy.\\n        \"\"\"\\n        name = create_string_buffer(name)\\n        type_ = create_string_buffer(MAXSTRLEN)\\n        self.library.get_var_type.argtypes = [c_char_p, c_char_p]\\n        self.library.get_var_type(name, type_)\\n        return type_.value': 986,\n",
       " 'def acquire_node(self, node):\\n        \"\"\"\\n        acquire a single redis node\\n        \"\"\"\\n        try:\\n            return node.set(self.resource, self.lock_key, nx=True, px=self.ttl)\\n        except (redis.exceptions.ConnectionError, redis.exceptions.TimeoutError):\\n            return False': 987,\n",
       " 'def java_version():\\n    \"\"\"Call java and return version information.\\n\\n    :return unicode: Java version string\\n    \"\"\"\\n    result = subprocess.check_output(\\n        [c.JAVA, \\'-version\\'], stderr=subprocess.STDOUT\\n    )\\n    first_line = result.splitlines()[0]\\n    return first_line.decode()': 988,\n",
       " 'def expireat(self, key, when):\\n        \"\"\"Emulate expireat\"\"\"\\n        expire_time = datetime.fromtimestamp(when)\\n        key = self._encode(key)\\n        if key in self.redis:\\n            self.timeouts[key] = expire_time\\n            return True\\n        return False': 989,\n",
       " 'def init_checks_registry():\\n    \"\"\"Register all globally visible functions.\\n\\n    The first argument name is either \\'physical_line\\' or \\'logical_line\\'.\\n    \"\"\"\\n    mod = inspect.getmodule(register_check)\\n    for (name, function) in inspect.getmembers(mod, inspect.isfunction):\\n        register_check(function)': 990,\n",
       " 'def find_root(self):\\n        \"\"\" Traverse parent refs to top. \"\"\"\\n        cmd = self\\n        while cmd.parent:\\n            cmd = cmd.parent\\n        return cmd': 991,\n",
       " 'def _load_texture(file_name, resolver):\\n    \"\"\"\\n    Load a texture from a file into a PIL image.\\n    \"\"\"\\n    file_data = resolver.get(file_name)\\n    image = PIL.Image.open(util.wrap_as_stream(file_data))\\n    return image': 992,\n",
       " 'def _tuple_repr(data):\\n    \"\"\"Return a repr() for a list/tuple\"\"\"\\n    if len(data) == 1:\\n        return \"(%s,)\" % rpr(data[0])\\n    else:\\n        return \"(%s)\" % \", \".join([rpr(x) for x in data])': 993,\n",
       " 'def Load(file):\\n    \"\"\" Loads a model from specified file \"\"\"\\n    with open(file, \\'rb\\') as file:\\n        model = dill.load(file)\\n        return model': 994,\n",
       " 'def make_bintree(levels):\\n    \"\"\"Make a symmetrical binary tree with @levels\"\"\"\\n    G = nx.DiGraph()\\n    root = \\'0\\'\\n    G.add_node(root)\\n    add_children(G, root, levels, 2)\\n    return G': 995,\n",
       " 'def is_valid_regex(string):\\n    \"\"\"\\n    Checks whether the re module can compile the given regular expression.\\n\\n    Parameters\\n    ----------\\n    string: str\\n\\n    Returns\\n    -------\\n    boolean\\n    \"\"\"\\n    try:\\n        re.compile(string)\\n        is_valid = True\\n    except re.error:\\n        is_valid = False\\n    return is_valid': 996,\n",
       " 'def _makes_clone(_func, *args, **kw):\\n    \"\"\"\\n    A decorator that returns a clone of the current object so that\\n    we can re-use the object for similar requests.\\n    \"\"\"\\n    self = args[0]._clone()\\n    _func(self, *args[1:], **kw)\\n    return self': 997,\n",
       " 'def validate_multiindex(self, obj):\\n        \"\"\"validate that we can store the multi-index; reset and return the\\n        new object\\n        \"\"\"\\n        levels = [l if l is not None else \"level_{0}\".format(i)\\n                  for i, l in enumerate(obj.index.names)]\\n        try:\\n            return obj.reset_index(), levels\\n        except ValueError:\\n            raise ValueError(\"duplicate names/columns in the multi-index when \"\\n                             \"storing as a table\")': 998,\n",
       " 'def alert(text=\\'\\', title=\\'\\', button=OK_TEXT, root=None, timeout=None):\\n    \"\"\"Displays a simple message box with text and a single OK button. Returns the text of the button clicked on.\"\"\"\\n    assert TKINTER_IMPORT_SUCCEEDED, \\'Tkinter is required for pymsgbox\\'\\n    return _buttonbox(msg=text, title=title, choices=[str(button)], root=root, timeout=timeout)': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " code_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T05:56:59.182296Z",
     "start_time": "2021-09-27T05:56:57.394360Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T05:57:48.095231Z",
     "start_time": "2021-09-27T05:57:48.072522Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.rand((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T05:58:18.010292Z",
     "start_time": "2021-09-27T05:58:17.994293Z"
    }
   },
   "outputs": [],
   "source": [
    "b = torch.rand((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T05:58:18.482441Z",
     "start_time": "2021-09-27T05:58:18.469922Z"
    }
   },
   "outputs": [],
   "source": [
    "score = [a,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T05:58:37.334647Z",
     "start_time": "2021-09-27T05:58:37.330637Z"
    }
   },
   "outputs": [],
   "source": [
    " c= torch.cat(score, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T05:58:41.522674Z",
     "start_time": "2021-09-27T05:58:41.505646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:12:29.587185Z",
     "start_time": "2021-09-27T06:12:29.580210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 4, 3, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score= torch.tensor([0,1,4,3,2])\n",
    "torch.argsort(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
